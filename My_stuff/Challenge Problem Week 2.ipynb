{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Average</th>\n",
       "      <th>Data_1</th>\n",
       "      <th>Data_2</th>\n",
       "      <th>Data_3</th>\n",
       "      <th>Data_4</th>\n",
       "      <th>Data_5</th>\n",
       "      <th>Data_6</th>\n",
       "      <th>Data_7</th>\n",
       "      <th>Data_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Data_37</th>\n",
       "      <th>Data_38</th>\n",
       "      <th>Data_39</th>\n",
       "      <th>Data_40</th>\n",
       "      <th>Data_41</th>\n",
       "      <th>Data_42</th>\n",
       "      <th>Data_43</th>\n",
       "      <th>Data_44</th>\n",
       "      <th>Data_45</th>\n",
       "      <th>Data_46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yariel</td>\n",
       "      <td>211305.8140</td>\n",
       "      <td>204858</td>\n",
       "      <td>286286</td>\n",
       "      <td>218850</td>\n",
       "      <td>163842</td>\n",
       "      <td>208936</td>\n",
       "      <td>210772</td>\n",
       "      <td>131447</td>\n",
       "      <td>242224</td>\n",
       "      <td>...</td>\n",
       "      <td>199156.0</td>\n",
       "      <td>275056.0</td>\n",
       "      <td>237057.0</td>\n",
       "      <td>183100.0</td>\n",
       "      <td>192963.0</td>\n",
       "      <td>270406.0</td>\n",
       "      <td>188295.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David</td>\n",
       "      <td>235034.4186</td>\n",
       "      <td>364157</td>\n",
       "      <td>192116</td>\n",
       "      <td>182751</td>\n",
       "      <td>196590</td>\n",
       "      <td>343780</td>\n",
       "      <td>195063</td>\n",
       "      <td>242795</td>\n",
       "      <td>195479</td>\n",
       "      <td>...</td>\n",
       "      <td>174536.0</td>\n",
       "      <td>241454.0</td>\n",
       "      <td>284076.0</td>\n",
       "      <td>249164.0</td>\n",
       "      <td>242866.0</td>\n",
       "      <td>421483.0</td>\n",
       "      <td>246092.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vineet</td>\n",
       "      <td>204089.3409</td>\n",
       "      <td>166236</td>\n",
       "      <td>152356</td>\n",
       "      <td>157459</td>\n",
       "      <td>168879</td>\n",
       "      <td>174007</td>\n",
       "      <td>192230</td>\n",
       "      <td>189787</td>\n",
       "      <td>149246</td>\n",
       "      <td>...</td>\n",
       "      <td>195672.0</td>\n",
       "      <td>167883.0</td>\n",
       "      <td>488581.0</td>\n",
       "      <td>310119.0</td>\n",
       "      <td>284390.0</td>\n",
       "      <td>231455.0</td>\n",
       "      <td>191126.0</td>\n",
       "      <td>193271.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edward</td>\n",
       "      <td>208359.4651</td>\n",
       "      <td>176878</td>\n",
       "      <td>186854</td>\n",
       "      <td>180379</td>\n",
       "      <td>181845</td>\n",
       "      <td>200305</td>\n",
       "      <td>108443</td>\n",
       "      <td>197407</td>\n",
       "      <td>187073</td>\n",
       "      <td>...</td>\n",
       "      <td>233916.0</td>\n",
       "      <td>318130.0</td>\n",
       "      <td>217341.0</td>\n",
       "      <td>207513.0</td>\n",
       "      <td>209229.0</td>\n",
       "      <td>177683.0</td>\n",
       "      <td>184432.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carol</td>\n",
       "      <td>174654.6136</td>\n",
       "      <td>177511</td>\n",
       "      <td>156647</td>\n",
       "      <td>171744</td>\n",
       "      <td>172564</td>\n",
       "      <td>173469</td>\n",
       "      <td>166916</td>\n",
       "      <td>164499</td>\n",
       "      <td>169239</td>\n",
       "      <td>...</td>\n",
       "      <td>151610.0</td>\n",
       "      <td>149091.0</td>\n",
       "      <td>152305.0</td>\n",
       "      <td>173887.0</td>\n",
       "      <td>160802.0</td>\n",
       "      <td>168195.0</td>\n",
       "      <td>320182.0</td>\n",
       "      <td>189543.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Joy</td>\n",
       "      <td>244750.9302</td>\n",
       "      <td>246339</td>\n",
       "      <td>186510</td>\n",
       "      <td>231041</td>\n",
       "      <td>267405</td>\n",
       "      <td>219968</td>\n",
       "      <td>224149</td>\n",
       "      <td>263395</td>\n",
       "      <td>244945</td>\n",
       "      <td>...</td>\n",
       "      <td>258074.0</td>\n",
       "      <td>196315.0</td>\n",
       "      <td>246975.0</td>\n",
       "      <td>244278.0</td>\n",
       "      <td>221299.0</td>\n",
       "      <td>253444.0</td>\n",
       "      <td>243880.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sharvill</td>\n",
       "      <td>219025.6190</td>\n",
       "      <td>207490</td>\n",
       "      <td>231224</td>\n",
       "      <td>201460</td>\n",
       "      <td>263652</td>\n",
       "      <td>188061</td>\n",
       "      <td>254707</td>\n",
       "      <td>300124</td>\n",
       "      <td>172624</td>\n",
       "      <td>...</td>\n",
       "      <td>191941.0</td>\n",
       "      <td>196941.0</td>\n",
       "      <td>201187.0</td>\n",
       "      <td>328923.0</td>\n",
       "      <td>197061.0</td>\n",
       "      <td>203932.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Esteban</td>\n",
       "      <td>185877.3182</td>\n",
       "      <td>160615</td>\n",
       "      <td>209885</td>\n",
       "      <td>175562</td>\n",
       "      <td>245080</td>\n",
       "      <td>165761</td>\n",
       "      <td>174758</td>\n",
       "      <td>170393</td>\n",
       "      <td>137429</td>\n",
       "      <td>...</td>\n",
       "      <td>196878.0</td>\n",
       "      <td>227003.0</td>\n",
       "      <td>188476.0</td>\n",
       "      <td>162886.0</td>\n",
       "      <td>298522.0</td>\n",
       "      <td>164720.0</td>\n",
       "      <td>167869.0</td>\n",
       "      <td>188950.0</td>\n",
       "      <td>188357.0</td>\n",
       "      <td>201690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pratik</td>\n",
       "      <td>207329.6364</td>\n",
       "      <td>188794</td>\n",
       "      <td>320636</td>\n",
       "      <td>184062</td>\n",
       "      <td>227252</td>\n",
       "      <td>222538</td>\n",
       "      <td>186490</td>\n",
       "      <td>162079</td>\n",
       "      <td>167592</td>\n",
       "      <td>...</td>\n",
       "      <td>244884.0</td>\n",
       "      <td>200373.0</td>\n",
       "      <td>235158.0</td>\n",
       "      <td>233631.0</td>\n",
       "      <td>235144.0</td>\n",
       "      <td>290388.0</td>\n",
       "      <td>181413.0</td>\n",
       "      <td>372462.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adi</td>\n",
       "      <td>170616.2439</td>\n",
       "      <td>338060</td>\n",
       "      <td>191325</td>\n",
       "      <td>258132</td>\n",
       "      <td>147160</td>\n",
       "      <td>154752</td>\n",
       "      <td>154725</td>\n",
       "      <td>148730</td>\n",
       "      <td>161314</td>\n",
       "      <td>...</td>\n",
       "      <td>185476.0</td>\n",
       "      <td>176060.0</td>\n",
       "      <td>227540.0</td>\n",
       "      <td>195289.0</td>\n",
       "      <td>167179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alex</td>\n",
       "      <td>240738.1136</td>\n",
       "      <td>226343</td>\n",
       "      <td>184379</td>\n",
       "      <td>197168</td>\n",
       "      <td>203597</td>\n",
       "      <td>337395</td>\n",
       "      <td>228899</td>\n",
       "      <td>246182</td>\n",
       "      <td>226420</td>\n",
       "      <td>...</td>\n",
       "      <td>391202.0</td>\n",
       "      <td>184563.0</td>\n",
       "      <td>204001.0</td>\n",
       "      <td>202953.0</td>\n",
       "      <td>184598.0</td>\n",
       "      <td>208583.0</td>\n",
       "      <td>197181.0</td>\n",
       "      <td>235789.0</td>\n",
       "      <td>201135.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Odessa</td>\n",
       "      <td>210327.1628</td>\n",
       "      <td>246824</td>\n",
       "      <td>225399</td>\n",
       "      <td>215384</td>\n",
       "      <td>217780</td>\n",
       "      <td>251753</td>\n",
       "      <td>208540</td>\n",
       "      <td>208250</td>\n",
       "      <td>200953</td>\n",
       "      <td>...</td>\n",
       "      <td>184878.0</td>\n",
       "      <td>181952.0</td>\n",
       "      <td>189045.0</td>\n",
       "      <td>206436.0</td>\n",
       "      <td>204126.0</td>\n",
       "      <td>185736.0</td>\n",
       "      <td>184315.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Shreya</td>\n",
       "      <td>199415.0233</td>\n",
       "      <td>354314</td>\n",
       "      <td>326278</td>\n",
       "      <td>245212</td>\n",
       "      <td>191291</td>\n",
       "      <td>223677</td>\n",
       "      <td>179549</td>\n",
       "      <td>184498</td>\n",
       "      <td>142705</td>\n",
       "      <td>...</td>\n",
       "      <td>256096.0</td>\n",
       "      <td>176891.0</td>\n",
       "      <td>193850.0</td>\n",
       "      <td>186369.0</td>\n",
       "      <td>192301.0</td>\n",
       "      <td>199845.0</td>\n",
       "      <td>176869.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mariela</td>\n",
       "      <td>191046.5128</td>\n",
       "      <td>239258</td>\n",
       "      <td>204884</td>\n",
       "      <td>190111</td>\n",
       "      <td>189049</td>\n",
       "      <td>197249</td>\n",
       "      <td>220115</td>\n",
       "      <td>175130</td>\n",
       "      <td>188821</td>\n",
       "      <td>...</td>\n",
       "      <td>162920.0</td>\n",
       "      <td>199302.0</td>\n",
       "      <td>190991.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Anna</td>\n",
       "      <td>230374.8611</td>\n",
       "      <td>275761</td>\n",
       "      <td>211233</td>\n",
       "      <td>203972</td>\n",
       "      <td>286162</td>\n",
       "      <td>208546</td>\n",
       "      <td>201558</td>\n",
       "      <td>242530</td>\n",
       "      <td>243939</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Elaine</td>\n",
       "      <td>258813.2000</td>\n",
       "      <td>194375</td>\n",
       "      <td>198578</td>\n",
       "      <td>177845</td>\n",
       "      <td>266463</td>\n",
       "      <td>338828</td>\n",
       "      <td>231795</td>\n",
       "      <td>185890</td>\n",
       "      <td>192148</td>\n",
       "      <td>...</td>\n",
       "      <td>280288.0</td>\n",
       "      <td>244239.0</td>\n",
       "      <td>241120.0</td>\n",
       "      <td>226440.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Harris</td>\n",
       "      <td>207254.7368</td>\n",
       "      <td>221375</td>\n",
       "      <td>194432</td>\n",
       "      <td>174891</td>\n",
       "      <td>179105</td>\n",
       "      <td>218150</td>\n",
       "      <td>175533</td>\n",
       "      <td>199114</td>\n",
       "      <td>169271</td>\n",
       "      <td>...</td>\n",
       "      <td>235610.0</td>\n",
       "      <td>182508.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vishal</td>\n",
       "      <td>232919.5897</td>\n",
       "      <td>275799</td>\n",
       "      <td>233790</td>\n",
       "      <td>232681</td>\n",
       "      <td>243393</td>\n",
       "      <td>271968</td>\n",
       "      <td>217959</td>\n",
       "      <td>212915</td>\n",
       "      <td>214583</td>\n",
       "      <td>...</td>\n",
       "      <td>213509.0</td>\n",
       "      <td>185394.0</td>\n",
       "      <td>185014.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Shuen</td>\n",
       "      <td>175527.9231</td>\n",
       "      <td>167600</td>\n",
       "      <td>222927</td>\n",
       "      <td>177871</td>\n",
       "      <td>172624</td>\n",
       "      <td>249035</td>\n",
       "      <td>158417</td>\n",
       "      <td>174977</td>\n",
       "      <td>172871</td>\n",
       "      <td>...</td>\n",
       "      <td>156922.0</td>\n",
       "      <td>184641.0</td>\n",
       "      <td>157883.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Varun</td>\n",
       "      <td>197082.0930</td>\n",
       "      <td>197411</td>\n",
       "      <td>213023</td>\n",
       "      <td>232769</td>\n",
       "      <td>191787</td>\n",
       "      <td>178604</td>\n",
       "      <td>216833</td>\n",
       "      <td>198419</td>\n",
       "      <td>217859</td>\n",
       "      <td>...</td>\n",
       "      <td>181953.0</td>\n",
       "      <td>186023.0</td>\n",
       "      <td>228910.0</td>\n",
       "      <td>188372.0</td>\n",
       "      <td>164176.0</td>\n",
       "      <td>215343.0</td>\n",
       "      <td>185148.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Other Joy</td>\n",
       "      <td>225146.1250</td>\n",
       "      <td>274350</td>\n",
       "      <td>274225</td>\n",
       "      <td>312815</td>\n",
       "      <td>198443</td>\n",
       "      <td>228269</td>\n",
       "      <td>204818</td>\n",
       "      <td>351328</td>\n",
       "      <td>208311</td>\n",
       "      <td>...</td>\n",
       "      <td>221596.0</td>\n",
       "      <td>182348.0</td>\n",
       "      <td>199227.0</td>\n",
       "      <td>225798.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Govind</td>\n",
       "      <td>176010.1190</td>\n",
       "      <td>187549</td>\n",
       "      <td>158480</td>\n",
       "      <td>137907</td>\n",
       "      <td>147181</td>\n",
       "      <td>158118</td>\n",
       "      <td>145790</td>\n",
       "      <td>145879</td>\n",
       "      <td>170279</td>\n",
       "      <td>...</td>\n",
       "      <td>231590.0</td>\n",
       "      <td>186522.0</td>\n",
       "      <td>203207.0</td>\n",
       "      <td>182011.0</td>\n",
       "      <td>208054.0</td>\n",
       "      <td>198179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Suat</td>\n",
       "      <td>238906.2273</td>\n",
       "      <td>270668</td>\n",
       "      <td>194416</td>\n",
       "      <td>276626</td>\n",
       "      <td>216204</td>\n",
       "      <td>203442</td>\n",
       "      <td>282655</td>\n",
       "      <td>237962</td>\n",
       "      <td>236491</td>\n",
       "      <td>...</td>\n",
       "      <td>260821.0</td>\n",
       "      <td>331297.0</td>\n",
       "      <td>191232.0</td>\n",
       "      <td>210420.0</td>\n",
       "      <td>309072.0</td>\n",
       "      <td>390790.0</td>\n",
       "      <td>278688.0</td>\n",
       "      <td>217058.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name      Average  Data_1  Data_2  Data_3  Data_4  Data_5  Data_6  \\\n",
       "0      Yariel  211305.8140  204858  286286  218850  163842  208936  210772   \n",
       "1       David  235034.4186  364157  192116  182751  196590  343780  195063   \n",
       "2      Vineet  204089.3409  166236  152356  157459  168879  174007  192230   \n",
       "3      Edward  208359.4651  176878  186854  180379  181845  200305  108443   \n",
       "4       Carol  174654.6136  177511  156647  171744  172564  173469  166916   \n",
       "5         Joy  244750.9302  246339  186510  231041  267405  219968  224149   \n",
       "6    Sharvill  219025.6190  207490  231224  201460  263652  188061  254707   \n",
       "7     Esteban  185877.3182  160615  209885  175562  245080  165761  174758   \n",
       "8      Pratik  207329.6364  188794  320636  184062  227252  222538  186490   \n",
       "9         Adi  170616.2439  338060  191325  258132  147160  154752  154725   \n",
       "10       Alex  240738.1136  226343  184379  197168  203597  337395  228899   \n",
       "11     Odessa  210327.1628  246824  225399  215384  217780  251753  208540   \n",
       "12     Shreya  199415.0233  354314  326278  245212  191291  223677  179549   \n",
       "13    Mariela  191046.5128  239258  204884  190111  189049  197249  220115   \n",
       "14       Anna  230374.8611  275761  211233  203972  286162  208546  201558   \n",
       "15     Elaine  258813.2000  194375  198578  177845  266463  338828  231795   \n",
       "16     Harris  207254.7368  221375  194432  174891  179105  218150  175533   \n",
       "17     Vishal  232919.5897  275799  233790  232681  243393  271968  217959   \n",
       "18      Shuen  175527.9231  167600  222927  177871  172624  249035  158417   \n",
       "19      Varun  197082.0930  197411  213023  232769  191787  178604  216833   \n",
       "20  Other Joy  225146.1250  274350  274225  312815  198443  228269  204818   \n",
       "21     Govind  176010.1190  187549  158480  137907  147181  158118  145790   \n",
       "22       Suat  238906.2273  270668  194416  276626  216204  203442  282655   \n",
       "\n",
       "    Data_7  Data_8    ...      Data_37   Data_38   Data_39   Data_40  \\\n",
       "0   131447  242224    ...     199156.0  275056.0  237057.0  183100.0   \n",
       "1   242795  195479    ...     174536.0  241454.0  284076.0  249164.0   \n",
       "2   189787  149246    ...     195672.0  167883.0  488581.0  310119.0   \n",
       "3   197407  187073    ...     233916.0  318130.0  217341.0  207513.0   \n",
       "4   164499  169239    ...     151610.0  149091.0  152305.0  173887.0   \n",
       "5   263395  244945    ...     258074.0  196315.0  246975.0  244278.0   \n",
       "6   300124  172624    ...     191941.0  196941.0  201187.0  328923.0   \n",
       "7   170393  137429    ...     196878.0  227003.0  188476.0  162886.0   \n",
       "8   162079  167592    ...     244884.0  200373.0  235158.0  233631.0   \n",
       "9   148730  161314    ...     185476.0  176060.0  227540.0  195289.0   \n",
       "10  246182  226420    ...     391202.0  184563.0  204001.0  202953.0   \n",
       "11  208250  200953    ...     184878.0  181952.0  189045.0  206436.0   \n",
       "12  184498  142705    ...     256096.0  176891.0  193850.0  186369.0   \n",
       "13  175130  188821    ...     162920.0  199302.0  190991.0       NaN   \n",
       "14  242530  243939    ...          NaN       NaN       NaN       NaN   \n",
       "15  185890  192148    ...     280288.0  244239.0  241120.0  226440.0   \n",
       "16  199114  169271    ...     235610.0  182508.0       NaN       NaN   \n",
       "17  212915  214583    ...     213509.0  185394.0  185014.0       NaN   \n",
       "18  174977  172871    ...     156922.0  184641.0  157883.0       NaN   \n",
       "19  198419  217859    ...     181953.0  186023.0  228910.0  188372.0   \n",
       "20  351328  208311    ...     221596.0  182348.0  199227.0  225798.0   \n",
       "21  145879  170279    ...     231590.0  186522.0  203207.0  182011.0   \n",
       "22  237962  236491    ...     260821.0  331297.0  191232.0  210420.0   \n",
       "\n",
       "     Data_41   Data_42   Data_43   Data_44   Data_45   Data_46  \n",
       "0   192963.0  270406.0  188295.0       NaN       NaN       NaN  \n",
       "1   242866.0  421483.0  246092.0       NaN       NaN       NaN  \n",
       "2   284390.0  231455.0  191126.0  193271.0       NaN       NaN  \n",
       "3   209229.0  177683.0  184432.0       NaN       NaN       NaN  \n",
       "4   160802.0  168195.0  320182.0  189543.0       NaN       NaN  \n",
       "5   221299.0  253444.0  243880.0       NaN       NaN       NaN  \n",
       "6   197061.0  203932.0       NaN       NaN       NaN       NaN  \n",
       "7   298522.0  164720.0  167869.0  188950.0  188357.0  201690.0  \n",
       "8   235144.0  290388.0  181413.0  372462.0       NaN       NaN  \n",
       "9   167179.0       NaN       NaN       NaN       NaN       NaN  \n",
       "10  184598.0  208583.0  197181.0  235789.0  201135.0       NaN  \n",
       "11  204126.0  185736.0  184315.0       NaN       NaN       NaN  \n",
       "12  192301.0  199845.0  176869.0       NaN       NaN       NaN  \n",
       "13       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "14       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "15       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "16       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "17       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "18       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "19  164176.0  215343.0  185148.0       NaN       NaN       NaN  \n",
       "20       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "21  208054.0  198179.0       NaN       NaN       NaN       NaN  \n",
       "22  309072.0  390790.0  278688.0  217058.0       NaN       NaN  \n",
       "\n",
       "[23 rows x 48 columns]"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PVT_data = pd.read_csv(\"PVT data - Sheet1.csv\")\n",
    "PVT_data = PVT_data[PVT_data > 100000]\n",
    "PVT_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yariel</th>\n",
       "      <th>David</th>\n",
       "      <th>Vineet</th>\n",
       "      <th>Edward</th>\n",
       "      <th>Carol</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sharvill</th>\n",
       "      <th>Esteban</th>\n",
       "      <th>Pratik</th>\n",
       "      <th>Adi</th>\n",
       "      <th>...</th>\n",
       "      <th>Mariela</th>\n",
       "      <th>Anna</th>\n",
       "      <th>Elaine</th>\n",
       "      <th>Harris</th>\n",
       "      <th>Vishal</th>\n",
       "      <th>Shuen</th>\n",
       "      <th>Varun</th>\n",
       "      <th>Other Joy</th>\n",
       "      <th>Govind</th>\n",
       "      <th>Suat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204858.0</td>\n",
       "      <td>364157.0</td>\n",
       "      <td>166236.0</td>\n",
       "      <td>176878.0</td>\n",
       "      <td>177511.0</td>\n",
       "      <td>246339.0</td>\n",
       "      <td>207490.0</td>\n",
       "      <td>160615</td>\n",
       "      <td>188794.0</td>\n",
       "      <td>338060.0</td>\n",
       "      <td>...</td>\n",
       "      <td>239258.0</td>\n",
       "      <td>275761.0</td>\n",
       "      <td>194375.0</td>\n",
       "      <td>221375.0</td>\n",
       "      <td>275799.0</td>\n",
       "      <td>167600.0</td>\n",
       "      <td>197411.0</td>\n",
       "      <td>274350.0</td>\n",
       "      <td>187549.0</td>\n",
       "      <td>270668.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286286.0</td>\n",
       "      <td>192116.0</td>\n",
       "      <td>152356.0</td>\n",
       "      <td>186854.0</td>\n",
       "      <td>156647.0</td>\n",
       "      <td>186510.0</td>\n",
       "      <td>231224.0</td>\n",
       "      <td>209885</td>\n",
       "      <td>320636.0</td>\n",
       "      <td>191325.0</td>\n",
       "      <td>...</td>\n",
       "      <td>204884.0</td>\n",
       "      <td>211233.0</td>\n",
       "      <td>198578.0</td>\n",
       "      <td>194432.0</td>\n",
       "      <td>233790.0</td>\n",
       "      <td>222927.0</td>\n",
       "      <td>213023.0</td>\n",
       "      <td>274225.0</td>\n",
       "      <td>158480.0</td>\n",
       "      <td>194416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218850.0</td>\n",
       "      <td>182751.0</td>\n",
       "      <td>157459.0</td>\n",
       "      <td>180379.0</td>\n",
       "      <td>171744.0</td>\n",
       "      <td>231041.0</td>\n",
       "      <td>201460.0</td>\n",
       "      <td>175562</td>\n",
       "      <td>184062.0</td>\n",
       "      <td>258132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>190111.0</td>\n",
       "      <td>203972.0</td>\n",
       "      <td>177845.0</td>\n",
       "      <td>174891.0</td>\n",
       "      <td>232681.0</td>\n",
       "      <td>177871.0</td>\n",
       "      <td>232769.0</td>\n",
       "      <td>312815.0</td>\n",
       "      <td>137907.0</td>\n",
       "      <td>276626.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163842.0</td>\n",
       "      <td>196590.0</td>\n",
       "      <td>168879.0</td>\n",
       "      <td>181845.0</td>\n",
       "      <td>172564.0</td>\n",
       "      <td>267405.0</td>\n",
       "      <td>263652.0</td>\n",
       "      <td>245080</td>\n",
       "      <td>227252.0</td>\n",
       "      <td>147160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>189049.0</td>\n",
       "      <td>286162.0</td>\n",
       "      <td>266463.0</td>\n",
       "      <td>179105.0</td>\n",
       "      <td>243393.0</td>\n",
       "      <td>172624.0</td>\n",
       "      <td>191787.0</td>\n",
       "      <td>198443.0</td>\n",
       "      <td>147181.0</td>\n",
       "      <td>216204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208936.0</td>\n",
       "      <td>343780.0</td>\n",
       "      <td>174007.0</td>\n",
       "      <td>200305.0</td>\n",
       "      <td>173469.0</td>\n",
       "      <td>219968.0</td>\n",
       "      <td>188061.0</td>\n",
       "      <td>165761</td>\n",
       "      <td>222538.0</td>\n",
       "      <td>154752.0</td>\n",
       "      <td>...</td>\n",
       "      <td>197249.0</td>\n",
       "      <td>208546.0</td>\n",
       "      <td>338828.0</td>\n",
       "      <td>218150.0</td>\n",
       "      <td>271968.0</td>\n",
       "      <td>249035.0</td>\n",
       "      <td>178604.0</td>\n",
       "      <td>228269.0</td>\n",
       "      <td>158118.0</td>\n",
       "      <td>203442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>210772.0</td>\n",
       "      <td>195063.0</td>\n",
       "      <td>192230.0</td>\n",
       "      <td>108443.0</td>\n",
       "      <td>166916.0</td>\n",
       "      <td>224149.0</td>\n",
       "      <td>254707.0</td>\n",
       "      <td>174758</td>\n",
       "      <td>186490.0</td>\n",
       "      <td>154725.0</td>\n",
       "      <td>...</td>\n",
       "      <td>220115.0</td>\n",
       "      <td>201558.0</td>\n",
       "      <td>231795.0</td>\n",
       "      <td>175533.0</td>\n",
       "      <td>217959.0</td>\n",
       "      <td>158417.0</td>\n",
       "      <td>216833.0</td>\n",
       "      <td>204818.0</td>\n",
       "      <td>145790.0</td>\n",
       "      <td>282655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>131447.0</td>\n",
       "      <td>242795.0</td>\n",
       "      <td>189787.0</td>\n",
       "      <td>197407.0</td>\n",
       "      <td>164499.0</td>\n",
       "      <td>263395.0</td>\n",
       "      <td>300124.0</td>\n",
       "      <td>170393</td>\n",
       "      <td>162079.0</td>\n",
       "      <td>148730.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175130.0</td>\n",
       "      <td>242530.0</td>\n",
       "      <td>185890.0</td>\n",
       "      <td>199114.0</td>\n",
       "      <td>212915.0</td>\n",
       "      <td>174977.0</td>\n",
       "      <td>198419.0</td>\n",
       "      <td>351328.0</td>\n",
       "      <td>145879.0</td>\n",
       "      <td>237962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>242224.0</td>\n",
       "      <td>195479.0</td>\n",
       "      <td>149246.0</td>\n",
       "      <td>187073.0</td>\n",
       "      <td>169239.0</td>\n",
       "      <td>244945.0</td>\n",
       "      <td>172624.0</td>\n",
       "      <td>137429</td>\n",
       "      <td>167592.0</td>\n",
       "      <td>161314.0</td>\n",
       "      <td>...</td>\n",
       "      <td>188821.0</td>\n",
       "      <td>243939.0</td>\n",
       "      <td>192148.0</td>\n",
       "      <td>169271.0</td>\n",
       "      <td>214583.0</td>\n",
       "      <td>172871.0</td>\n",
       "      <td>217859.0</td>\n",
       "      <td>208311.0</td>\n",
       "      <td>170279.0</td>\n",
       "      <td>236491.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>206926.0</td>\n",
       "      <td>204261.0</td>\n",
       "      <td>154905.0</td>\n",
       "      <td>203213.0</td>\n",
       "      <td>203443.0</td>\n",
       "      <td>246524.0</td>\n",
       "      <td>188363.0</td>\n",
       "      <td>159498</td>\n",
       "      <td>219369.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>192073.0</td>\n",
       "      <td>195800.0</td>\n",
       "      <td>184634.0</td>\n",
       "      <td>190789.0</td>\n",
       "      <td>254876.0</td>\n",
       "      <td>170337.0</td>\n",
       "      <td>198661.0</td>\n",
       "      <td>205307.0</td>\n",
       "      <td>163899.0</td>\n",
       "      <td>214765.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>206689.0</td>\n",
       "      <td>193601.0</td>\n",
       "      <td>148615.0</td>\n",
       "      <td>222111.0</td>\n",
       "      <td>205669.0</td>\n",
       "      <td>231938.0</td>\n",
       "      <td>166599.0</td>\n",
       "      <td>183652</td>\n",
       "      <td>163588.0</td>\n",
       "      <td>233924.0</td>\n",
       "      <td>...</td>\n",
       "      <td>210252.0</td>\n",
       "      <td>196837.0</td>\n",
       "      <td>243295.0</td>\n",
       "      <td>218184.0</td>\n",
       "      <td>242976.0</td>\n",
       "      <td>174330.0</td>\n",
       "      <td>221238.0</td>\n",
       "      <td>231338.0</td>\n",
       "      <td>216986.0</td>\n",
       "      <td>213015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>206496.0</td>\n",
       "      <td>228048.0</td>\n",
       "      <td>220956.0</td>\n",
       "      <td>213196.0</td>\n",
       "      <td>165719.0</td>\n",
       "      <td>211540.0</td>\n",
       "      <td>183328.0</td>\n",
       "      <td>160102</td>\n",
       "      <td>161151.0</td>\n",
       "      <td>166299.0</td>\n",
       "      <td>...</td>\n",
       "      <td>171061.0</td>\n",
       "      <td>252035.0</td>\n",
       "      <td>183755.0</td>\n",
       "      <td>193939.0</td>\n",
       "      <td>229084.0</td>\n",
       "      <td>164030.0</td>\n",
       "      <td>207392.0</td>\n",
       "      <td>205176.0</td>\n",
       "      <td>181427.0</td>\n",
       "      <td>226710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>218458.0</td>\n",
       "      <td>254455.0</td>\n",
       "      <td>186114.0</td>\n",
       "      <td>210735.0</td>\n",
       "      <td>172717.0</td>\n",
       "      <td>215465.0</td>\n",
       "      <td>220336.0</td>\n",
       "      <td>154805</td>\n",
       "      <td>190377.0</td>\n",
       "      <td>232174.0</td>\n",
       "      <td>...</td>\n",
       "      <td>176472.0</td>\n",
       "      <td>327411.0</td>\n",
       "      <td>227632.0</td>\n",
       "      <td>242303.0</td>\n",
       "      <td>199832.0</td>\n",
       "      <td>160026.0</td>\n",
       "      <td>188944.0</td>\n",
       "      <td>190128.0</td>\n",
       "      <td>179044.0</td>\n",
       "      <td>168526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>197786.0</td>\n",
       "      <td>225844.0</td>\n",
       "      <td>174477.0</td>\n",
       "      <td>201823.0</td>\n",
       "      <td>198093.0</td>\n",
       "      <td>316876.0</td>\n",
       "      <td>209918.0</td>\n",
       "      <td>256259</td>\n",
       "      <td>168932.0</td>\n",
       "      <td>151482.0</td>\n",
       "      <td>...</td>\n",
       "      <td>188395.0</td>\n",
       "      <td>210060.0</td>\n",
       "      <td>214068.0</td>\n",
       "      <td>183307.0</td>\n",
       "      <td>277152.0</td>\n",
       "      <td>203981.0</td>\n",
       "      <td>232432.0</td>\n",
       "      <td>197078.0</td>\n",
       "      <td>155633.0</td>\n",
       "      <td>177966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>186190.0</td>\n",
       "      <td>190986.0</td>\n",
       "      <td>227876.0</td>\n",
       "      <td>200352.0</td>\n",
       "      <td>198597.0</td>\n",
       "      <td>264820.0</td>\n",
       "      <td>278922.0</td>\n",
       "      <td>177101</td>\n",
       "      <td>179918.0</td>\n",
       "      <td>115600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>197417.0</td>\n",
       "      <td>209481.0</td>\n",
       "      <td>329122.0</td>\n",
       "      <td>181765.0</td>\n",
       "      <td>215889.0</td>\n",
       "      <td>179724.0</td>\n",
       "      <td>207625.0</td>\n",
       "      <td>248664.0</td>\n",
       "      <td>177864.0</td>\n",
       "      <td>233863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>184755.0</td>\n",
       "      <td>199107.0</td>\n",
       "      <td>161141.0</td>\n",
       "      <td>223489.0</td>\n",
       "      <td>178796.0</td>\n",
       "      <td>188389.0</td>\n",
       "      <td>174794.0</td>\n",
       "      <td>170426</td>\n",
       "      <td>221004.0</td>\n",
       "      <td>154040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>192164.0</td>\n",
       "      <td>235251.0</td>\n",
       "      <td>240420.0</td>\n",
       "      <td>220631.0</td>\n",
       "      <td>204783.0</td>\n",
       "      <td>162188.0</td>\n",
       "      <td>232556.0</td>\n",
       "      <td>201086.0</td>\n",
       "      <td>140055.0</td>\n",
       "      <td>245915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>287313.0</td>\n",
       "      <td>278480.0</td>\n",
       "      <td>192844.0</td>\n",
       "      <td>206241.0</td>\n",
       "      <td>177384.0</td>\n",
       "      <td>232375.0</td>\n",
       "      <td>187261.0</td>\n",
       "      <td>178882</td>\n",
       "      <td>295998.0</td>\n",
       "      <td>230497.0</td>\n",
       "      <td>...</td>\n",
       "      <td>217493.0</td>\n",
       "      <td>262801.0</td>\n",
       "      <td>177127.0</td>\n",
       "      <td>188020.0</td>\n",
       "      <td>216066.0</td>\n",
       "      <td>177910.0</td>\n",
       "      <td>205727.0</td>\n",
       "      <td>219615.0</td>\n",
       "      <td>152885.0</td>\n",
       "      <td>238301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>183440.0</td>\n",
       "      <td>239319.0</td>\n",
       "      <td>207617.0</td>\n",
       "      <td>202729.0</td>\n",
       "      <td>403448.0</td>\n",
       "      <td>195218.0</td>\n",
       "      <td>366579.0</td>\n",
       "      <td>177956</td>\n",
       "      <td>198567.0</td>\n",
       "      <td>172754.0</td>\n",
       "      <td>...</td>\n",
       "      <td>185258.0</td>\n",
       "      <td>186770.0</td>\n",
       "      <td>179257.0</td>\n",
       "      <td>252735.0</td>\n",
       "      <td>191662.0</td>\n",
       "      <td>160341.0</td>\n",
       "      <td>191244.0</td>\n",
       "      <td>386733.0</td>\n",
       "      <td>185384.0</td>\n",
       "      <td>205098.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>170179.0</td>\n",
       "      <td>298456.0</td>\n",
       "      <td>186766.0</td>\n",
       "      <td>205800.0</td>\n",
       "      <td>160279.0</td>\n",
       "      <td>208609.0</td>\n",
       "      <td>171827.0</td>\n",
       "      <td>213653</td>\n",
       "      <td>186355.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>173830.0</td>\n",
       "      <td>199483.0</td>\n",
       "      <td>288901.0</td>\n",
       "      <td>167014.0</td>\n",
       "      <td>239250.0</td>\n",
       "      <td>174237.0</td>\n",
       "      <td>176839.0</td>\n",
       "      <td>256924.0</td>\n",
       "      <td>155692.0</td>\n",
       "      <td>185977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>228932.0</td>\n",
       "      <td>254720.0</td>\n",
       "      <td>201337.0</td>\n",
       "      <td>209128.0</td>\n",
       "      <td>196850.0</td>\n",
       "      <td>308954.0</td>\n",
       "      <td>181005.0</td>\n",
       "      <td>200900</td>\n",
       "      <td>189852.0</td>\n",
       "      <td>186026.0</td>\n",
       "      <td>...</td>\n",
       "      <td>185262.0</td>\n",
       "      <td>252359.0</td>\n",
       "      <td>215306.0</td>\n",
       "      <td>198728.0</td>\n",
       "      <td>240064.0</td>\n",
       "      <td>171229.0</td>\n",
       "      <td>168879.0</td>\n",
       "      <td>183877.0</td>\n",
       "      <td>162744.0</td>\n",
       "      <td>196565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>170918.0</td>\n",
       "      <td>230292.0</td>\n",
       "      <td>193491.0</td>\n",
       "      <td>246749.0</td>\n",
       "      <td>166400.0</td>\n",
       "      <td>233026.0</td>\n",
       "      <td>201936.0</td>\n",
       "      <td>167426</td>\n",
       "      <td>169447.0</td>\n",
       "      <td>231414.0</td>\n",
       "      <td>...</td>\n",
       "      <td>181438.0</td>\n",
       "      <td>181448.0</td>\n",
       "      <td>345798.0</td>\n",
       "      <td>197876.0</td>\n",
       "      <td>202276.0</td>\n",
       "      <td>176295.0</td>\n",
       "      <td>148424.0</td>\n",
       "      <td>256629.0</td>\n",
       "      <td>157893.0</td>\n",
       "      <td>197379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>193313.0</td>\n",
       "      <td>226973.0</td>\n",
       "      <td>181154.0</td>\n",
       "      <td>246327.0</td>\n",
       "      <td>161447.0</td>\n",
       "      <td>226616.0</td>\n",
       "      <td>229179.0</td>\n",
       "      <td>173974</td>\n",
       "      <td>175009.0</td>\n",
       "      <td>183801.0</td>\n",
       "      <td>...</td>\n",
       "      <td>197120.0</td>\n",
       "      <td>222765.0</td>\n",
       "      <td>313040.0</td>\n",
       "      <td>198497.0</td>\n",
       "      <td>283974.0</td>\n",
       "      <td>161507.0</td>\n",
       "      <td>173442.0</td>\n",
       "      <td>206854.0</td>\n",
       "      <td>165856.0</td>\n",
       "      <td>267115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>162745.0</td>\n",
       "      <td>228250.0</td>\n",
       "      <td>179548.0</td>\n",
       "      <td>206015.0</td>\n",
       "      <td>161969.0</td>\n",
       "      <td>202985.0</td>\n",
       "      <td>240469.0</td>\n",
       "      <td>201580</td>\n",
       "      <td>197718.0</td>\n",
       "      <td>176626.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193770.0</td>\n",
       "      <td>240332.0</td>\n",
       "      <td>254111.0</td>\n",
       "      <td>207623.0</td>\n",
       "      <td>191688.0</td>\n",
       "      <td>153143.0</td>\n",
       "      <td>213220.0</td>\n",
       "      <td>198518.0</td>\n",
       "      <td>202737.0</td>\n",
       "      <td>613407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>180992.0</td>\n",
       "      <td>213792.0</td>\n",
       "      <td>178236.0</td>\n",
       "      <td>222506.0</td>\n",
       "      <td>146313.0</td>\n",
       "      <td>182839.0</td>\n",
       "      <td>247629.0</td>\n",
       "      <td>185905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158716.0</td>\n",
       "      <td>...</td>\n",
       "      <td>186221.0</td>\n",
       "      <td>249297.0</td>\n",
       "      <td>273863.0</td>\n",
       "      <td>209971.0</td>\n",
       "      <td>231231.0</td>\n",
       "      <td>165020.0</td>\n",
       "      <td>191480.0</td>\n",
       "      <td>195936.0</td>\n",
       "      <td>156980.0</td>\n",
       "      <td>180861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>192962.0</td>\n",
       "      <td>248159.0</td>\n",
       "      <td>162032.0</td>\n",
       "      <td>350614.0</td>\n",
       "      <td>153342.0</td>\n",
       "      <td>162805.0</td>\n",
       "      <td>199464.0</td>\n",
       "      <td>180678</td>\n",
       "      <td>202443.0</td>\n",
       "      <td>157730.0</td>\n",
       "      <td>...</td>\n",
       "      <td>183775.0</td>\n",
       "      <td>385076.0</td>\n",
       "      <td>250705.0</td>\n",
       "      <td>240947.0</td>\n",
       "      <td>289082.0</td>\n",
       "      <td>159901.0</td>\n",
       "      <td>188125.0</td>\n",
       "      <td>234745.0</td>\n",
       "      <td>203496.0</td>\n",
       "      <td>182484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>206849.0</td>\n",
       "      <td>223159.0</td>\n",
       "      <td>456162.0</td>\n",
       "      <td>189013.0</td>\n",
       "      <td>160666.0</td>\n",
       "      <td>210370.0</td>\n",
       "      <td>330455.0</td>\n",
       "      <td>176907</td>\n",
       "      <td>160874.0</td>\n",
       "      <td>328838.0</td>\n",
       "      <td>...</td>\n",
       "      <td>203854.0</td>\n",
       "      <td>210911.0</td>\n",
       "      <td>402476.0</td>\n",
       "      <td>201497.0</td>\n",
       "      <td>224711.0</td>\n",
       "      <td>147590.0</td>\n",
       "      <td>156406.0</td>\n",
       "      <td>204623.0</td>\n",
       "      <td>150310.0</td>\n",
       "      <td>193207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>199571.0</td>\n",
       "      <td>198094.0</td>\n",
       "      <td>196006.0</td>\n",
       "      <td>175392.0</td>\n",
       "      <td>162493.0</td>\n",
       "      <td>190678.0</td>\n",
       "      <td>206245.0</td>\n",
       "      <td>166541</td>\n",
       "      <td>205105.0</td>\n",
       "      <td>164154.0</td>\n",
       "      <td>...</td>\n",
       "      <td>146216.0</td>\n",
       "      <td>229445.0</td>\n",
       "      <td>257565.0</td>\n",
       "      <td>206539.0</td>\n",
       "      <td>203184.0</td>\n",
       "      <td>195464.0</td>\n",
       "      <td>184086.0</td>\n",
       "      <td>255500.0</td>\n",
       "      <td>173139.0</td>\n",
       "      <td>192181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>424669.0</td>\n",
       "      <td>237763.0</td>\n",
       "      <td>167689.0</td>\n",
       "      <td>193912.0</td>\n",
       "      <td>133073.0</td>\n",
       "      <td>194593.0</td>\n",
       "      <td>206692.0</td>\n",
       "      <td>158029</td>\n",
       "      <td>221404.0</td>\n",
       "      <td>175910.0</td>\n",
       "      <td>...</td>\n",
       "      <td>187805.0</td>\n",
       "      <td>211091.0</td>\n",
       "      <td>324236.0</td>\n",
       "      <td>190508.0</td>\n",
       "      <td>203358.0</td>\n",
       "      <td>156273.0</td>\n",
       "      <td>181296.0</td>\n",
       "      <td>229640.0</td>\n",
       "      <td>167467.0</td>\n",
       "      <td>195436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>219317.0</td>\n",
       "      <td>248977.0</td>\n",
       "      <td>191538.0</td>\n",
       "      <td>177129.0</td>\n",
       "      <td>151759.0</td>\n",
       "      <td>206803.0</td>\n",
       "      <td>247604.0</td>\n",
       "      <td>157104</td>\n",
       "      <td>174571.0</td>\n",
       "      <td>236730.0</td>\n",
       "      <td>...</td>\n",
       "      <td>192188.0</td>\n",
       "      <td>235299.0</td>\n",
       "      <td>221073.0</td>\n",
       "      <td>216970.0</td>\n",
       "      <td>335060.0</td>\n",
       "      <td>164800.0</td>\n",
       "      <td>261980.0</td>\n",
       "      <td>198508.0</td>\n",
       "      <td>184420.0</td>\n",
       "      <td>190820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>210600.0</td>\n",
       "      <td>188710.0</td>\n",
       "      <td>163312.0</td>\n",
       "      <td>206364.0</td>\n",
       "      <td>206340.0</td>\n",
       "      <td>346281.0</td>\n",
       "      <td>196945.0</td>\n",
       "      <td>181933</td>\n",
       "      <td>226960.0</td>\n",
       "      <td>152013.0</td>\n",
       "      <td>...</td>\n",
       "      <td>202988.0</td>\n",
       "      <td>192231.0</td>\n",
       "      <td>233546.0</td>\n",
       "      <td>180714.0</td>\n",
       "      <td>234675.0</td>\n",
       "      <td>187811.0</td>\n",
       "      <td>179273.0</td>\n",
       "      <td>158420.0</td>\n",
       "      <td>183590.0</td>\n",
       "      <td>194135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>186352.0</td>\n",
       "      <td>222878.0</td>\n",
       "      <td>159890.0</td>\n",
       "      <td>202743.0</td>\n",
       "      <td>155456.0</td>\n",
       "      <td>183758.0</td>\n",
       "      <td>191262.0</td>\n",
       "      <td>181408</td>\n",
       "      <td>215239.0</td>\n",
       "      <td>138535.0</td>\n",
       "      <td>...</td>\n",
       "      <td>223866.0</td>\n",
       "      <td>241048.0</td>\n",
       "      <td>394911.0</td>\n",
       "      <td>280442.0</td>\n",
       "      <td>218073.0</td>\n",
       "      <td>187292.0</td>\n",
       "      <td>192284.0</td>\n",
       "      <td>199668.0</td>\n",
       "      <td>226023.0</td>\n",
       "      <td>188312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>176071.0</td>\n",
       "      <td>253812.0</td>\n",
       "      <td>235230.0</td>\n",
       "      <td>222590.0</td>\n",
       "      <td>171706.0</td>\n",
       "      <td>277436.0</td>\n",
       "      <td>174825.0</td>\n",
       "      <td>179792</td>\n",
       "      <td>240936.0</td>\n",
       "      <td>176518.0</td>\n",
       "      <td>...</td>\n",
       "      <td>178239.0</td>\n",
       "      <td>242303.0</td>\n",
       "      <td>256514.0</td>\n",
       "      <td>206894.0</td>\n",
       "      <td>426563.0</td>\n",
       "      <td>221020.0</td>\n",
       "      <td>241833.0</td>\n",
       "      <td>211098.0</td>\n",
       "      <td>173187.0</td>\n",
       "      <td>236206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>230986.0</td>\n",
       "      <td>190380.0</td>\n",
       "      <td>309805.0</td>\n",
       "      <td>209486.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256787.0</td>\n",
       "      <td>217055.0</td>\n",
       "      <td>223969</td>\n",
       "      <td>192967.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>159937.0</td>\n",
       "      <td>194044.0</td>\n",
       "      <td>313980.0</td>\n",
       "      <td>258217.0</td>\n",
       "      <td>216514.0</td>\n",
       "      <td>172861.0</td>\n",
       "      <td>163571.0</td>\n",
       "      <td>242804.0</td>\n",
       "      <td>171946.0</td>\n",
       "      <td>279062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>183005.0</td>\n",
       "      <td>233737.0</td>\n",
       "      <td>203266.0</td>\n",
       "      <td>204397.0</td>\n",
       "      <td>161445.0</td>\n",
       "      <td>223134.0</td>\n",
       "      <td>236322.0</td>\n",
       "      <td>160011</td>\n",
       "      <td>190125.0</td>\n",
       "      <td>169635.0</td>\n",
       "      <td>...</td>\n",
       "      <td>171350.0</td>\n",
       "      <td>230038.0</td>\n",
       "      <td>267874.0</td>\n",
       "      <td>205107.0</td>\n",
       "      <td>200844.0</td>\n",
       "      <td>156666.0</td>\n",
       "      <td>191949.0</td>\n",
       "      <td>229211.0</td>\n",
       "      <td>193625.0</td>\n",
       "      <td>225694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>242763.0</td>\n",
       "      <td>208334.0</td>\n",
       "      <td>191371.0</td>\n",
       "      <td>247494.0</td>\n",
       "      <td>155474.0</td>\n",
       "      <td>586621.0</td>\n",
       "      <td>212540.0</td>\n",
       "      <td>238406</td>\n",
       "      <td>262258.0</td>\n",
       "      <td>190701.0</td>\n",
       "      <td>...</td>\n",
       "      <td>180215.0</td>\n",
       "      <td>200580.0</td>\n",
       "      <td>301423.0</td>\n",
       "      <td>277105.0</td>\n",
       "      <td>225240.0</td>\n",
       "      <td>152191.0</td>\n",
       "      <td>188024.0</td>\n",
       "      <td>190848.0</td>\n",
       "      <td>189560.0</td>\n",
       "      <td>215061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>201507.0</td>\n",
       "      <td>216327.0</td>\n",
       "      <td>162364.0</td>\n",
       "      <td>207731.0</td>\n",
       "      <td>164974.0</td>\n",
       "      <td>274212.0</td>\n",
       "      <td>189927.0</td>\n",
       "      <td>168135</td>\n",
       "      <td>197586.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>206490.0</td>\n",
       "      <td>216994.0</td>\n",
       "      <td>276191.0</td>\n",
       "      <td>208004.0</td>\n",
       "      <td>205637.0</td>\n",
       "      <td>204761.0</td>\n",
       "      <td>184681.0</td>\n",
       "      <td>193227.0</td>\n",
       "      <td>179018.0</td>\n",
       "      <td>291675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>213118.0</td>\n",
       "      <td>197164.0</td>\n",
       "      <td>173492.0</td>\n",
       "      <td>184750.0</td>\n",
       "      <td>145803.0</td>\n",
       "      <td>396621.0</td>\n",
       "      <td>202268.0</td>\n",
       "      <td>208783</td>\n",
       "      <td>261854.0</td>\n",
       "      <td>168999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>207835.0</td>\n",
       "      <td>208604.0</td>\n",
       "      <td>403696.0</td>\n",
       "      <td>201365.0</td>\n",
       "      <td>193115.0</td>\n",
       "      <td>188893.0</td>\n",
       "      <td>206289.0</td>\n",
       "      <td>192162.0</td>\n",
       "      <td>180819.0</td>\n",
       "      <td>254296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>199156.0</td>\n",
       "      <td>174536.0</td>\n",
       "      <td>195672.0</td>\n",
       "      <td>233916.0</td>\n",
       "      <td>151610.0</td>\n",
       "      <td>258074.0</td>\n",
       "      <td>191941.0</td>\n",
       "      <td>196878</td>\n",
       "      <td>244884.0</td>\n",
       "      <td>185476.0</td>\n",
       "      <td>...</td>\n",
       "      <td>162920.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280288.0</td>\n",
       "      <td>235610.0</td>\n",
       "      <td>213509.0</td>\n",
       "      <td>156922.0</td>\n",
       "      <td>181953.0</td>\n",
       "      <td>221596.0</td>\n",
       "      <td>231590.0</td>\n",
       "      <td>260821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>275056.0</td>\n",
       "      <td>241454.0</td>\n",
       "      <td>167883.0</td>\n",
       "      <td>318130.0</td>\n",
       "      <td>149091.0</td>\n",
       "      <td>196315.0</td>\n",
       "      <td>196941.0</td>\n",
       "      <td>227003</td>\n",
       "      <td>200373.0</td>\n",
       "      <td>176060.0</td>\n",
       "      <td>...</td>\n",
       "      <td>199302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>244239.0</td>\n",
       "      <td>182508.0</td>\n",
       "      <td>185394.0</td>\n",
       "      <td>184641.0</td>\n",
       "      <td>186023.0</td>\n",
       "      <td>182348.0</td>\n",
       "      <td>186522.0</td>\n",
       "      <td>331297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>237057.0</td>\n",
       "      <td>284076.0</td>\n",
       "      <td>488581.0</td>\n",
       "      <td>217341.0</td>\n",
       "      <td>152305.0</td>\n",
       "      <td>246975.0</td>\n",
       "      <td>201187.0</td>\n",
       "      <td>188476</td>\n",
       "      <td>235158.0</td>\n",
       "      <td>227540.0</td>\n",
       "      <td>...</td>\n",
       "      <td>190991.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185014.0</td>\n",
       "      <td>157883.0</td>\n",
       "      <td>228910.0</td>\n",
       "      <td>199227.0</td>\n",
       "      <td>203207.0</td>\n",
       "      <td>191232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>183100.0</td>\n",
       "      <td>249164.0</td>\n",
       "      <td>310119.0</td>\n",
       "      <td>207513.0</td>\n",
       "      <td>173887.0</td>\n",
       "      <td>244278.0</td>\n",
       "      <td>328923.0</td>\n",
       "      <td>162886</td>\n",
       "      <td>233631.0</td>\n",
       "      <td>195289.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>226440.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188372.0</td>\n",
       "      <td>225798.0</td>\n",
       "      <td>182011.0</td>\n",
       "      <td>210420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>192963.0</td>\n",
       "      <td>242866.0</td>\n",
       "      <td>284390.0</td>\n",
       "      <td>209229.0</td>\n",
       "      <td>160802.0</td>\n",
       "      <td>221299.0</td>\n",
       "      <td>197061.0</td>\n",
       "      <td>298522</td>\n",
       "      <td>235144.0</td>\n",
       "      <td>167179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208054.0</td>\n",
       "      <td>309072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>270406.0</td>\n",
       "      <td>421483.0</td>\n",
       "      <td>231455.0</td>\n",
       "      <td>177683.0</td>\n",
       "      <td>168195.0</td>\n",
       "      <td>253444.0</td>\n",
       "      <td>203932.0</td>\n",
       "      <td>164720</td>\n",
       "      <td>290388.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215343.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198179.0</td>\n",
       "      <td>390790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>188295.0</td>\n",
       "      <td>246092.0</td>\n",
       "      <td>191126.0</td>\n",
       "      <td>184432.0</td>\n",
       "      <td>320182.0</td>\n",
       "      <td>243880.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167869</td>\n",
       "      <td>181413.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185148.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193271.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189543.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188950</td>\n",
       "      <td>372462.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217058.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Yariel     David    Vineet    Edward     Carol       Joy  Sharvill  \\\n",
       "0   204858.0  364157.0  166236.0  176878.0  177511.0  246339.0  207490.0   \n",
       "1   286286.0  192116.0  152356.0  186854.0  156647.0  186510.0  231224.0   \n",
       "2   218850.0  182751.0  157459.0  180379.0  171744.0  231041.0  201460.0   \n",
       "3   163842.0  196590.0  168879.0  181845.0  172564.0  267405.0  263652.0   \n",
       "4   208936.0  343780.0  174007.0  200305.0  173469.0  219968.0  188061.0   \n",
       "5   210772.0  195063.0  192230.0  108443.0  166916.0  224149.0  254707.0   \n",
       "6   131447.0  242795.0  189787.0  197407.0  164499.0  263395.0  300124.0   \n",
       "7   242224.0  195479.0  149246.0  187073.0  169239.0  244945.0  172624.0   \n",
       "8   206926.0  204261.0  154905.0  203213.0  203443.0  246524.0  188363.0   \n",
       "9   206689.0  193601.0  148615.0  222111.0  205669.0  231938.0  166599.0   \n",
       "10  206496.0  228048.0  220956.0  213196.0  165719.0  211540.0  183328.0   \n",
       "11  218458.0  254455.0  186114.0  210735.0  172717.0  215465.0  220336.0   \n",
       "12  197786.0  225844.0  174477.0  201823.0  198093.0  316876.0  209918.0   \n",
       "13  186190.0  190986.0  227876.0  200352.0  198597.0  264820.0  278922.0   \n",
       "14  184755.0  199107.0  161141.0  223489.0  178796.0  188389.0  174794.0   \n",
       "15  287313.0  278480.0  192844.0  206241.0  177384.0  232375.0  187261.0   \n",
       "16  183440.0  239319.0  207617.0  202729.0  403448.0  195218.0  366579.0   \n",
       "17  170179.0  298456.0  186766.0  205800.0  160279.0  208609.0  171827.0   \n",
       "18  228932.0  254720.0  201337.0  209128.0  196850.0  308954.0  181005.0   \n",
       "19  170918.0  230292.0  193491.0  246749.0  166400.0  233026.0  201936.0   \n",
       "20  193313.0  226973.0  181154.0  246327.0  161447.0  226616.0  229179.0   \n",
       "21  162745.0  228250.0  179548.0  206015.0  161969.0  202985.0  240469.0   \n",
       "22  180992.0  213792.0  178236.0  222506.0  146313.0  182839.0  247629.0   \n",
       "23  192962.0  248159.0  162032.0  350614.0  153342.0  162805.0  199464.0   \n",
       "24  206849.0  223159.0  456162.0  189013.0  160666.0  210370.0  330455.0   \n",
       "25  199571.0  198094.0  196006.0  175392.0  162493.0  190678.0  206245.0   \n",
       "26  424669.0  237763.0  167689.0  193912.0  133073.0  194593.0  206692.0   \n",
       "27  219317.0  248977.0  191538.0  177129.0  151759.0  206803.0  247604.0   \n",
       "28  210600.0  188710.0  163312.0  206364.0  206340.0  346281.0  196945.0   \n",
       "29  186352.0  222878.0  159890.0  202743.0  155456.0  183758.0  191262.0   \n",
       "30  176071.0  253812.0  235230.0  222590.0  171706.0  277436.0  174825.0   \n",
       "31  230986.0  190380.0  309805.0  209486.0       NaN  256787.0  217055.0   \n",
       "32  183005.0  233737.0  203266.0  204397.0  161445.0  223134.0  236322.0   \n",
       "33  242763.0  208334.0  191371.0  247494.0  155474.0  586621.0  212540.0   \n",
       "34  201507.0  216327.0  162364.0  207731.0  164974.0  274212.0  189927.0   \n",
       "35  213118.0  197164.0  173492.0  184750.0  145803.0  396621.0  202268.0   \n",
       "36  199156.0  174536.0  195672.0  233916.0  151610.0  258074.0  191941.0   \n",
       "37  275056.0  241454.0  167883.0  318130.0  149091.0  196315.0  196941.0   \n",
       "38  237057.0  284076.0  488581.0  217341.0  152305.0  246975.0  201187.0   \n",
       "39  183100.0  249164.0  310119.0  207513.0  173887.0  244278.0  328923.0   \n",
       "40  192963.0  242866.0  284390.0  209229.0  160802.0  221299.0  197061.0   \n",
       "41  270406.0  421483.0  231455.0  177683.0  168195.0  253444.0  203932.0   \n",
       "42  188295.0  246092.0  191126.0  184432.0  320182.0  243880.0       NaN   \n",
       "43       NaN       NaN  193271.0       NaN  189543.0       NaN       NaN   \n",
       "44       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "45       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "    Esteban    Pratik       Adi    ...      Mariela      Anna    Elaine  \\\n",
       "0    160615  188794.0  338060.0    ...     239258.0  275761.0  194375.0   \n",
       "1    209885  320636.0  191325.0    ...     204884.0  211233.0  198578.0   \n",
       "2    175562  184062.0  258132.0    ...     190111.0  203972.0  177845.0   \n",
       "3    245080  227252.0  147160.0    ...     189049.0  286162.0  266463.0   \n",
       "4    165761  222538.0  154752.0    ...     197249.0  208546.0  338828.0   \n",
       "5    174758  186490.0  154725.0    ...     220115.0  201558.0  231795.0   \n",
       "6    170393  162079.0  148730.0    ...     175130.0  242530.0  185890.0   \n",
       "7    137429  167592.0  161314.0    ...     188821.0  243939.0  192148.0   \n",
       "8    159498  219369.0       NaN    ...     192073.0  195800.0  184634.0   \n",
       "9    183652  163588.0  233924.0    ...     210252.0  196837.0  243295.0   \n",
       "10   160102  161151.0  166299.0    ...     171061.0  252035.0  183755.0   \n",
       "11   154805  190377.0  232174.0    ...     176472.0  327411.0  227632.0   \n",
       "12   256259  168932.0  151482.0    ...     188395.0  210060.0  214068.0   \n",
       "13   177101  179918.0  115600.0    ...     197417.0  209481.0  329122.0   \n",
       "14   170426  221004.0  154040.0    ...     192164.0  235251.0  240420.0   \n",
       "15   178882  295998.0  230497.0    ...     217493.0  262801.0  177127.0   \n",
       "16   177956  198567.0  172754.0    ...     185258.0  186770.0  179257.0   \n",
       "17   213653  186355.0       NaN    ...     173830.0  199483.0  288901.0   \n",
       "18   200900  189852.0  186026.0    ...     185262.0  252359.0  215306.0   \n",
       "19   167426  169447.0  231414.0    ...     181438.0  181448.0  345798.0   \n",
       "20   173974  175009.0  183801.0    ...     197120.0  222765.0  313040.0   \n",
       "21   201580  197718.0  176626.0    ...     193770.0  240332.0  254111.0   \n",
       "22   185905       NaN  158716.0    ...     186221.0  249297.0  273863.0   \n",
       "23   180678  202443.0  157730.0    ...     183775.0  385076.0  250705.0   \n",
       "24   176907  160874.0  328838.0    ...     203854.0  210911.0  402476.0   \n",
       "25   166541  205105.0  164154.0    ...     146216.0  229445.0  257565.0   \n",
       "26   158029  221404.0  175910.0    ...     187805.0  211091.0  324236.0   \n",
       "27   157104  174571.0  236730.0    ...     192188.0  235299.0  221073.0   \n",
       "28   181933  226960.0  152013.0    ...     202988.0  192231.0  233546.0   \n",
       "29   181408  215239.0  138535.0    ...     223866.0  241048.0  394911.0   \n",
       "30   179792  240936.0  176518.0    ...     178239.0  242303.0  256514.0   \n",
       "31   223969  192967.0       NaN    ...     159937.0  194044.0  313980.0   \n",
       "32   160011  190125.0  169635.0    ...     171350.0  230038.0  267874.0   \n",
       "33   238406  262258.0  190701.0    ...     180215.0  200580.0  301423.0   \n",
       "34   168135  197586.0       NaN    ...     206490.0  216994.0  276191.0   \n",
       "35   208783  261854.0  168999.0    ...     207835.0  208604.0  403696.0   \n",
       "36   196878  244884.0  185476.0    ...     162920.0       NaN  280288.0   \n",
       "37   227003  200373.0  176060.0    ...     199302.0       NaN  244239.0   \n",
       "38   188476  235158.0  227540.0    ...     190991.0       NaN  241120.0   \n",
       "39   162886  233631.0  195289.0    ...          NaN       NaN  226440.0   \n",
       "40   298522  235144.0  167179.0    ...          NaN       NaN       NaN   \n",
       "41   164720  290388.0       NaN    ...          NaN       NaN       NaN   \n",
       "42   167869  181413.0       NaN    ...          NaN       NaN       NaN   \n",
       "43   188950  372462.0       NaN    ...          NaN       NaN       NaN   \n",
       "44   188357       NaN       NaN    ...          NaN       NaN       NaN   \n",
       "45   201690       NaN       NaN    ...          NaN       NaN       NaN   \n",
       "\n",
       "      Harris    Vishal     Shuen     Varun  Other Joy    Govind      Suat  \n",
       "0   221375.0  275799.0  167600.0  197411.0   274350.0  187549.0  270668.0  \n",
       "1   194432.0  233790.0  222927.0  213023.0   274225.0  158480.0  194416.0  \n",
       "2   174891.0  232681.0  177871.0  232769.0   312815.0  137907.0  276626.0  \n",
       "3   179105.0  243393.0  172624.0  191787.0   198443.0  147181.0  216204.0  \n",
       "4   218150.0  271968.0  249035.0  178604.0   228269.0  158118.0  203442.0  \n",
       "5   175533.0  217959.0  158417.0  216833.0   204818.0  145790.0  282655.0  \n",
       "6   199114.0  212915.0  174977.0  198419.0   351328.0  145879.0  237962.0  \n",
       "7   169271.0  214583.0  172871.0  217859.0   208311.0  170279.0  236491.0  \n",
       "8   190789.0  254876.0  170337.0  198661.0   205307.0  163899.0  214765.0  \n",
       "9   218184.0  242976.0  174330.0  221238.0   231338.0  216986.0  213015.0  \n",
       "10  193939.0  229084.0  164030.0  207392.0   205176.0  181427.0  226710.0  \n",
       "11  242303.0  199832.0  160026.0  188944.0   190128.0  179044.0  168526.0  \n",
       "12  183307.0  277152.0  203981.0  232432.0   197078.0  155633.0  177966.0  \n",
       "13  181765.0  215889.0  179724.0  207625.0   248664.0  177864.0  233863.0  \n",
       "14  220631.0  204783.0  162188.0  232556.0   201086.0  140055.0  245915.0  \n",
       "15  188020.0  216066.0  177910.0  205727.0   219615.0  152885.0  238301.0  \n",
       "16  252735.0  191662.0  160341.0  191244.0   386733.0  185384.0  205098.0  \n",
       "17  167014.0  239250.0  174237.0  176839.0   256924.0  155692.0  185977.0  \n",
       "18  198728.0  240064.0  171229.0  168879.0   183877.0  162744.0  196565.0  \n",
       "19  197876.0  202276.0  176295.0  148424.0   256629.0  157893.0  197379.0  \n",
       "20  198497.0  283974.0  161507.0  173442.0   206854.0  165856.0  267115.0  \n",
       "21  207623.0  191688.0  153143.0  213220.0   198518.0  202737.0  613407.0  \n",
       "22  209971.0  231231.0  165020.0  191480.0   195936.0  156980.0  180861.0  \n",
       "23  240947.0  289082.0  159901.0  188125.0   234745.0  203496.0  182484.0  \n",
       "24  201497.0  224711.0  147590.0  156406.0   204623.0  150310.0  193207.0  \n",
       "25  206539.0  203184.0  195464.0  184086.0   255500.0  173139.0  192181.0  \n",
       "26  190508.0  203358.0  156273.0  181296.0   229640.0  167467.0  195436.0  \n",
       "27  216970.0  335060.0  164800.0  261980.0   198508.0  184420.0  190820.0  \n",
       "28  180714.0  234675.0  187811.0  179273.0   158420.0  183590.0  194135.0  \n",
       "29  280442.0  218073.0  187292.0  192284.0   199668.0  226023.0  188312.0  \n",
       "30  206894.0  426563.0  221020.0  241833.0   211098.0  173187.0  236206.0  \n",
       "31  258217.0  216514.0  172861.0  163571.0   242804.0  171946.0  279062.0  \n",
       "32  205107.0  200844.0  156666.0  191949.0   229211.0  193625.0  225694.0  \n",
       "33  277105.0  225240.0  152191.0  188024.0   190848.0  189560.0  215061.0  \n",
       "34  208004.0  205637.0  204761.0  184681.0   193227.0  179018.0  291675.0  \n",
       "35  201365.0  193115.0  188893.0  206289.0   192162.0  180819.0  254296.0  \n",
       "36  235610.0  213509.0  156922.0  181953.0   221596.0  231590.0  260821.0  \n",
       "37  182508.0  185394.0  184641.0  186023.0   182348.0  186522.0  331297.0  \n",
       "38       NaN  185014.0  157883.0  228910.0   199227.0  203207.0  191232.0  \n",
       "39       NaN       NaN       NaN  188372.0   225798.0  182011.0  210420.0  \n",
       "40       NaN       NaN       NaN  164176.0        NaN  208054.0  309072.0  \n",
       "41       NaN       NaN       NaN  215343.0        NaN  198179.0  390790.0  \n",
       "42       NaN       NaN       NaN  185148.0        NaN       NaN  278688.0  \n",
       "43       NaN       NaN       NaN       NaN        NaN       NaN  217058.0  \n",
       "44       NaN       NaN       NaN       NaN        NaN       NaN       NaN  \n",
       "45       NaN       NaN       NaN       NaN        NaN       NaN       NaN  \n",
       "\n",
       "[46 rows x 23 columns]"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PVT_data2 = pd.read_csv(\"PVT data - Sheet2.csv\")\n",
    "PVT_data2 = PVT_data2[PVT_data2 > 100000]\n",
    "PVT_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PVT_data['mean'] = PVT_data.mean(axis=1)\n",
    "# PVT_data['median'] = PVT_data.median(axis=1)\n",
    "# PVT_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = pd.DataFrame.mean(PVT_data2)\n",
    "# print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = pd.DataFrame.median(mean)\n",
    "# print(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yariel        True\n",
      "David         True\n",
      "Vineet       False\n",
      "Edward       False\n",
      "Carol        False\n",
      "Joy           True\n",
      "Sharvill      True\n",
      "Esteban      False\n",
      "Pratik        True\n",
      "Adi          False\n",
      "Alex          True\n",
      "Odessa       False\n",
      "Shreya       False\n",
      "Mariela      False\n",
      "Anna          True\n",
      "Elaine        True\n",
      "Harris       False\n",
      "Vishal        True\n",
      "Shuen        False\n",
      "Varun        False\n",
      "Other Joy     True\n",
      "Govind       False\n",
      "Suat          True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "label = mean > median\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5., 3., 6., 3., 5., 1.]),\n",
       " array([175527.92307692, 189408.8025641 , 203289.68205128, 217170.56153846,\n",
       "        231051.44102564, 244932.32051282, 258813.2       ]),\n",
       " <a list of 6 Patch objects>)"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mean, bins=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>sleep</th>\n",
       "      <th>fatigue scale</th>\n",
       "      <th>exercise(min)</th>\n",
       "      <th>eating scale</th>\n",
       "      <th>stress scale</th>\n",
       "      <th>caffeine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anna</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elaine</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mariela</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harris</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oddessa</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shreya</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Varun</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Joy Liu</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vishal</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shuen</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Govind</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Suat</td>\n",
       "      <td>4.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>David</td>\n",
       "      <td>6.25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yariel</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Joy Lim</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>45</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Edward</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>150</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Carol</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>45</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vineet</td>\n",
       "      <td>8.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pratik</td>\n",
       "      <td>6.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sharvil</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>180</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Alex</td>\n",
       "      <td>7.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Esteban</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Aadi</td>\n",
       "      <td>4.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>107</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  sleep  fatigue scale  exercise(min)  eating scale  stress scale  \\\n",
       "0      Anna   7.00            7.0              0           8.0           3.0   \n",
       "1    Elaine   8.00            4.0              0           3.0           7.0   \n",
       "2   Mariela   4.00            4.0              0           5.0           1.0   \n",
       "3    Harris   6.00            6.0             15           6.0           3.0   \n",
       "4   Oddessa   5.50            6.0             30           7.0           7.0   \n",
       "5    Shreya   8.00            2.0             60           9.0           1.0   \n",
       "6     Varun   6.00            3.0              0           9.0           2.0   \n",
       "7   Joy Liu   6.50            5.0             10          10.0           8.0   \n",
       "8    Vishal   6.00            3.0              0           8.0           3.0   \n",
       "9     Shuen   4.00            8.0              0           4.0           7.0   \n",
       "10   Govind   4.00            3.0              0           8.0           8.0   \n",
       "11     Suat   4.50            6.0              0           7.0           1.0   \n",
       "12   David    6.25            8.0              0           9.5           7.0   \n",
       "13   Yariel   6.00            6.0              0           3.0           6.0   \n",
       "14  Joy Lim   5.00            6.5             45           7.0           6.0   \n",
       "15   Edward   7.00            7.0            150           9.0           8.0   \n",
       "16    Carol   7.00            3.5             45           4.0           3.5   \n",
       "17   Vineet   8.00            5.0             30           4.0           6.0   \n",
       "18   Pratik   6.50            8.0             70           9.0           2.0   \n",
       "19  Sharvil   6.00            5.0            180           5.0           6.0   \n",
       "20     Alex   7.50            8.0            300           5.0           4.0   \n",
       "21  Esteban   6.00            3.0            120           6.0           1.0   \n",
       "22     Aadi   4.50            6.0            107          10.0           3.0   \n",
       "\n",
       "    caffeine   \n",
       "0        0.00  \n",
       "1        1.00  \n",
       "2        0.00  \n",
       "3        0.00  \n",
       "4        2.00  \n",
       "5        0.00  \n",
       "6        0.00  \n",
       "7        0.50  \n",
       "8        0.00  \n",
       "9        1.00  \n",
       "10       0.00  \n",
       "11       0.00  \n",
       "12       2.50  \n",
       "13       5.50  \n",
       "14       0.00  \n",
       "15       0.00  \n",
       "16       0.75  \n",
       "17       0.00  \n",
       "18       0.00  \n",
       "19       0.00  \n",
       "20       0.00  \n",
       "21       1.00  \n",
       "22       0.00  "
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cognitive_Fatigue_Data = pd.read_csv(\"Cognitive_Fatigue_Data.csv\")\n",
    "Cognitive_Fatigue_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment name:</th>\n",
       "      <th>NeuLog experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Duration:</td>\n",
       "      <td>2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rate:</td>\n",
       "      <td>50 per second</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sensors:</td>\n",
       "      <td>Pulse (ID 1  Exp 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Range:</td>\n",
       "      <td>Wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Units:</td>\n",
       "      <td>Arb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Time</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'0:0:0.0</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'0:0:0.02</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'0:0:0.04</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'0:0:0.06</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'0:0:0.08</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'0:0:0.1</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'0:0:0.12</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'0:0:0.14</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'0:0:0.16</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'0:0:0.18</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'0:0:0.2</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'0:0:0.22</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'0:0:0.24</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'0:0:0.26</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>'0:0:0.28</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>'0:0:0.3</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'0:0:0.32</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>'0:0:0.34</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'0:0:0.36</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'0:0:0.38</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>'0:0:0.4</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>'0:0:0.42</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>'0:0:0.44</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>'0:0:0.46</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>'0:1:59.46</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>'0:1:59.48</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>'0:1:59.5</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5982</th>\n",
       "      <td>'0:1:59.52</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>'0:1:59.54</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>'0:1:59.56</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>'0:1:59.58</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>'0:1:59.6</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5987</th>\n",
       "      <td>'0:1:59.62</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5988</th>\n",
       "      <td>'0:1:59.64</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>'0:1:59.66</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5990</th>\n",
       "      <td>'0:1:59.68</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991</th>\n",
       "      <td>'0:1:59.7</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>'0:1:59.72</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>'0:1:59.74</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>'0:1:59.76</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>'0:1:59.78</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>'0:1:59.8</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>'0:1:59.82</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>'0:1:59.84</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>'0:1:59.86</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>'0:1:59.88</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6001</th>\n",
       "      <td>'0:1:59.9</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002</th>\n",
       "      <td>'0:1:59.92</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003</th>\n",
       "      <td>'0:1:59.94</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>'0:1:59.96</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>'0:1:59.98</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6006</th>\n",
       "      <td>'0:1:60.0</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007</th>\n",
       "      <td>sys info:[91~54~52~93~44~91~34~56~126~49~126~4...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6008</th>\n",
       "      <td>Attention! Any change in the file may prevent ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6009 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Experiment name:     NeuLog experiment\n",
       "0                                             Duration:                   2 0\n",
       "1                                                 Rate:         50 per second\n",
       "2                                              Sensors:   Pulse (ID 1  Exp 1)\n",
       "3                                                Range:                  Wave\n",
       "4                                                Units:                   Arb\n",
       "5                                                  Time                   NaN\n",
       "6                                              '0:0:0.0                   443\n",
       "7                                             '0:0:0.02                   435\n",
       "8                                             '0:0:0.04                   417\n",
       "9                                             '0:0:0.06                   410\n",
       "10                                            '0:0:0.08                   404\n",
       "11                                             '0:0:0.1                   400\n",
       "12                                            '0:0:0.12                   395\n",
       "13                                            '0:0:0.14                   391\n",
       "14                                            '0:0:0.16                   390\n",
       "15                                            '0:0:0.18                   390\n",
       "16                                             '0:0:0.2                   393\n",
       "17                                            '0:0:0.22                   400\n",
       "18                                            '0:0:0.24                   405\n",
       "19                                            '0:0:0.26                   409\n",
       "20                                            '0:0:0.28                   409\n",
       "21                                             '0:0:0.3                   405\n",
       "22                                            '0:0:0.32                   401\n",
       "23                                            '0:0:0.34                   396\n",
       "24                                            '0:0:0.36                   394\n",
       "25                                            '0:0:0.38                   392\n",
       "26                                             '0:0:0.4                   390\n",
       "27                                            '0:0:0.42                   388\n",
       "28                                            '0:0:0.44                   389\n",
       "29                                            '0:0:0.46                   392\n",
       "...                                                 ...                   ...\n",
       "5979                                         '0:1:59.46                   356\n",
       "5980                                         '0:1:59.48                   357\n",
       "5981                                          '0:1:59.5                   359\n",
       "5982                                         '0:1:59.52                   361\n",
       "5983                                         '0:1:59.54                   373\n",
       "5984                                         '0:1:59.56                   394\n",
       "5985                                         '0:1:59.58                   416\n",
       "5986                                          '0:1:59.6                   429\n",
       "5987                                         '0:1:59.62                   429\n",
       "5988                                         '0:1:59.64                   420\n",
       "5989                                         '0:1:59.66                   407\n",
       "5990                                         '0:1:59.68                   391\n",
       "5991                                          '0:1:59.7                   377\n",
       "5992                                         '0:1:59.72                   364\n",
       "5993                                         '0:1:59.74                   354\n",
       "5994                                         '0:1:59.76                   347\n",
       "5995                                         '0:1:59.78                   347\n",
       "5996                                          '0:1:59.8                   353\n",
       "5997                                         '0:1:59.82                   364\n",
       "5998                                         '0:1:59.84                   373\n",
       "5999                                         '0:1:59.86                   379\n",
       "6000                                         '0:1:59.88                   381\n",
       "6001                                          '0:1:59.9                   380\n",
       "6002                                         '0:1:59.92                   376\n",
       "6003                                         '0:1:59.94                   371\n",
       "6004                                         '0:1:59.96                   365\n",
       "6005                                         '0:1:59.98                   360\n",
       "6006                                          '0:1:60.0                   357\n",
       "6007  sys info:[91~54~52~93~44~91~34~56~126~49~126~4...                   NaN\n",
       "6008  Attention! Any change in the file may prevent ...                   NaN\n",
       "\n",
       "[6009 rows x 2 columns]"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb = pd.read_csv(\"ShuenWuHeartbeat.csv\")\n",
    "hb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NeuLog experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5982</th>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5987</th>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5988</th>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5990</th>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6001 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NeuLog experiment\n",
       "0                   443\n",
       "1                   435\n",
       "2                   417\n",
       "3                   410\n",
       "4                   404\n",
       "5                   400\n",
       "6                   395\n",
       "7                   391\n",
       "8                   390\n",
       "9                   390\n",
       "10                  393\n",
       "11                  400\n",
       "12                  405\n",
       "13                  409\n",
       "14                  409\n",
       "15                  405\n",
       "16                  401\n",
       "17                  396\n",
       "18                  394\n",
       "19                  392\n",
       "20                  390\n",
       "21                  388\n",
       "22                  389\n",
       "23                  392\n",
       "24                  392\n",
       "25                  389\n",
       "26                  385\n",
       "27                  387\n",
       "28                  394\n",
       "29                  406\n",
       "...                 ...\n",
       "5971                353\n",
       "5972                354\n",
       "5973                356\n",
       "5974                357\n",
       "5975                359\n",
       "5976                361\n",
       "5977                373\n",
       "5978                394\n",
       "5979                416\n",
       "5980                429\n",
       "5981                429\n",
       "5982                420\n",
       "5983                407\n",
       "5984                391\n",
       "5985                377\n",
       "5986                364\n",
       "5987                354\n",
       "5988                347\n",
       "5989                347\n",
       "5990                353\n",
       "5991                364\n",
       "5992                373\n",
       "5993                379\n",
       "5994                381\n",
       "5995                380\n",
       "5996                376\n",
       "5997                371\n",
       "5998                365\n",
       "5999                360\n",
       "6000                357\n",
       "\n",
       "[6001 rows x 1 columns]"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Heartbeat = pd.read_csv(\"ShuenWuHeartbeat.csv\", skiprows=[1, 2, 3, 4, 5, 6], skipfooter=3)\n",
    "Heartbeat = Heartbeat.drop(\"Experiment name:\", axis=1)\n",
    "Heartbeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x280618f7518>]"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(6001)/50\n",
    "left, right = plt.xlim()\n",
    "plt.xlim((0, 10))\n",
    "plt.plot(x, Heartbeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 6001)"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.signal import find_peaks\n",
    "peaks, _ = find_peaks(Heartbeat.iloc[:, 0], distance=30, prominence=20)\n",
    "plt.plot(Heartbeat)\n",
    "plt.scatter(peaks, Heartbeat.iloc[peaks], color = \"orange\")\n",
    "plt.xlim(0, 6001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.0"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_hb = len(peaks)/2\n",
    "my_hb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AadiDass-VattamHeartbeat.csv': '74.5',\n",
       " 'AlexYuHeartbeat.csv': '55.5',\n",
       " 'AnnaHeHeartbeat.csv': '81.5',\n",
       " 'CarolZhangHeartbeat.csv': '81.5',\n",
       " 'DavidDelValleHeartbeat.csv': '82.0',\n",
       " 'EdwardYanHeartbeat.csv': '71.0',\n",
       " 'ElaineChuHeartbeat.csv': '69.5',\n",
       " 'EstebanCintronHeartbeat.csv': '81.5',\n",
       " 'GovindChadaHearbeat.csv': '71.5',\n",
       " 'HarrisBubaloHeartbeat.csv': '78.0',\n",
       " 'JoyLimHeartbeat.csv': '67.0',\n",
       " 'JoyLiuHeartbeat.csv': '86.5',\n",
       " 'MarielaNazarioCastroHeartbeat.csv': '87.0',\n",
       " 'OdessaThompsonHeartbeat.csv': '72.0',\n",
       " 'PratikBharadwajHeartbeat.csv': '74.5',\n",
       " 'SharvilTrifaleHeartbeat.csv': '76.0',\n",
       " 'ShreyaJainHeartbeat.csv': '67.0',\n",
       " 'ShuenWuHeartbeat.csv': '84.0',\n",
       " 'SuatMartinHeartbeat.csv': '70.5',\n",
       " 'VarunNairHeartbeat.csv': '62.0',\n",
       " 'VineetChinthakindiHeartbeat.csv': '57.5',\n",
       " 'VishalKumarHeartbeat.csv': '65.5',\n",
       " 'YerielMaldonadoHeartbeat.csv': '66.0'}"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#other joy = joy liu\n",
    "hb_dic = {}\n",
    "hb_list = []\n",
    "import os\n",
    "for file in os.listdir('Heartbeat'):\n",
    "    their_hb = pd.read_csv('Heartbeat/' + file, skiprows=[1, 2, 3, 4, 5, 6], skipfooter=3)\n",
    "    their_hb = their_hb.drop(\"Experiment name:\", axis=1)\n",
    "    peaks, _ = find_peaks(their_hb.iloc[:, 0], distance=30, prominence=20)\n",
    "    hb_dic[file] = str(len(peaks)/2)\n",
    "    hb_list.append(len(peaks)/2)\n",
    "hb_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adi', 'Alex', 'Anna', 'Carol', 'David', 'Edward', 'Elaine', 'Esteban', 'Govind', 'Harris', 'Joy', 'Joy2', 'Mariela', 'Odessa', 'Pratik', 'Sharvill', 'Shreya', 'Shuen', 'Suat', 'Varun', 'Vineet', 'Vishal', 'Yariel']\n",
      "Yariel       1\n",
      "David        1\n",
      "Vineet       0\n",
      "Edward       0\n",
      "Carol        0\n",
      "Joy          1\n",
      "Sharvill     1\n",
      "Esteban      0\n",
      "Pratik       1\n",
      "Adi          0\n",
      "Alex         1\n",
      "Odessa       0\n",
      "Shreya       0\n",
      "Mariela      0\n",
      "Anna         1\n",
      "Elaine       1\n",
      "Harris       0\n",
      "Vishal       1\n",
      "Shuen        0\n",
      "Varun        0\n",
      "Other Joy    1\n",
      "Govind       0\n",
      "Suat         1\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "names = sorted(PVT_data2)\n",
    "names.remove('Other Joy')\n",
    "names.append('Joy2')\n",
    "names = sorted(names)\n",
    "print(names)\n",
    "labels = [0,1,1,0,1,0,1,0,0,0,1,1,0,0,1,1,0,0,1,0,0,1,1]\n",
    "print(label.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first try, before speech stuff came out\n",
    "# final_df = pd.DataFrame({'Name':names, 'isFatigued':labels,'Heart Rate': hb_list, 'Sleep': Cognitive_Fatigue_Data.iloc[:, 1], 'Fatigue Scale': Cognitive_Fatigue_Data.iloc[:, 2], 'Exercise': Cognitive_Fatigue_Data.iloc[:, 3], 'Eating Scale': Cognitive_Fatigue_Data.iloc[:, 4], 'Stress': Cognitive_Fatigue_Data.iloc[:, 5], 'Caffeine': Cognitive_Fatigue_Data.iloc[:, 6]})\n",
    "# final_df.to_csv(path_or_buf='AllData.csv')\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classdata = pd.read_csv('classdata.csv')\n",
    "\n",
    "# # columns_names = []\n",
    "# # for item in classdata.columns:\n",
    "# #     if item != 'Name' and item != 'Labels':\n",
    "# #         columns_names.append(item)\n",
    "# # columns_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# for i in columns_names:\n",
    "#     norm_data = classdata.i.values.reshape(-1, 1)\n",
    "#     scaler.fit(norm_data)\n",
    "#     classdata['n'+str(i)] = scaler.transform(norm_data)\n",
    "#     classdata = classdata.drop([i], axis=0)\n",
    "\n",
    "# classdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# norm_data = classdata.Sleep.values.reshape(-1, 1)\n",
    "# scaler.fit(norm_data)\n",
    "# classdata['nSleep'] = scaler.transform(norm_data)\n",
    "\n",
    "# classdata = classdata.drop(['Sleep'], axis=1)\n",
    "\n",
    "# norm_data = classdata.Fatigue_Scale.values.reshape(-1, 1)\n",
    "# scaler.fit(norm_data)\n",
    "# classdata['nFatigue_Scale'] = scaler.transform(norm_data)\n",
    "# classdata = classdata.drop(['Fatigue_Scale'], axis=1)\n",
    "\n",
    "# norm_data = classdata.Exercise.values.reshape(-1, 1)\n",
    "# scaler.fit(norm_data)\n",
    "# classdata['nExercise'] = scaler.transform(norm_data)\n",
    "# classdata = classdata.drop(['Exercise'], axis=1)\n",
    "\n",
    "# norm_data = classdata.Eating_Scale.values.reshape(-1, 1)\n",
    "# scaler.fit(norm_data)\n",
    "# classdata['nEating_Scale'] = scaler.transform(norm_data)\n",
    "# classdata = classdata.drop(['Eating_Scale'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_data = classdata.Heart_Rate.values.reshape(-1, 1)\n",
    "# scaler.fit(norm_data)\n",
    "# classdata['nHeart_Rate'] = scaler.transform(norm_data)\n",
    "# classdata = classdata.drop(['Heart_Rate'], axis=1)\n",
    "\n",
    "# norm_data = classdata.Caffeine.values.reshape(-1, 1)\n",
    "# scaler.fit(norm_data)\n",
    "# classdata['nCaffeine'] = scaler.transform(norm_data)\n",
    "# classdata = classdata.drop(['Caffeine'], axis=1)\n",
    "\n",
    "# norm_data = classdata.Stress_Scale.values.reshape(-1, 1)\n",
    "# scaler.fit(norm_data)\n",
    "# classdata['nStress_Scale'] = scaler.transform(norm_data)\n",
    "# classdata = classdata.drop(['Stress_Scale'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this is wrong don't do this\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data_train, data_val = train_test_split(classdata, test_size = 0.20, random_state = 0, stratify = classdata['Labels'])\n",
    "\n",
    "\n",
    "# y_train = data_train['Labels']\n",
    "# y_val = data_val['Labels']\n",
    "\n",
    "# # only features \n",
    "# X_train = data_train[['nSleep', 'nFatigue_Scale', 'nExercise', 'nEating_Scale', 'nHeart_Rate', 'nCaffeine', 'nStress_Scale']]\n",
    "# X_val = data_val[['nSleep', 'nFatigue_Scale', 'nExercise', 'nEating_Scale', 'nHeart_Rate', 'nCaffeine', 'nStress_Scale']]\n",
    "\n",
    "\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# #feature labels\n",
    "# x_cols = ['nSleep', 'nFatigue_Scale', 'nExercise', 'nEating_Scale', 'nHeart_Rate', 'nCaffeine', 'nStress_Scale']\n",
    "\n",
    "# #class labels\n",
    "# y_col = [\"Labels\"]\n",
    "\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(classdata[x_cols], classdata[y_col], test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>nSleep</th>\n",
       "      <th>nFatigue_Scale</th>\n",
       "      <th>nExercise</th>\n",
       "      <th>nEating_Scale</th>\n",
       "      <th>nHeart_Rate</th>\n",
       "      <th>nCaffeine</th>\n",
       "      <th>nStress_Scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.146982</td>\n",
       "      <td>0.394238</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.014389</td>\n",
       "      <td>-0.066121</td>\n",
       "      <td>0.284870</td>\n",
       "      <td>0.014389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nSleep</th>\n",
       "      <td>0.146982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.079677</td>\n",
       "      <td>0.274117</td>\n",
       "      <td>-0.095130</td>\n",
       "      <td>-0.350017</td>\n",
       "      <td>-0.004211</td>\n",
       "      <td>-0.095130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nFatigue_Scale</th>\n",
       "      <td>0.394238</td>\n",
       "      <td>-0.079677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.235113</td>\n",
       "      <td>0.030822</td>\n",
       "      <td>0.221148</td>\n",
       "      <td>0.169831</td>\n",
       "      <td>0.030822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nExercise</th>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.274117</td>\n",
       "      <td>0.235113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034360</td>\n",
       "      <td>-0.211437</td>\n",
       "      <td>-0.236355</td>\n",
       "      <td>-0.034360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nEating_Scale</th>\n",
       "      <td>0.014389</td>\n",
       "      <td>-0.095130</td>\n",
       "      <td>0.030822</td>\n",
       "      <td>-0.034360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024563</td>\n",
       "      <td>-0.330283</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nHeart_Rate</th>\n",
       "      <td>-0.066121</td>\n",
       "      <td>-0.350017</td>\n",
       "      <td>0.221148</td>\n",
       "      <td>-0.211437</td>\n",
       "      <td>0.024563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142562</td>\n",
       "      <td>0.024563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCaffeine</th>\n",
       "      <td>0.284870</td>\n",
       "      <td>-0.004211</td>\n",
       "      <td>0.169831</td>\n",
       "      <td>-0.236355</td>\n",
       "      <td>-0.330283</td>\n",
       "      <td>0.142562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.330283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nStress_Scale</th>\n",
       "      <td>0.014389</td>\n",
       "      <td>-0.095130</td>\n",
       "      <td>0.030822</td>\n",
       "      <td>-0.034360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024563</td>\n",
       "      <td>-0.330283</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Labels    nSleep  nFatigue_Scale  nExercise  nEating_Scale  \\\n",
       "Labels          1.000000  0.146982        0.394238   0.033700       0.014389   \n",
       "nSleep          0.146982  1.000000       -0.079677   0.274117      -0.095130   \n",
       "nFatigue_Scale  0.394238 -0.079677        1.000000   0.235113       0.030822   \n",
       "nExercise       0.033700  0.274117        0.235113   1.000000      -0.034360   \n",
       "nEating_Scale   0.014389 -0.095130        0.030822  -0.034360       1.000000   \n",
       "nHeart_Rate    -0.066121 -0.350017        0.221148  -0.211437       0.024563   \n",
       "nCaffeine       0.284870 -0.004211        0.169831  -0.236355      -0.330283   \n",
       "nStress_Scale   0.014389 -0.095130        0.030822  -0.034360       1.000000   \n",
       "\n",
       "                nHeart_Rate  nCaffeine  nStress_Scale  \n",
       "Labels            -0.066121   0.284870       0.014389  \n",
       "nSleep            -0.350017  -0.004211      -0.095130  \n",
       "nFatigue_Scale     0.221148   0.169831       0.030822  \n",
       "nExercise         -0.211437  -0.236355      -0.034360  \n",
       "nEating_Scale      0.024563  -0.330283       1.000000  \n",
       "nHeart_Rate        1.000000   0.142562       0.024563  \n",
       "nCaffeine          0.142562   1.000000      -0.330283  \n",
       "nStress_Scale      0.024563  -0.330283       1.000000  "
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classdata.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# #feature labels\n",
    "# x_cols = ['nSleep', 'nFatigue_Scale', 'nCaffeine', 'nHeart_Rate', 'nStress_Scale']\n",
    "\n",
    "# #class labels\n",
    "# y_col = [\"Labels\"]\n",
    "\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(classdata[x_cols], classdata[y_col], test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# logreg = LogisticRegression()\n",
    "# results = logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #training the data\n",
    "# y_train_predict = logreg.predict(x_train)\n",
    "# y_train_proba = logreg.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "# #getting the auc\n",
    "# from sklearn.metrics import auc\n",
    "# fpr, tpr, threshold = metrics.roc_curve(y_train, y_train_predict) \n",
    "\n",
    "# roc_auc = metrics.auc(fpr, tpr)\n",
    "# # print('AUC: ',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #auc curve plot\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.plot(fpr, tpr, 'b', label = 'AUC = %0.3f' % roc_auc)\n",
    "# plt.legend(loc = 'lower right')\n",
    "# plt.plot([0, 1], [0, 1],'r--')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing with logistic regression\n",
    "# logreg = LogisticRegression()\n",
    "# results = logreg.fit(x_test, y_test)\n",
    "# y_test_predict = logreg.predict(x_test)\n",
    "# y_test_proba = logreg.predict_proba(x_test)\n",
    "# fpr, tpr, threshold = metrics.roc_curve(y_test, y_test_predict) \n",
    "# roc_auc = metrics.auc(fpr, tpr)\n",
    "# print('AUC: ',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation crap\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #aight, time to mess around with SVMs\n",
    "# from sklearn import svm\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.svm import SVC\n",
    "# x_cols = ['nSleep', 'nFatigue_Scale', 'nCaffeine']\n",
    "# y_col = [\"Labels\"]\n",
    "# x_train, x_test, y_train, y_test = train_test_split(classdata[x_cols], classdata[y_col], test_size=0.20, random_state=0)\n",
    "# svm = SVC(gamma = .01)\n",
    "# svm.fit(x_train, y_train)\n",
    "# y_train_pred_svm= svm.predict(x_train)\n",
    "# print(\"Training Accuracy is \", accuracy_score(y_train, y_train_pred_svm)*100)\n",
    "# # y_test_pred_svm= svm.predict(x_test)\n",
    "# # print(\"Testing Accuracy is \", accuracy_score(y_test,y_test_pred_svm)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #aight, time to mess around with KNN\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# x_cols = ['nSleep', 'nFatigue_Scale', 'nCaffeine']\n",
    "# y_col = [\"Labels\"]\n",
    "# x_train, x_test, y_train, y_test = train_test_split(classdata[x_cols], classdata[y_col], test_size=0.20, random_state=0)\n",
    "# knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "# knn.fit(x_train, y_train)\n",
    "# y_train_pred_knn= knn.predict(x_train)\n",
    "# print(\"Training Accuracy is \", accuracy_score(y_train, y_train_pred_knn)*100)\n",
    "# # y_test_pred= knn.predict(x_testing)\n",
    "# # print(\"Testing Accuracy is \", accuracy_score(y_test, y_test_pred_knn)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #aight, time to mess around with decision trees\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# x_cols = ['nSleep', 'nFatigue_Scale', 'nCaffeine', 'nHeart_Rate']\n",
    "# y_col = [\"Labels\"]\n",
    "# x_train, x_test, y_train, y_test = train_test_split(classdata[x_cols], classdata[y_col], test_size=0.20, random_state=0)\n",
    "# decision_tree = DecisionTreeClassifier(criterion = \"entropy\", random_state = None,\n",
    "#                               max_depth=5, min_samples_leaf=5)\n",
    "# decision_tree.fit(x_train, y_train)\n",
    "# y_train_pred_dt= decision_tree.predict(x_train)\n",
    "# print(\"Training Accuracy is \", accuracy_score(y_train, y_train_pred_dt)*100)\n",
    "# # y_test_pred_dt= decision_tree.predict(x_test)\n",
    "# # print(\"Testing Accuracy is \", accuracy_score(y_test,y_test_pred_dt)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# x_cols = ['nSleep', 'nFatigue_Scale', 'nCaffeine', 'nHeart_Rate']\n",
    "# y_col = [\"Labels\"]\n",
    "# x_train, x_test, y_train, y_test = train_test_split(classdata[x_cols], classdata[y_col], test_size=0.20, random_state=0)\n",
    "# random_forest = RandomForestClassifier(n_estimators=100)\n",
    "# random_forest.fit(x_train, y_train)\n",
    "# y_train_pred_rf= decision_tree.predict(x_train)\n",
    "# print(\"Training Accuracy is \", accuracy_score(y_train, y_train_pred_rf)*100)\n",
    "# # y_test_pred_rf= decision_tree.predict(x_test)\n",
    "# # print(\"Testing Accuracy is \", accuracy_score(y_test,y_test_pred_rf)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok time to import speech data\n",
    "import parselmouth as pm\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "hInt_list = []\n",
    "hPit_list = []\n",
    "hForm_list = []\n",
    "intensities_list = []\n",
    "for file in os.listdir('Speech'):\n",
    "    name = pm.Sound('Speech/' + file)\n",
    "    hInt = name.to_intensity()\n",
    "    hPit = name.to_pitch()\n",
    "    hForm = name.to_formant_burg()\n",
    "    hInt_list.append(hInt)\n",
    "    hPit_list.append(hPit)\n",
    "    hForm_list.append(hForm)\n",
    "# Shuen = pm.Sound(\"Speech/Shuen.wav\")\n",
    "# type(Shuen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting lists of intensity stuff (max, average, and variance)\n",
    "int_max_list = []\n",
    "int_avg_list = []\n",
    "int_var_list = []\n",
    "for item in hInt_list:\n",
    "    int_max_list.append(np.max(item))\n",
    "for item in hInt_list:\n",
    "    int_avg_list.append(np.mean(item))\n",
    "for item in hInt_list:\n",
    "    int_var_list.append(np.var(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hInt = Shuen.to_intensity()\n",
    "# hPit = Shuen.to_pitch()\n",
    "# hForm = Shuen.to_formant_burg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intensities = []\n",
    "# for val in hInt.t_grid():\n",
    "#     intensities.append(hInt.get_value(val))\n",
    "# plt.plot(intensities[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pitches = []\n",
    "# for val in hPit.t_grid():\n",
    "#     pitches.append(hPit.get_value_at_time(val))\n",
    "# plt.plot(pitches[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting pitch variance\n",
    "#this block is wrong, plz help me Andy\n",
    "import math\n",
    "pit_var_list = []\n",
    "for file in hPit_list:\n",
    "    pitch_list = []\n",
    "    for val in file.t_grid():\n",
    "        if np.isnan(file.get_value_at_time(val)) == False:\n",
    "            pitch_list.append(file.get_value_at_time(val))\n",
    "    var = np.var(pitch_list)\n",
    "    pit_var_list.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up formants data\n",
    "for_0_avg_list = []\n",
    "for_1_avg_list = []\n",
    "for_2_avg_list = []\n",
    "for file in hForm_list:\n",
    "    formant_0 = []\n",
    "    formant_1 = []\n",
    "    formant_2 = []\n",
    "    for val in file.t_grid():\n",
    "        if math.isnan(file.get_value_at_time(1,val)) == False:\n",
    "            formant_0.append(file.get_value_at_time(1,val))\n",
    "        if math.isnan(file.get_value_at_time(2,val)) == False:\n",
    "            formant_1.append(file.get_value_at_time(2,val))\n",
    "        if math.isnan(file.get_value_at_time(3,val)) == False:\n",
    "            formant_2.append(file.get_value_at_time(3,val))\n",
    "    for_0_avg_list.append(np.mean(formant_0))\n",
    "    for_1_avg_list.append(np.mean(formant_1))\n",
    "    for_2_avg_list.append(np.mean(formant_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formants = [[],[],[]]\n",
    "# for val in hForm.t_grid():\n",
    "#     formants[0].append(hForm.get_value_at_time(1,val))\n",
    "#     formants[1].append(hForm.get_value_at_time(2,val))\n",
    "#     formants[2].append(hForm.get_value_at_time(3,val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(formants[0][0:100])\n",
    "# plt.plot(formants[1][0:100])\n",
    "# plt.plot(formants[2][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>sleep</th>\n",
       "      <th>fatigue scale</th>\n",
       "      <th>exercise(min)</th>\n",
       "      <th>eating scale</th>\n",
       "      <th>stress scale</th>\n",
       "      <th>caffeine</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>S_Intensity_max</th>\n",
       "      <th>S_Intensity_avg</th>\n",
       "      <th>S_Intensity_var</th>\n",
       "      <th>S_Formant_1_avg</th>\n",
       "      <th>S_Formant_2_avg</th>\n",
       "      <th>S_Formant_0_avg</th>\n",
       "      <th>S_Pitch_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anna</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>92.541157</td>\n",
       "      <td>56.087746</td>\n",
       "      <td>173.802336</td>\n",
       "      <td>1797.804568</td>\n",
       "      <td>2829.002668</td>\n",
       "      <td>636.753885</td>\n",
       "      <td>7947.273729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elaine</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>55.5</td>\n",
       "      <td>63.732773</td>\n",
       "      <td>43.167914</td>\n",
       "      <td>79.869429</td>\n",
       "      <td>1694.829937</td>\n",
       "      <td>2837.516960</td>\n",
       "      <td>600.437194</td>\n",
       "      <td>11605.797568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mariela</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>81.5</td>\n",
       "      <td>58.660419</td>\n",
       "      <td>42.533051</td>\n",
       "      <td>68.978492</td>\n",
       "      <td>1833.728526</td>\n",
       "      <td>2799.275700</td>\n",
       "      <td>644.425035</td>\n",
       "      <td>1107.172870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harris</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>91.906829</td>\n",
       "      <td>50.164482</td>\n",
       "      <td>120.969947</td>\n",
       "      <td>1817.936659</td>\n",
       "      <td>2898.958206</td>\n",
       "      <td>665.778777</td>\n",
       "      <td>3119.855483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oddessa</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>82.0</td>\n",
       "      <td>69.459283</td>\n",
       "      <td>40.548850</td>\n",
       "      <td>70.224773</td>\n",
       "      <td>1645.443099</td>\n",
       "      <td>2771.281355</td>\n",
       "      <td>566.830285</td>\n",
       "      <td>1136.087506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shreya</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>76.587958</td>\n",
       "      <td>47.855985</td>\n",
       "      <td>114.142240</td>\n",
       "      <td>1789.524635</td>\n",
       "      <td>2848.376007</td>\n",
       "      <td>674.525748</td>\n",
       "      <td>1556.566636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Varun</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>69.5</td>\n",
       "      <td>62.550444</td>\n",
       "      <td>46.816353</td>\n",
       "      <td>75.871835</td>\n",
       "      <td>1847.222330</td>\n",
       "      <td>2865.197090</td>\n",
       "      <td>649.562542</td>\n",
       "      <td>662.701218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Joy Liu</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>73.583660</td>\n",
       "      <td>46.871383</td>\n",
       "      <td>103.594023</td>\n",
       "      <td>1776.279422</td>\n",
       "      <td>2801.450600</td>\n",
       "      <td>553.721628</td>\n",
       "      <td>2521.174017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vishal</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>71.5</td>\n",
       "      <td>65.316281</td>\n",
       "      <td>45.546339</td>\n",
       "      <td>89.861459</td>\n",
       "      <td>1658.304960</td>\n",
       "      <td>2802.058591</td>\n",
       "      <td>589.322112</td>\n",
       "      <td>915.743617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shuen</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>60.119681</td>\n",
       "      <td>42.304023</td>\n",
       "      <td>72.817752</td>\n",
       "      <td>1806.214954</td>\n",
       "      <td>2756.580267</td>\n",
       "      <td>642.538916</td>\n",
       "      <td>9695.337779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Govind</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>65.404524</td>\n",
       "      <td>43.015008</td>\n",
       "      <td>76.969596</td>\n",
       "      <td>1782.892421</td>\n",
       "      <td>2830.430914</td>\n",
       "      <td>580.706474</td>\n",
       "      <td>2785.854383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Suat</td>\n",
       "      <td>4.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>86.5</td>\n",
       "      <td>62.657438</td>\n",
       "      <td>44.449829</td>\n",
       "      <td>77.785964</td>\n",
       "      <td>1766.780952</td>\n",
       "      <td>2746.537584</td>\n",
       "      <td>617.111149</td>\n",
       "      <td>2259.002648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>David</td>\n",
       "      <td>6.25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>92.376928</td>\n",
       "      <td>52.915584</td>\n",
       "      <td>185.269743</td>\n",
       "      <td>1887.858860</td>\n",
       "      <td>2952.279985</td>\n",
       "      <td>663.091778</td>\n",
       "      <td>1859.209798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yariel</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>92.157163</td>\n",
       "      <td>46.647394</td>\n",
       "      <td>94.072075</td>\n",
       "      <td>1850.732024</td>\n",
       "      <td>2901.474771</td>\n",
       "      <td>662.805577</td>\n",
       "      <td>2184.166568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Joy Lim</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>45</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>74.5</td>\n",
       "      <td>91.792062</td>\n",
       "      <td>48.153630</td>\n",
       "      <td>110.831182</td>\n",
       "      <td>1768.884536</td>\n",
       "      <td>2759.865668</td>\n",
       "      <td>687.401028</td>\n",
       "      <td>11076.602273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Edward</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>150</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>92.154790</td>\n",
       "      <td>56.913025</td>\n",
       "      <td>160.573795</td>\n",
       "      <td>1793.728572</td>\n",
       "      <td>2834.043366</td>\n",
       "      <td>657.823331</td>\n",
       "      <td>3958.719677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Carol</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>45</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.617178</td>\n",
       "      <td>45.777167</td>\n",
       "      <td>70.754705</td>\n",
       "      <td>1793.612414</td>\n",
       "      <td>2864.227352</td>\n",
       "      <td>648.921957</td>\n",
       "      <td>1804.839945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vineet</td>\n",
       "      <td>8.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>70.323216</td>\n",
       "      <td>45.715135</td>\n",
       "      <td>37.874128</td>\n",
       "      <td>1576.127224</td>\n",
       "      <td>2761.699492</td>\n",
       "      <td>582.890443</td>\n",
       "      <td>849.958463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pratik</td>\n",
       "      <td>6.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>70.5</td>\n",
       "      <td>92.256634</td>\n",
       "      <td>55.060571</td>\n",
       "      <td>102.063353</td>\n",
       "      <td>1659.044738</td>\n",
       "      <td>2711.741314</td>\n",
       "      <td>586.771639</td>\n",
       "      <td>4098.060685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sharvil</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>180</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>92.974262</td>\n",
       "      <td>64.678620</td>\n",
       "      <td>220.059919</td>\n",
       "      <td>1740.844264</td>\n",
       "      <td>2786.984803</td>\n",
       "      <td>634.605034</td>\n",
       "      <td>5554.645723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Alex</td>\n",
       "      <td>7.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>57.5</td>\n",
       "      <td>91.823019</td>\n",
       "      <td>58.687591</td>\n",
       "      <td>179.773275</td>\n",
       "      <td>1778.345735</td>\n",
       "      <td>2842.482347</td>\n",
       "      <td>668.238583</td>\n",
       "      <td>4417.719176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Esteban</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>65.5</td>\n",
       "      <td>90.581106</td>\n",
       "      <td>54.990438</td>\n",
       "      <td>154.487380</td>\n",
       "      <td>1680.208334</td>\n",
       "      <td>2707.634245</td>\n",
       "      <td>654.213247</td>\n",
       "      <td>3653.605706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Aadi</td>\n",
       "      <td>4.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>107</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>78.565213</td>\n",
       "      <td>49.733060</td>\n",
       "      <td>126.227384</td>\n",
       "      <td>1691.828700</td>\n",
       "      <td>2715.620877</td>\n",
       "      <td>626.666306</td>\n",
       "      <td>1612.593953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  sleep  fatigue scale  exercise(min)  eating scale  stress scale  \\\n",
       "0      Anna   7.00            7.0              0           8.0           3.0   \n",
       "1    Elaine   8.00            4.0              0           3.0           7.0   \n",
       "2   Mariela   4.00            4.0              0           5.0           1.0   \n",
       "3    Harris   6.00            6.0             15           6.0           3.0   \n",
       "4   Oddessa   5.50            6.0             30           7.0           7.0   \n",
       "5    Shreya   8.00            2.0             60           9.0           1.0   \n",
       "6     Varun   6.00            3.0              0           9.0           2.0   \n",
       "7   Joy Liu   6.50            5.0             10          10.0           8.0   \n",
       "8    Vishal   6.00            3.0              0           8.0           3.0   \n",
       "9     Shuen   4.00            8.0              0           4.0           7.0   \n",
       "10   Govind   4.00            3.0              0           8.0           8.0   \n",
       "11     Suat   4.50            6.0              0           7.0           1.0   \n",
       "12   David    6.25            8.0              0           9.5           7.0   \n",
       "13   Yariel   6.00            6.0              0           3.0           6.0   \n",
       "14  Joy Lim   5.00            6.5             45           7.0           6.0   \n",
       "15   Edward   7.00            7.0            150           9.0           8.0   \n",
       "16    Carol   7.00            3.5             45           4.0           3.5   \n",
       "17   Vineet   8.00            5.0             30           4.0           6.0   \n",
       "18   Pratik   6.50            8.0             70           9.0           2.0   \n",
       "19  Sharvil   6.00            5.0            180           5.0           6.0   \n",
       "20     Alex   7.50            8.0            300           5.0           4.0   \n",
       "21  Esteban   6.00            3.0            120           6.0           1.0   \n",
       "22     Aadi   4.50            6.0            107          10.0           3.0   \n",
       "\n",
       "    caffeine   Labels  Heart_Rate  S_Intensity_max  S_Intensity_avg  \\\n",
       "0        0.00       0        74.5        92.541157        56.087746   \n",
       "1        1.00       1        55.5        63.732773        43.167914   \n",
       "2        0.00       1        81.5        58.660419        42.533051   \n",
       "3        0.00       0        81.5        91.906829        50.164482   \n",
       "4        2.00       1        82.0        69.459283        40.548850   \n",
       "5        0.00       0        71.0        76.587958        47.855985   \n",
       "6        0.00       1        69.5        62.550444        46.816353   \n",
       "7        0.50       0        81.5        73.583660        46.871383   \n",
       "8        0.00       0        71.5        65.316281        45.546339   \n",
       "9        1.00       0        78.0        60.119681        42.304023   \n",
       "10       0.00       1        67.0        65.404524        43.015008   \n",
       "11       0.00       1        86.5        62.657438        44.449829   \n",
       "12       2.50       0        87.0        92.376928        52.915584   \n",
       "13       5.50       0        72.0        92.157163        46.647394   \n",
       "14       0.00       1        74.5        91.792062        48.153630   \n",
       "15       0.00       1        76.0        92.154790        56.913025   \n",
       "16       0.75       0        67.0        67.617178        45.777167   \n",
       "17       0.00       0        84.0        70.323216        45.715135   \n",
       "18       0.00       1        70.5        92.256634        55.060571   \n",
       "19       0.00       0        62.0        92.974262        64.678620   \n",
       "20       0.00       0        57.5        91.823019        58.687591   \n",
       "21       1.00       1        65.5        90.581106        54.990438   \n",
       "22       0.00       1        66.0        78.565213        49.733060   \n",
       "\n",
       "    S_Intensity_var  S_Formant_1_avg  S_Formant_2_avg  S_Formant_0_avg  \\\n",
       "0        173.802336      1797.804568      2829.002668       636.753885   \n",
       "1         79.869429      1694.829937      2837.516960       600.437194   \n",
       "2         68.978492      1833.728526      2799.275700       644.425035   \n",
       "3        120.969947      1817.936659      2898.958206       665.778777   \n",
       "4         70.224773      1645.443099      2771.281355       566.830285   \n",
       "5        114.142240      1789.524635      2848.376007       674.525748   \n",
       "6         75.871835      1847.222330      2865.197090       649.562542   \n",
       "7        103.594023      1776.279422      2801.450600       553.721628   \n",
       "8         89.861459      1658.304960      2802.058591       589.322112   \n",
       "9         72.817752      1806.214954      2756.580267       642.538916   \n",
       "10        76.969596      1782.892421      2830.430914       580.706474   \n",
       "11        77.785964      1766.780952      2746.537584       617.111149   \n",
       "12       185.269743      1887.858860      2952.279985       663.091778   \n",
       "13        94.072075      1850.732024      2901.474771       662.805577   \n",
       "14       110.831182      1768.884536      2759.865668       687.401028   \n",
       "15       160.573795      1793.728572      2834.043366       657.823331   \n",
       "16        70.754705      1793.612414      2864.227352       648.921957   \n",
       "17        37.874128      1576.127224      2761.699492       582.890443   \n",
       "18       102.063353      1659.044738      2711.741314       586.771639   \n",
       "19       220.059919      1740.844264      2786.984803       634.605034   \n",
       "20       179.773275      1778.345735      2842.482347       668.238583   \n",
       "21       154.487380      1680.208334      2707.634245       654.213247   \n",
       "22       126.227384      1691.828700      2715.620877       626.666306   \n",
       "\n",
       "     S_Pitch_var  \n",
       "0    7947.273729  \n",
       "1   11605.797568  \n",
       "2    1107.172870  \n",
       "3    3119.855483  \n",
       "4    1136.087506  \n",
       "5    1556.566636  \n",
       "6     662.701218  \n",
       "7    2521.174017  \n",
       "8     915.743617  \n",
       "9    9695.337779  \n",
       "10   2785.854383  \n",
       "11   2259.002648  \n",
       "12   1859.209798  \n",
       "13   2184.166568  \n",
       "14  11076.602273  \n",
       "15   3958.719677  \n",
       "16   1804.839945  \n",
       "17    849.958463  \n",
       "18   4098.060685  \n",
       "19   5554.645723  \n",
       "20   4417.719176  \n",
       "21   3653.605706  \n",
       "22   1612.593953  "
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([Cognitive_Fatigue_Data], axis=1)\n",
    "final_df.sort_index(inplace=True)\n",
    "final_df.loc[:, 'Labels'] = labels\n",
    "final_df.loc[:, 'Heart_Rate'] = hb_list\n",
    "final_df.loc[:, 'S_Intensity_max'] = int_max_list\n",
    "final_df.loc[:, 'S_Intensity_avg'] = int_avg_list\n",
    "final_df.loc[:, 'S_Intensity_var'] = int_var_list\n",
    "final_df.loc[:, 'S_Formant_1_avg'] = for_1_avg_list\n",
    "final_df.loc[:, 'S_Formant_2_avg'] = for_2_avg_list\n",
    "final_df.loc[:, 'S_Formant_0_avg'] = for_0_avg_list\n",
    "final_df.loc[:, 'S_Pitch_var'] = pit_var_list\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sleep</th>\n",
       "      <th>Fatigue_Scale</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Eating_Scale</th>\n",
       "      <th>Stress_Scale</th>\n",
       "      <th>Caffeine</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>S_Intensity_max</th>\n",
       "      <th>S_Intensity_avg</th>\n",
       "      <th>S_Intensity_var</th>\n",
       "      <th>S_Formant_1_avg</th>\n",
       "      <th>S_Formant_2_avg</th>\n",
       "      <th>S_Formant_0_avg</th>\n",
       "      <th>S_Pitch_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anna</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>92.541157</td>\n",
       "      <td>56.087746</td>\n",
       "      <td>173.802336</td>\n",
       "      <td>1797.804568</td>\n",
       "      <td>2829.002668</td>\n",
       "      <td>636.753885</td>\n",
       "      <td>7947.273729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elaine</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>55.5</td>\n",
       "      <td>63.732773</td>\n",
       "      <td>43.167914</td>\n",
       "      <td>79.869429</td>\n",
       "      <td>1694.829937</td>\n",
       "      <td>2837.516960</td>\n",
       "      <td>600.437194</td>\n",
       "      <td>11605.797568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mariela</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>81.5</td>\n",
       "      <td>58.660419</td>\n",
       "      <td>42.533051</td>\n",
       "      <td>68.978492</td>\n",
       "      <td>1833.728526</td>\n",
       "      <td>2799.275700</td>\n",
       "      <td>644.425035</td>\n",
       "      <td>1107.172870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harris</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>91.906829</td>\n",
       "      <td>50.164482</td>\n",
       "      <td>120.969947</td>\n",
       "      <td>1817.936659</td>\n",
       "      <td>2898.958206</td>\n",
       "      <td>665.778777</td>\n",
       "      <td>3119.855483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oddessa</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>82.0</td>\n",
       "      <td>69.459283</td>\n",
       "      <td>40.548850</td>\n",
       "      <td>70.224773</td>\n",
       "      <td>1645.443099</td>\n",
       "      <td>2771.281355</td>\n",
       "      <td>566.830285</td>\n",
       "      <td>1136.087506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shreya</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>76.587958</td>\n",
       "      <td>47.855985</td>\n",
       "      <td>114.142240</td>\n",
       "      <td>1789.524635</td>\n",
       "      <td>2848.376007</td>\n",
       "      <td>674.525748</td>\n",
       "      <td>1556.566636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Varun</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>69.5</td>\n",
       "      <td>62.550444</td>\n",
       "      <td>46.816353</td>\n",
       "      <td>75.871835</td>\n",
       "      <td>1847.222330</td>\n",
       "      <td>2865.197090</td>\n",
       "      <td>649.562542</td>\n",
       "      <td>662.701218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Joy Liu</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>73.583660</td>\n",
       "      <td>46.871383</td>\n",
       "      <td>103.594023</td>\n",
       "      <td>1776.279422</td>\n",
       "      <td>2801.450600</td>\n",
       "      <td>553.721628</td>\n",
       "      <td>2521.174017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vishal</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>71.5</td>\n",
       "      <td>65.316281</td>\n",
       "      <td>45.546339</td>\n",
       "      <td>89.861459</td>\n",
       "      <td>1658.304960</td>\n",
       "      <td>2802.058591</td>\n",
       "      <td>589.322112</td>\n",
       "      <td>915.743617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shuen</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>60.119681</td>\n",
       "      <td>42.304023</td>\n",
       "      <td>72.817752</td>\n",
       "      <td>1806.214954</td>\n",
       "      <td>2756.580267</td>\n",
       "      <td>642.538916</td>\n",
       "      <td>9695.337779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Govind</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>65.404524</td>\n",
       "      <td>43.015008</td>\n",
       "      <td>76.969596</td>\n",
       "      <td>1782.892421</td>\n",
       "      <td>2830.430914</td>\n",
       "      <td>580.706474</td>\n",
       "      <td>2785.854383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Suat</td>\n",
       "      <td>4.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>86.5</td>\n",
       "      <td>62.657438</td>\n",
       "      <td>44.449829</td>\n",
       "      <td>77.785964</td>\n",
       "      <td>1766.780952</td>\n",
       "      <td>2746.537584</td>\n",
       "      <td>617.111149</td>\n",
       "      <td>2259.002648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>David</td>\n",
       "      <td>6.25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>92.376928</td>\n",
       "      <td>52.915584</td>\n",
       "      <td>185.269743</td>\n",
       "      <td>1887.858860</td>\n",
       "      <td>2952.279985</td>\n",
       "      <td>663.091778</td>\n",
       "      <td>1859.209798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yariel</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>92.157163</td>\n",
       "      <td>46.647394</td>\n",
       "      <td>94.072075</td>\n",
       "      <td>1850.732024</td>\n",
       "      <td>2901.474771</td>\n",
       "      <td>662.805577</td>\n",
       "      <td>2184.166568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Joy Lim</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>45</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>74.5</td>\n",
       "      <td>91.792062</td>\n",
       "      <td>48.153630</td>\n",
       "      <td>110.831182</td>\n",
       "      <td>1768.884536</td>\n",
       "      <td>2759.865668</td>\n",
       "      <td>687.401028</td>\n",
       "      <td>11076.602273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Edward</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>150</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>92.154790</td>\n",
       "      <td>56.913025</td>\n",
       "      <td>160.573795</td>\n",
       "      <td>1793.728572</td>\n",
       "      <td>2834.043366</td>\n",
       "      <td>657.823331</td>\n",
       "      <td>3958.719677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Carol</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>45</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.617178</td>\n",
       "      <td>45.777167</td>\n",
       "      <td>70.754705</td>\n",
       "      <td>1793.612414</td>\n",
       "      <td>2864.227352</td>\n",
       "      <td>648.921957</td>\n",
       "      <td>1804.839945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vineet</td>\n",
       "      <td>8.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>70.323216</td>\n",
       "      <td>45.715135</td>\n",
       "      <td>37.874128</td>\n",
       "      <td>1576.127224</td>\n",
       "      <td>2761.699492</td>\n",
       "      <td>582.890443</td>\n",
       "      <td>849.958463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pratik</td>\n",
       "      <td>6.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>70.5</td>\n",
       "      <td>92.256634</td>\n",
       "      <td>55.060571</td>\n",
       "      <td>102.063353</td>\n",
       "      <td>1659.044738</td>\n",
       "      <td>2711.741314</td>\n",
       "      <td>586.771639</td>\n",
       "      <td>4098.060685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sharvil</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>180</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>92.974262</td>\n",
       "      <td>64.678620</td>\n",
       "      <td>220.059919</td>\n",
       "      <td>1740.844264</td>\n",
       "      <td>2786.984803</td>\n",
       "      <td>634.605034</td>\n",
       "      <td>5554.645723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Alex</td>\n",
       "      <td>7.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>57.5</td>\n",
       "      <td>91.823019</td>\n",
       "      <td>58.687591</td>\n",
       "      <td>179.773275</td>\n",
       "      <td>1778.345735</td>\n",
       "      <td>2842.482347</td>\n",
       "      <td>668.238583</td>\n",
       "      <td>4417.719176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Esteban</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>65.5</td>\n",
       "      <td>90.581106</td>\n",
       "      <td>54.990438</td>\n",
       "      <td>154.487380</td>\n",
       "      <td>1680.208334</td>\n",
       "      <td>2707.634245</td>\n",
       "      <td>654.213247</td>\n",
       "      <td>3653.605706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Aadi</td>\n",
       "      <td>4.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>107</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>78.565213</td>\n",
       "      <td>49.733060</td>\n",
       "      <td>126.227384</td>\n",
       "      <td>1691.828700</td>\n",
       "      <td>2715.620877</td>\n",
       "      <td>626.666306</td>\n",
       "      <td>1612.593953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Sleep  Fatigue_Scale  Exercise  Eating_Scale  Stress_Scale  \\\n",
       "0      Anna   7.00            7.0         0           8.0           3.0   \n",
       "1    Elaine   8.00            4.0         0           3.0           7.0   \n",
       "2   Mariela   4.00            4.0         0           5.0           1.0   \n",
       "3    Harris   6.00            6.0        15           6.0           3.0   \n",
       "4   Oddessa   5.50            6.0        30           7.0           7.0   \n",
       "5    Shreya   8.00            2.0        60           9.0           1.0   \n",
       "6     Varun   6.00            3.0         0           9.0           2.0   \n",
       "7   Joy Liu   6.50            5.0        10          10.0           8.0   \n",
       "8    Vishal   6.00            3.0         0           8.0           3.0   \n",
       "9     Shuen   4.00            8.0         0           4.0           7.0   \n",
       "10   Govind   4.00            3.0         0           8.0           8.0   \n",
       "11     Suat   4.50            6.0         0           7.0           1.0   \n",
       "12   David    6.25            8.0         0           9.5           7.0   \n",
       "13   Yariel   6.00            6.0         0           3.0           6.0   \n",
       "14  Joy Lim   5.00            6.5        45           7.0           6.0   \n",
       "15   Edward   7.00            7.0       150           9.0           8.0   \n",
       "16    Carol   7.00            3.5        45           4.0           3.5   \n",
       "17   Vineet   8.00            5.0        30           4.0           6.0   \n",
       "18   Pratik   6.50            8.0        70           9.0           2.0   \n",
       "19  Sharvil   6.00            5.0       180           5.0           6.0   \n",
       "20     Alex   7.50            8.0       300           5.0           4.0   \n",
       "21  Esteban   6.00            3.0       120           6.0           1.0   \n",
       "22     Aadi   4.50            6.0       107          10.0           3.0   \n",
       "\n",
       "    Caffeine  Labels  Heart_Rate  S_Intensity_max  S_Intensity_avg  \\\n",
       "0       0.00       0        74.5        92.541157        56.087746   \n",
       "1       1.00       1        55.5        63.732773        43.167914   \n",
       "2       0.00       1        81.5        58.660419        42.533051   \n",
       "3       0.00       0        81.5        91.906829        50.164482   \n",
       "4       2.00       1        82.0        69.459283        40.548850   \n",
       "5       0.00       0        71.0        76.587958        47.855985   \n",
       "6       0.00       1        69.5        62.550444        46.816353   \n",
       "7       0.50       0        81.5        73.583660        46.871383   \n",
       "8       0.00       0        71.5        65.316281        45.546339   \n",
       "9       1.00       0        78.0        60.119681        42.304023   \n",
       "10      0.00       1        67.0        65.404524        43.015008   \n",
       "11      0.00       1        86.5        62.657438        44.449829   \n",
       "12      2.50       0        87.0        92.376928        52.915584   \n",
       "13      5.50       0        72.0        92.157163        46.647394   \n",
       "14      0.00       1        74.5        91.792062        48.153630   \n",
       "15      0.00       1        76.0        92.154790        56.913025   \n",
       "16      0.75       0        67.0        67.617178        45.777167   \n",
       "17      0.00       0        84.0        70.323216        45.715135   \n",
       "18      0.00       1        70.5        92.256634        55.060571   \n",
       "19      0.00       0        62.0        92.974262        64.678620   \n",
       "20      0.00       0        57.5        91.823019        58.687591   \n",
       "21      1.00       1        65.5        90.581106        54.990438   \n",
       "22      0.00       1        66.0        78.565213        49.733060   \n",
       "\n",
       "    S_Intensity_var  S_Formant_1_avg  S_Formant_2_avg  S_Formant_0_avg  \\\n",
       "0        173.802336      1797.804568      2829.002668       636.753885   \n",
       "1         79.869429      1694.829937      2837.516960       600.437194   \n",
       "2         68.978492      1833.728526      2799.275700       644.425035   \n",
       "3        120.969947      1817.936659      2898.958206       665.778777   \n",
       "4         70.224773      1645.443099      2771.281355       566.830285   \n",
       "5        114.142240      1789.524635      2848.376007       674.525748   \n",
       "6         75.871835      1847.222330      2865.197090       649.562542   \n",
       "7        103.594023      1776.279422      2801.450600       553.721628   \n",
       "8         89.861459      1658.304960      2802.058591       589.322112   \n",
       "9         72.817752      1806.214954      2756.580267       642.538916   \n",
       "10        76.969596      1782.892421      2830.430914       580.706474   \n",
       "11        77.785964      1766.780952      2746.537584       617.111149   \n",
       "12       185.269743      1887.858860      2952.279985       663.091778   \n",
       "13        94.072075      1850.732024      2901.474771       662.805577   \n",
       "14       110.831182      1768.884536      2759.865668       687.401028   \n",
       "15       160.573795      1793.728572      2834.043366       657.823331   \n",
       "16        70.754705      1793.612414      2864.227352       648.921957   \n",
       "17        37.874128      1576.127224      2761.699492       582.890443   \n",
       "18       102.063353      1659.044738      2711.741314       586.771639   \n",
       "19       220.059919      1740.844264      2786.984803       634.605034   \n",
       "20       179.773275      1778.345735      2842.482347       668.238583   \n",
       "21       154.487380      1680.208334      2707.634245       654.213247   \n",
       "22       126.227384      1691.828700      2715.620877       626.666306   \n",
       "\n",
       "     S_Pitch_var  \n",
       "0    7947.273729  \n",
       "1   11605.797568  \n",
       "2    1107.172870  \n",
       "3    3119.855483  \n",
       "4    1136.087506  \n",
       "5    1556.566636  \n",
       "6     662.701218  \n",
       "7    2521.174017  \n",
       "8     915.743617  \n",
       "9    9695.337779  \n",
       "10   2785.854383  \n",
       "11   2259.002648  \n",
       "12   1859.209798  \n",
       "13   2184.166568  \n",
       "14  11076.602273  \n",
       "15   3958.719677  \n",
       "16   1804.839945  \n",
       "17    849.958463  \n",
       "18   4098.060685  \n",
       "19   5554.645723  \n",
       "20   4417.719176  \n",
       "21   3653.605706  \n",
       "22   1612.593953  "
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.copy(final_df)\n",
    "df = df.rename(index=str, columns={'caffeine ': 'Caffeine','sleep': 'Sleep', 'stress scale': 'Stress_Scale', 'fatigue scale': 'Fatigue_Scale', 'eating scale': 'Eating_Scale', 'exercise(min)': 'Exercise'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Labels</th>\n",
       "      <th>nHeart_Rate</th>\n",
       "      <th>nSleep</th>\n",
       "      <th>nFatigue_Scale</th>\n",
       "      <th>nExercise</th>\n",
       "      <th>nEating_Scale</th>\n",
       "      <th>nStress_Scale</th>\n",
       "      <th>nCaffeine</th>\n",
       "      <th>nS_Intensity_max</th>\n",
       "      <th>nS_Intensity_avg</th>\n",
       "      <th>nS_Intensity_var</th>\n",
       "      <th>nS_Formant_0_avg</th>\n",
       "      <th>nS_Formant_1_avg</th>\n",
       "      <th>nS_Formant_2_avg</th>\n",
       "      <th>nS_Pitch_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anna</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159040</td>\n",
       "      <td>0.761227</td>\n",
       "      <td>0.898795</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>0.554313</td>\n",
       "      <td>-0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.108375</td>\n",
       "      <td>1.160502</td>\n",
       "      <td>1.362221</td>\n",
       "      <td>0.175746</td>\n",
       "      <td>0.523118</td>\n",
       "      <td>0.307106</td>\n",
       "      <td>1.307753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elaine</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.047327</td>\n",
       "      <td>1.566204</td>\n",
       "      <td>-0.733227</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>-1.682389</td>\n",
       "      <td>1.004376</td>\n",
       "      <td>0.306288</td>\n",
       "      <td>-1.095019</td>\n",
       "      <td>-0.976316</td>\n",
       "      <td>-0.695002</td>\n",
       "      <td>-0.801625</td>\n",
       "      <td>-0.836396</td>\n",
       "      <td>0.443064</td>\n",
       "      <td>2.449215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mariela</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971912</td>\n",
       "      <td>-1.653701</td>\n",
       "      <td>-0.733227</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>-0.787708</td>\n",
       "      <td>-1.406127</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-1.482975</td>\n",
       "      <td>-1.081316</td>\n",
       "      <td>-0.933524</td>\n",
       "      <td>0.382196</td>\n",
       "      <td>0.997401</td>\n",
       "      <td>-0.167583</td>\n",
       "      <td>-0.826364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971912</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>-0.478563</td>\n",
       "      <td>-0.340368</td>\n",
       "      <td>-0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.059858</td>\n",
       "      <td>0.180850</td>\n",
       "      <td>0.205140</td>\n",
       "      <td>0.956877</td>\n",
       "      <td>0.788910</td>\n",
       "      <td>1.424176</td>\n",
       "      <td>-0.198406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oddessa</td>\n",
       "      <td>1</td>\n",
       "      <td>1.029975</td>\n",
       "      <td>-0.446237</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>-0.276477</td>\n",
       "      <td>0.106973</td>\n",
       "      <td>1.004376</td>\n",
       "      <td>1.111387</td>\n",
       "      <td>-0.657030</td>\n",
       "      <td>-1.409484</td>\n",
       "      <td>-0.906230</td>\n",
       "      <td>-1.706069</td>\n",
       "      <td>-1.488421</td>\n",
       "      <td>-0.614605</td>\n",
       "      <td>-0.817343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shreya</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.247396</td>\n",
       "      <td>1.566204</td>\n",
       "      <td>-1.821242</td>\n",
       "      <td>0.127695</td>\n",
       "      <td>1.001654</td>\n",
       "      <td>-1.406127</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-0.111797</td>\n",
       "      <td>-0.200953</td>\n",
       "      <td>0.055606</td>\n",
       "      <td>1.192280</td>\n",
       "      <td>0.413803</td>\n",
       "      <td>0.616465</td>\n",
       "      <td>-0.686153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Varun</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.421583</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>-1.277235</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>1.001654</td>\n",
       "      <td>-1.004376</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-1.185448</td>\n",
       "      <td>-0.372899</td>\n",
       "      <td>-0.782553</td>\n",
       "      <td>0.520458</td>\n",
       "      <td>1.175552</td>\n",
       "      <td>0.885069</td>\n",
       "      <td>-0.965039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Joy Liu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971912</td>\n",
       "      <td>0.358739</td>\n",
       "      <td>-0.189220</td>\n",
       "      <td>-0.545925</td>\n",
       "      <td>1.448994</td>\n",
       "      <td>1.406127</td>\n",
       "      <td>-0.096262</td>\n",
       "      <td>-0.341579</td>\n",
       "      <td>-0.363797</td>\n",
       "      <td>-0.175410</td>\n",
       "      <td>-2.058855</td>\n",
       "      <td>0.238934</td>\n",
       "      <td>-0.132854</td>\n",
       "      <td>-0.385195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vishal</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.189334</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>-1.277235</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>0.554313</td>\n",
       "      <td>-0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-0.973905</td>\n",
       "      <td>-0.582947</td>\n",
       "      <td>-0.476167</td>\n",
       "      <td>-1.100759</td>\n",
       "      <td>-1.318613</td>\n",
       "      <td>-0.123145</td>\n",
       "      <td>-0.886090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shuen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565476</td>\n",
       "      <td>-1.653701</td>\n",
       "      <td>1.442802</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>-1.235049</td>\n",
       "      <td>1.004376</td>\n",
       "      <td>0.306288</td>\n",
       "      <td>-1.371364</td>\n",
       "      <td>-1.119195</td>\n",
       "      <td>-0.849441</td>\n",
       "      <td>0.331435</td>\n",
       "      <td>0.634156</td>\n",
       "      <td>-0.849356</td>\n",
       "      <td>1.853150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Govind</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.711894</td>\n",
       "      <td>-1.653701</td>\n",
       "      <td>-1.277235</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>0.554313</td>\n",
       "      <td>1.406127</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-0.967156</td>\n",
       "      <td>-1.001605</td>\n",
       "      <td>-0.758511</td>\n",
       "      <td>-1.332627</td>\n",
       "      <td>0.326242</td>\n",
       "      <td>0.329912</td>\n",
       "      <td>-0.302614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Suat</td>\n",
       "      <td>1</td>\n",
       "      <td>1.552535</td>\n",
       "      <td>-1.251213</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>0.106973</td>\n",
       "      <td>-1.406127</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-1.177265</td>\n",
       "      <td>-0.764299</td>\n",
       "      <td>-0.740632</td>\n",
       "      <td>-0.352888</td>\n",
       "      <td>0.113532</td>\n",
       "      <td>-1.009720</td>\n",
       "      <td>-0.466992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>David</td>\n",
       "      <td>0</td>\n",
       "      <td>1.610598</td>\n",
       "      <td>0.157495</td>\n",
       "      <td>1.442802</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>1.225324</td>\n",
       "      <td>1.004376</td>\n",
       "      <td>1.513937</td>\n",
       "      <td>1.095814</td>\n",
       "      <td>0.635857</td>\n",
       "      <td>1.613369</td>\n",
       "      <td>0.884563</td>\n",
       "      <td>1.712052</td>\n",
       "      <td>2.275633</td>\n",
       "      <td>-0.591728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yariel</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.131271</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>-1.682389</td>\n",
       "      <td>0.602626</td>\n",
       "      <td>3.929235</td>\n",
       "      <td>1.079005</td>\n",
       "      <td>-0.400843</td>\n",
       "      <td>-0.383950</td>\n",
       "      <td>0.876861</td>\n",
       "      <td>1.221888</td>\n",
       "      <td>1.464361</td>\n",
       "      <td>-0.490341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Joy Lim</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159040</td>\n",
       "      <td>-0.848725</td>\n",
       "      <td>0.626791</td>\n",
       "      <td>-0.074391</td>\n",
       "      <td>0.106973</td>\n",
       "      <td>0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.051081</td>\n",
       "      <td>-0.151726</td>\n",
       "      <td>-0.016909</td>\n",
       "      <td>1.538785</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>-0.796894</td>\n",
       "      <td>2.284105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Edward</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333227</td>\n",
       "      <td>0.761227</td>\n",
       "      <td>0.898795</td>\n",
       "      <td>1.340212</td>\n",
       "      <td>1.001654</td>\n",
       "      <td>1.406127</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.078824</td>\n",
       "      <td>1.296996</td>\n",
       "      <td>1.072503</td>\n",
       "      <td>0.742777</td>\n",
       "      <td>0.469305</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.063321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Carol</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.711894</td>\n",
       "      <td>0.761227</td>\n",
       "      <td>-1.005231</td>\n",
       "      <td>-0.074391</td>\n",
       "      <td>-1.235049</td>\n",
       "      <td>-0.401751</td>\n",
       "      <td>0.105013</td>\n",
       "      <td>-0.797922</td>\n",
       "      <td>-0.544770</td>\n",
       "      <td>-0.894623</td>\n",
       "      <td>0.503219</td>\n",
       "      <td>0.467772</td>\n",
       "      <td>0.869583</td>\n",
       "      <td>-0.608691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vineet</td>\n",
       "      <td>0</td>\n",
       "      <td>1.262224</td>\n",
       "      <td>1.566204</td>\n",
       "      <td>-0.189220</td>\n",
       "      <td>-0.276477</td>\n",
       "      <td>-1.235049</td>\n",
       "      <td>0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-0.590952</td>\n",
       "      <td>-0.555030</td>\n",
       "      <td>-1.614741</td>\n",
       "      <td>-1.273851</td>\n",
       "      <td>-2.403558</td>\n",
       "      <td>-0.767611</td>\n",
       "      <td>-0.906615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pratik</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.305458</td>\n",
       "      <td>0.358739</td>\n",
       "      <td>1.442802</td>\n",
       "      <td>0.262419</td>\n",
       "      <td>1.001654</td>\n",
       "      <td>-1.004376</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.086613</td>\n",
       "      <td>0.990617</td>\n",
       "      <td>-0.208933</td>\n",
       "      <td>-1.169399</td>\n",
       "      <td>-1.308847</td>\n",
       "      <td>-1.565357</td>\n",
       "      <td>0.106795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sharvil</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.292517</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>-0.189220</td>\n",
       "      <td>1.744384</td>\n",
       "      <td>-0.787708</td>\n",
       "      <td>0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.141500</td>\n",
       "      <td>2.581352</td>\n",
       "      <td>2.375308</td>\n",
       "      <td>0.117915</td>\n",
       "      <td>-0.228895</td>\n",
       "      <td>-0.363848</td>\n",
       "      <td>0.561251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Alex</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.815078</td>\n",
       "      <td>1.163715</td>\n",
       "      <td>1.442802</td>\n",
       "      <td>3.361073</td>\n",
       "      <td>-0.787708</td>\n",
       "      <td>-0.200875</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.053448</td>\n",
       "      <td>1.590492</td>\n",
       "      <td>1.492991</td>\n",
       "      <td>1.023077</td>\n",
       "      <td>0.266215</td>\n",
       "      <td>0.522353</td>\n",
       "      <td>0.206529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Esteban</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.886081</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>-1.277235</td>\n",
       "      <td>0.936039</td>\n",
       "      <td>-0.340368</td>\n",
       "      <td>-1.406127</td>\n",
       "      <td>0.306288</td>\n",
       "      <td>0.958461</td>\n",
       "      <td>0.979018</td>\n",
       "      <td>0.939205</td>\n",
       "      <td>0.645620</td>\n",
       "      <td>-1.029436</td>\n",
       "      <td>-1.630940</td>\n",
       "      <td>-0.031875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Aadi</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.828019</td>\n",
       "      <td>-1.251213</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>0.760898</td>\n",
       "      <td>1.448994</td>\n",
       "      <td>-0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.109497</td>\n",
       "      <td>0.320283</td>\n",
       "      <td>-0.095735</td>\n",
       "      <td>-0.876019</td>\n",
       "      <td>-1.503407</td>\n",
       "      <td>-0.668672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Labels  nHeart_Rate    nSleep  nFatigue_Scale  nExercise  \\\n",
       "0      Anna       0     0.159040  0.761227        0.898795  -0.680649   \n",
       "1    Elaine       1    -2.047327  1.566204       -0.733227  -0.680649   \n",
       "2   Mariela       1     0.971912 -1.653701       -0.733227  -0.680649   \n",
       "3    Harris       0     0.971912 -0.043749        0.354787  -0.478563   \n",
       "4   Oddessa       1     1.029975 -0.446237        0.354787  -0.276477   \n",
       "5    Shreya       0    -0.247396  1.566204       -1.821242   0.127695   \n",
       "6     Varun       1    -0.421583 -0.043749       -1.277235  -0.680649   \n",
       "7   Joy Liu       0     0.971912  0.358739       -0.189220  -0.545925   \n",
       "8    Vishal       0    -0.189334 -0.043749       -1.277235  -0.680649   \n",
       "9     Shuen       0     0.565476 -1.653701        1.442802  -0.680649   \n",
       "10   Govind       1    -0.711894 -1.653701       -1.277235  -0.680649   \n",
       "11     Suat       1     1.552535 -1.251213        0.354787  -0.680649   \n",
       "12   David        0     1.610598  0.157495        1.442802  -0.680649   \n",
       "13   Yariel       0    -0.131271 -0.043749        0.354787  -0.680649   \n",
       "14  Joy Lim       1     0.159040 -0.848725        0.626791  -0.074391   \n",
       "15   Edward       1     0.333227  0.761227        0.898795   1.340212   \n",
       "16    Carol       0    -0.711894  0.761227       -1.005231  -0.074391   \n",
       "17   Vineet       0     1.262224  1.566204       -0.189220  -0.276477   \n",
       "18   Pratik       1    -0.305458  0.358739        1.442802   0.262419   \n",
       "19  Sharvil       0    -1.292517 -0.043749       -0.189220   1.744384   \n",
       "20     Alex       0    -1.815078  1.163715        1.442802   3.361073   \n",
       "21  Esteban       1    -0.886081 -0.043749       -1.277235   0.936039   \n",
       "22     Aadi       1    -0.828019 -1.251213        0.354787   0.760898   \n",
       "\n",
       "    nEating_Scale  nStress_Scale  nCaffeine  nS_Intensity_max  \\\n",
       "0        0.554313      -0.602626  -0.498812          1.108375   \n",
       "1       -1.682389       1.004376   0.306288         -1.095019   \n",
       "2       -0.787708      -1.406127  -0.498812         -1.482975   \n",
       "3       -0.340368      -0.602626  -0.498812          1.059858   \n",
       "4        0.106973       1.004376   1.111387         -0.657030   \n",
       "5        1.001654      -1.406127  -0.498812         -0.111797   \n",
       "6        1.001654      -1.004376  -0.498812         -1.185448   \n",
       "7        1.448994       1.406127  -0.096262         -0.341579   \n",
       "8        0.554313      -0.602626  -0.498812         -0.973905   \n",
       "9       -1.235049       1.004376   0.306288         -1.371364   \n",
       "10       0.554313       1.406127  -0.498812         -0.967156   \n",
       "11       0.106973      -1.406127  -0.498812         -1.177265   \n",
       "12       1.225324       1.004376   1.513937          1.095814   \n",
       "13      -1.682389       0.602626   3.929235          1.079005   \n",
       "14       0.106973       0.602626  -0.498812          1.051081   \n",
       "15       1.001654       1.406127  -0.498812          1.078824   \n",
       "16      -1.235049      -0.401751   0.105013         -0.797922   \n",
       "17      -1.235049       0.602626  -0.498812         -0.590952   \n",
       "18       1.001654      -1.004376  -0.498812          1.086613   \n",
       "19      -0.787708       0.602626  -0.498812          1.141500   \n",
       "20      -0.787708      -0.200875  -0.498812          1.053448   \n",
       "21      -0.340368      -1.406127   0.306288          0.958461   \n",
       "22       1.448994      -0.602626  -0.498812          0.039432   \n",
       "\n",
       "    nS_Intensity_avg  nS_Intensity_var  nS_Formant_0_avg  nS_Formant_1_avg  \\\n",
       "0           1.160502          1.362221          0.175746          0.523118   \n",
       "1          -0.976316         -0.695002         -0.801625         -0.836396   \n",
       "2          -1.081316         -0.933524          0.382196          0.997401   \n",
       "3           0.180850          0.205140          0.956877          0.788910   \n",
       "4          -1.409484         -0.906230         -1.706069         -1.488421   \n",
       "5          -0.200953          0.055606          1.192280          0.413803   \n",
       "6          -0.372899         -0.782553          0.520458          1.175552   \n",
       "7          -0.363797         -0.175410         -2.058855          0.238934   \n",
       "8          -0.582947         -0.476167         -1.100759         -1.318613   \n",
       "9          -1.119195         -0.849441          0.331435          0.634156   \n",
       "10         -1.001605         -0.758511         -1.332627          0.326242   \n",
       "11         -0.764299         -0.740632         -0.352888          0.113532   \n",
       "12          0.635857          1.613369          0.884563          1.712052   \n",
       "13         -0.400843         -0.383950          0.876861          1.221888   \n",
       "14         -0.151726         -0.016909          1.538785          0.141304   \n",
       "15          1.296996          1.072503          0.742777          0.469305   \n",
       "16         -0.544770         -0.894623          0.503219          0.467772   \n",
       "17         -0.555030         -1.614741         -1.273851         -2.403558   \n",
       "18          0.990617         -0.208933         -1.169399         -1.308847   \n",
       "19          2.581352          2.375308          0.117915         -0.228895   \n",
       "20          1.590492          1.492991          1.023077          0.266215   \n",
       "21          0.979018          0.939205          0.645620         -1.029436   \n",
       "22          0.109497          0.320283         -0.095735         -0.876019   \n",
       "\n",
       "    nS_Formant_2_avg  nS_Pitch_var  \n",
       "0           0.307106      1.307753  \n",
       "1           0.443064      2.449215  \n",
       "2          -0.167583     -0.826364  \n",
       "3           1.424176     -0.198406  \n",
       "4          -0.614605     -0.817343  \n",
       "5           0.616465     -0.686153  \n",
       "6           0.885069     -0.965039  \n",
       "7          -0.132854     -0.385195  \n",
       "8          -0.123145     -0.886090  \n",
       "9          -0.849356      1.853150  \n",
       "10          0.329912     -0.302614  \n",
       "11         -1.009720     -0.466992  \n",
       "12          2.275633     -0.591728  \n",
       "13          1.464361     -0.490341  \n",
       "14         -0.796894      2.284105  \n",
       "15          0.387597      0.063321  \n",
       "16          0.869583     -0.608691  \n",
       "17         -0.767611     -0.906615  \n",
       "18         -1.565357      0.106795  \n",
       "19         -0.363848      0.561251  \n",
       "20          0.522353      0.206529  \n",
       "21         -1.630940     -0.031875  \n",
       "22         -1.503407     -0.668672  "
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numeric_columns = ['Heart_Rate', 'Sleep', 'Fatigue_Scale', 'Exercise', 'Eating_Scale', 'Stress_Scale', 'Caffeine', 'S_Intensity_max', 'S_Intensity_avg', 'S_Intensity_var', 'S_Formant_0_avg', 'S_Formant_1_avg', 'S_Formant_2_avg', 'S_Pitch_var'] \n",
    "    \n",
    "for item in numeric_columns:\n",
    "    norm_data = df[item].values.reshape(-1, 1)\n",
    "    scaler.fit(norm_data)\n",
    "    df['n'+item] = scaler.transform(norm_data)\n",
    "    df = df.drop([item], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #bashing every combo function\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import auc\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn import svm\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# def get_all_metrics(x_cols, y_col):\n",
    "#     #finds and prints the AUC of every single model for given x_cols and y_col\n",
    "    \n",
    "#     #Logistic\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(df[x_cols], df[y_col], test_size = 0.30, random_state = 0)\n",
    "#     logreg = LogisticRegression()\n",
    "#     results = logreg.fit(x_train, y_train)\n",
    "#     y_train_predict = logreg.predict(x_train)\n",
    "#     y_train_proba = logreg.predict_proba(x_train)\n",
    "#     fpr, tpr, threshold = metrics.roc_curve(y_train, y_train_predict) \n",
    "#     roc_auc = metrics.auc(fpr, tpr)\n",
    "#     logistic_score = accuracy_score(y_train, y_train_predict)*100\n",
    "# #     print('Logistic AUC: ',roc_auc)\n",
    "# #     print(\"Logistic Training Accuracy is \", logistic_score)\n",
    "    \n",
    "#     #SVM\n",
    "#     svm = SVC(gamma = .01)\n",
    "#     svm.fit(x_train, y_train)\n",
    "#     y_train_pred_svm= svm.predict(x_train)\n",
    "#     svm_score = accuracy_score(y_train, y_train_pred_svm)*100\n",
    "# #     print(\"SVM Training Accuracy is \", svm_score)\n",
    "    \n",
    "#     #KNN\n",
    "#     knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "#     knn.fit(x_train, y_train)\n",
    "#     y_train_pred_knn= knn.predict(x_train)\n",
    "#     knn_score = accuracy_score(y_train, y_train_pred_knn)*100\n",
    "# #     print(\"KNN Training Accuracy is \", knn_score)\n",
    "    \n",
    "#     #Decision Tree\n",
    "#     decision_tree = DecisionTreeClassifier(criterion = \"entropy\", random_state = None,\n",
    "#                               max_depth=5, min_samples_leaf=5)\n",
    "#     decision_tree.fit(x_train, y_train)\n",
    "#     y_train_pred_dt= decision_tree.predict(x_train)\n",
    "#     dt_score = accuracy_score(y_train, y_train_pred_dt)*100\n",
    "# #     print(\"Decision Tree Training Accuracy is \", dt_score)\n",
    "    \n",
    "#     #Random Forest\n",
    "#     random_forest = RandomForestClassifier(n_estimators=100)\n",
    "#     random_forest.fit(x_train, y_train)\n",
    "#     y_train_pred_rf= decision_tree.predict(x_train)\n",
    "#     rf_score = accuracy_score(y_train, y_train_pred_rf)*100\n",
    "# #     print(\"Random Forest Training Accuracy is \", rf_score)\n",
    "    \n",
    "#     return max(logistic_score, svm_score, knn_score, dt_score, rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a, b, c, d, e in col_combos:\n",
    "#     x_columns = a, b, c, d, e\n",
    "#     x_columns = list(x_columns)\n",
    "#     if 'Labels' not in x_columns:\n",
    "#         print(x_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #what to do after you've found the best one, now finding which type of regression\n",
    "\n",
    "# def print_all_metrics(x_cols, y_col):\n",
    "#     #finds and prints the AUC of every single model for given x_cols and y_col\n",
    "    \n",
    "#     #Logistic\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(df[x_cols], df[y_col], test_size = 0.30, random_state = 0)\n",
    "#     logreg = LogisticRegression()\n",
    "#     results = logreg.fit(x_train, y_train)\n",
    "#     y_train_predict = logreg.predict(x_train)\n",
    "#     y_train_proba = logreg.predict_proba(x_train)\n",
    "#     fpr, tpr, threshold = metrics.roc_curve(y_train, y_train_predict) \n",
    "#     roc_auc = metrics.auc(fpr, tpr)\n",
    "#     logistic_score = accuracy_score(y_train, y_train_predict)*100\n",
    "#     print('Logistic AUC: ',roc_auc)\n",
    "#     print(\"Logistic Training Accuracy is \", logistic_score)\n",
    "    \n",
    "#     #SVM\n",
    "#     svm = SVC(gamma = .01)\n",
    "#     svm.fit(x_train, y_train)\n",
    "#     y_train_pred_svm= svm.predict(x_train)\n",
    "#     svm_score = accuracy_score(y_train, y_train_pred_svm)*100\n",
    "#     print(\"SVM Training Accuracy is \", svm_score)\n",
    "    \n",
    "#     #KNN\n",
    "#     knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "#     knn.fit(x_train, y_train)\n",
    "#     y_train_pred_knn= knn.predict(x_train)\n",
    "#     knn_score = accuracy_score(y_train, y_train_pred_knn)*100\n",
    "#     print(\"KNN Training Accuracy is \", knn_score)\n",
    "    \n",
    "#     #Decision Tree\n",
    "#     decision_tree = DecisionTreeClassifier(criterion = \"entropy\", random_state = None,\n",
    "#                               max_depth=5, min_samples_leaf=5)\n",
    "#     decision_tree.fit(x_train, y_train)\n",
    "#     y_train_pred_dt= decision_tree.predict(x_train)\n",
    "#     dt_score = accuracy_score(y_train, y_train_pred_dt)*100\n",
    "#     print(\"Decision Tree Training Accuracy is \", dt_score)\n",
    "    \n",
    "#     #Random Forest\n",
    "#     random_forest = RandomForestClassifier(n_estimators=100)\n",
    "#     random_forest.fit(x_train, y_train)\n",
    "#     y_train_pred_rf= decision_tree.predict(x_train)\n",
    "#     rf_score = accuracy_score(y_train, y_train_pred_rf)*100\n",
    "#     print(\"Random Forest Training Accuracy is \", rf_score)\n",
    "    \n",
    "#     return max(logistic_score, svm_score, knn_score, dt_score, rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #actual bashing begins with all the 5 column combos\n",
    "# import itertools\n",
    "# col_combos = list(itertools.combinations(df.columns, 5))\n",
    "# highest_accuracy_number = 0\n",
    "# highest_accuracy_combo = []\n",
    "# for a, b, c, d, e in col_combos:\n",
    "#     x_columns = a, b, c, d, e\n",
    "#     x_columns = list(x_columns)\n",
    "#     if 'Labels' not in x_columns:\n",
    "#         if get_all_metrics(x_columns, ['Labels'])>highest_accuracy_number:\n",
    "#             highest_accuracy_number = get_all_metrics(x_columns, ['Labels'])\n",
    "#             highest_accuracy_combo = x_columns\n",
    "# print(highest_accuracy_combo)\n",
    "# print(highest_accuracy_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_all_metrics(['nSleep', 'nFatigue_Scale', 'nExercise', 'nEating_Scale', 'nS_Intensity_var'], ['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #bashing all the four column combos\n",
    "# import itertools\n",
    "# col_combos = list(itertools.combinations(df.columns, 4))\n",
    "# highest_accuracy_number = 0\n",
    "# highest_accuracy_combo = []\n",
    "# for a, b, c, d in col_combos:\n",
    "#     x_columns = a, b, c, d\n",
    "#     x_columns = list(x_columns)\n",
    "#     if 'Labels' not in x_columns:\n",
    "#         if get_all_metrics(x_columns, ['Labels'])>highest_accuracy_number:\n",
    "#             highest_accuracy_number = get_all_metrics(x_columns, ['Labels'])\n",
    "#             highest_accuracy_combo = x_columns\n",
    "# print(highest_accuracy_combo)\n",
    "# print(highest_accuracy_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_all_metrics(['nSleep', 'nExercise', 'nEating_Scale', 'nS_Intensity_var'], ['Labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #bashing all 3 column combos\n",
    "# import itertools\n",
    "# col_combos = list(itertools.combinations(df.columns, 3))\n",
    "# highest_accuracy_number = 0\n",
    "# highest_accuracy_combo = []\n",
    "# for a, b, c in col_combos:\n",
    "#     x_columns = a, b, c\n",
    "#     x_columns = list(x_columns)\n",
    "#     if 'Labels' not in x_columns:\n",
    "#         if get_all_metrics(x_columns, ['Labels'])>highest_accuracy_number:\n",
    "#             highest_accuracy_number = get_all_metrics(x_columns, ['Labels'])\n",
    "#             highest_accuracy_combo = x_columns\n",
    "# print(highest_accuracy_combo)\n",
    "# print(highest_accuracy_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #bashing all 2 combos\n",
    "# import itertools\n",
    "# col_combos = list(itertools.combinations(df.columns, 2))\n",
    "# highest_accuracy_number = 0\n",
    "# highest_accuracy_combo = []\n",
    "# for a, b in col_combos:\n",
    "#     x_columns = a, b\n",
    "#     x_columns = list(x_columns)\n",
    "#     if 'Labels' not in x_columns:\n",
    "#         if get_all_metrics(x_columns, ['Labels'])>highest_accuracy_number:\n",
    "#             highest_accuracy_number = get_all_metrics(x_columns, ['Labels'])\n",
    "#             highest_accuracy_combo = x_columns\n",
    "# print(highest_accuracy_combo)\n",
    "# print(highest_accuracy_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #bashing all single combos\n",
    "# import itertools\n",
    "# col_combos = list(itertools.combinations(df.columns, 1))\n",
    "# highest_accuracy_number = 0\n",
    "# highest_accuracy_combo = []\n",
    "# for a in col_combos:\n",
    "#     x_columns = a\n",
    "#     x_columns = list(x_columns)\n",
    "#     if 'Labels' not in x_columns:\n",
    "#         if get_all_metrics(x_columns, ['Labels'])>highest_accuracy_number:\n",
    "#             highest_accuracy_number = get_all_metrics(x_columns, ['Labels'])\n",
    "#             highest_accuracy_combo = x_columns\n",
    "# print(highest_accuracy_combo)\n",
    "# print(highest_accuracy_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #training accuracy with different random state\n",
    "# x_cols = ['nSleep', 'nExercise', 'nEating_Scale', 'nS_Intensity_var']\n",
    "# y_col = ['Labels']\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(df[x_cols], df[y_col], test_size = 0.30, random_state = 0)\n",
    "\n",
    "# logreg = LogisticRegression()\n",
    "# results = logreg.fit(x_train, y_train)\n",
    "# y_train_predict = logreg.predict(x_train)\n",
    "# y_train_proba = logreg.predict_proba(x_train)\n",
    "# fpr, tpr, threshold = metrics.roc_curve(y_train, y_train_predict) \n",
    "# roc_auc = metrics.auc(fpr, tpr)\n",
    "# logistic_score = accuracy_score(y_train, y_train_predict)*100\n",
    "# print('Logistic AUC: ',roc_auc)\n",
    "# print(\"Logistic Training Accuracy is \", logistic_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing accuracy yeye\n",
    "# logreg_test = LogisticRegression()\n",
    "# results_test = logreg_test.fit(x_test, y_test)\n",
    "# y_test_predict = logreg_test.predict(x_test)\n",
    "# y_test_proba = logreg_test.predict_proba(x_test)\n",
    "# fpr_test, tpr_test, threshold_test = metrics.roc_curve(y_test, y_test_predict) \n",
    "# roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "# print('AUC: ',roc_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rewriting the get_all_metrics function this time with cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#bashing every combo function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def get_best_metric(x_cols, y_col):\n",
    "    #finds and prints the AUC of every single model for given x_cols and y_col\n",
    "    \n",
    "    #Logistic\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df[x_cols], df[y_col], test_size = 0.30, random_state = 0)\n",
    "    logreg = LogisticRegression()\n",
    "#     results = logreg.fit(x_train, y_train)\n",
    "#     y_train_predict = logreg.predict(x_train)\n",
    "#     y_train_proba = logreg.predict_proba(x_train)\n",
    "#     fpr, tpr, threshold = metrics.roc_curve(y_train, y_train_predict) \n",
    "#     roc_auc = metrics.auc(fpr, tpr)\n",
    "#     logistic_score = accuracy_score(y_train, y_train_predict)*100\n",
    "    log_cross_scores = cross_val_score(logreg, df[x_cols], df[y_col], cv=5)\n",
    "#     print('Logistic AUC: ',roc_auc)\n",
    "#     print(\"Logistic Training Accuracy is \", logistic_score)\n",
    "    \n",
    "    #SVM\n",
    "    svm = SVC(gamma = .01)\n",
    "#     svm.fit(x_train, y_train)\n",
    "#     y_train_pred_svm= svm.predict(x_train)\n",
    "#     svm_score = accuracy_score(y_train, y_train_pred_svm)*100\n",
    "    svm_cross_scores = cross_val_score(svm, df[x_cols], df[y_col], cv=5)\n",
    "#     print(\"SVM Training Accuracy is \", svm_score)\n",
    "    \n",
    "    #KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "#     knn.fit(x_train, y_train)\n",
    "#     y_train_pred_knn= knn.predict(x_train)\n",
    "#     knn_score = accuracy_score(y_train, y_train_pred_knn)*100\n",
    "    knn_cross_scores = cross_val_score(knn, df[x_cols], df[y_col], cv=5)\n",
    "#     print(\"KNN Training Accuracy is \", knn_score)\n",
    "    \n",
    "    #Decision Tree\n",
    "    decision_tree = DecisionTreeClassifier(criterion = \"entropy\", random_state = None,\n",
    "                              max_depth=5, min_samples_leaf=5)\n",
    "#     decision_tree.fit(x_train, y_train)\n",
    "#     y_train_pred_dt= decision_tree.predict(x_train)\n",
    "#     dt_score = accuracy_score(y_train, y_train_pred_dt)*100\n",
    "    dt_cross_scores = cross_val_score(decision_tree, df[x_cols], df[y_col], cv=5)\n",
    "#     print(\"Decision Tree Training Accuracy is \", dt_score)\n",
    "    \n",
    "    #Random Forest\n",
    "    random_forest = RandomForestClassifier(n_estimators=100)\n",
    "#     random_forest.fit(x_train, y_train)\n",
    "#     y_train_pred_rf= decision_tree.predict(x_train)\n",
    "#     rf_score = accuracy_score(y_train, y_train_pred_rf)*100\n",
    "    rf_cross_scores = cross_val_score(random_forest, df[x_cols], df[y_col], cv=5)\n",
    "#     print(\"Random Forest Training Accuracy is \", rf_score)\n",
    "    \n",
    "    return max(log_cross_scores.mean(), svm_cross_scores.mean(), knn_cross_scores.mean(), dt_cross_scores.mean(), rf_cross_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_best_metric(x_cols, y_col):\n",
    "    #finds and prints the AUC of every single model for given x_cols and y_col\n",
    "    \n",
    "    #Logistic\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df[x_cols], df[y_col], test_size = 0.30, random_state = 0)\n",
    "#     logreg = LogisticRegression()\n",
    "#     results = logreg.fit(x_train, y_train)\n",
    "#     y_train_predict = logreg.predict(x_train)\n",
    "#     y_train_proba = logreg.predict_proba(x_train)\n",
    "#     fpr, tpr, threshold = metrics.roc_curve(y_train, y_train_predict) \n",
    "#     roc_auc = metrics.auc(fpr, tpr)\n",
    "#     logistic_score = accuracy_score(y_train, y_train_predict)*100\n",
    "#     print('Logistic AUC: ',roc_auc)\n",
    "#     print(\"Logistic Training Accuracy is \", logistic_score)\n",
    "    logreg = LogisticRegression()\n",
    "    log_cross_scores = cross_val_score(logreg, df[x_cols], df[y_col], cv=5)\n",
    "    print(log_cross_scores.mean())\n",
    "    \n",
    "    #SVM\n",
    "    svm = SVC(gamma = .01)\n",
    "#     svm.fit(x_train, y_train)\n",
    "#     y_train_pred_svm= svm.predict(x_train)\n",
    "#     svm_score = accuracy_score(y_train, y_train_pred_svm)*100\n",
    "#     print(\"SVM Training Accuracy is \", svm_score)\n",
    "    svm_cross_scores = cross_val_score(svm, df[x_cols], df[y_col], cv=5)\n",
    "    print(svm_cross_scores.mean())\n",
    "    \n",
    "    #KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "#     knn.fit(x_train, y_train)\n",
    "#     y_train_pred_knn= knn.predict(x_train)\n",
    "#     knn_score = accuracy_score(y_train, y_train_pred_knn)*100\n",
    "#     print(\"KNN Training Accuracy is \", knn_score)\n",
    "    knn_cross_scores = cross_val_score(knn, df[x_cols], df[y_col], cv=5)\n",
    "    print(knn_cross_scores.mean())\n",
    "    \n",
    "    #Decision Tree\n",
    "    decision_tree = DecisionTreeClassifier(criterion = \"entropy\", random_state = None,\n",
    "                              max_depth=5, min_samples_leaf=5)\n",
    "#     decision_tree.fit(x_train, y_train)\n",
    "#     y_train_pred_dt= decision_tree.predict(x_train)\n",
    "#     dt_score = accuracy_score(y_train, y_train_pred_dt)*100\n",
    "#     print(\"Decision Tree Training Accuracy is \", dt_score)\n",
    "    dt_cross_scores = cross_val_score(decision_tree, df[x_cols], df[y_col], cv=5)\n",
    "    print(dt_cross_scores.mean())\n",
    "    \n",
    "    #Random Forest\n",
    "    random_forest = RandomForestClassifier(n_estimators=100)\n",
    "#     random_forest.fit(x_train, y_train)\n",
    "#     y_train_pred_rf= decision_tree.predict(x_train)\n",
    "#     rf_score = accuracy_score(y_train, y_train_pred_rf)*100\n",
    "#     print(\"Random Forest Training Accuracy is \", rf_score)\n",
    "    rf_cross_scores = cross_val_score(random_forest, df[x_cols], df[y_col], cv=5)\n",
    "    print(rf_cross_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Labels</th>\n",
       "      <th>nHeart_Rate</th>\n",
       "      <th>nSleep</th>\n",
       "      <th>nFatigue_Scale</th>\n",
       "      <th>nExercise</th>\n",
       "      <th>nEating_Scale</th>\n",
       "      <th>nStress_Scale</th>\n",
       "      <th>nCaffeine</th>\n",
       "      <th>nS_Intensity_max</th>\n",
       "      <th>nS_Intensity_avg</th>\n",
       "      <th>nS_Intensity_var</th>\n",
       "      <th>nS_Formant_0_avg</th>\n",
       "      <th>nS_Formant_1_avg</th>\n",
       "      <th>nS_Formant_2_avg</th>\n",
       "      <th>nS_Pitch_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anna</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159040</td>\n",
       "      <td>0.761227</td>\n",
       "      <td>0.898795</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>0.554313</td>\n",
       "      <td>-0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.108375</td>\n",
       "      <td>1.160502</td>\n",
       "      <td>1.362221</td>\n",
       "      <td>0.175746</td>\n",
       "      <td>0.523118</td>\n",
       "      <td>0.307106</td>\n",
       "      <td>1.307753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elaine</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.047327</td>\n",
       "      <td>1.566204</td>\n",
       "      <td>-0.733227</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>-1.682389</td>\n",
       "      <td>1.004376</td>\n",
       "      <td>0.306288</td>\n",
       "      <td>-1.095019</td>\n",
       "      <td>-0.976316</td>\n",
       "      <td>-0.695002</td>\n",
       "      <td>-0.801625</td>\n",
       "      <td>-0.836396</td>\n",
       "      <td>0.443064</td>\n",
       "      <td>2.449215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mariela</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971912</td>\n",
       "      <td>-1.653701</td>\n",
       "      <td>-0.733227</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>-0.787708</td>\n",
       "      <td>-1.406127</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-1.482975</td>\n",
       "      <td>-1.081316</td>\n",
       "      <td>-0.933524</td>\n",
       "      <td>0.382196</td>\n",
       "      <td>0.997401</td>\n",
       "      <td>-0.167583</td>\n",
       "      <td>-0.826364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971912</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>-0.478563</td>\n",
       "      <td>-0.340368</td>\n",
       "      <td>-0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.059858</td>\n",
       "      <td>0.180850</td>\n",
       "      <td>0.205140</td>\n",
       "      <td>0.956877</td>\n",
       "      <td>0.788910</td>\n",
       "      <td>1.424176</td>\n",
       "      <td>-0.198406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oddessa</td>\n",
       "      <td>1</td>\n",
       "      <td>1.029975</td>\n",
       "      <td>-0.446237</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>-0.276477</td>\n",
       "      <td>0.106973</td>\n",
       "      <td>1.004376</td>\n",
       "      <td>1.111387</td>\n",
       "      <td>-0.657030</td>\n",
       "      <td>-1.409484</td>\n",
       "      <td>-0.906230</td>\n",
       "      <td>-1.706069</td>\n",
       "      <td>-1.488421</td>\n",
       "      <td>-0.614605</td>\n",
       "      <td>-0.817343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shreya</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.247396</td>\n",
       "      <td>1.566204</td>\n",
       "      <td>-1.821242</td>\n",
       "      <td>0.127695</td>\n",
       "      <td>1.001654</td>\n",
       "      <td>-1.406127</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-0.111797</td>\n",
       "      <td>-0.200953</td>\n",
       "      <td>0.055606</td>\n",
       "      <td>1.192280</td>\n",
       "      <td>0.413803</td>\n",
       "      <td>0.616465</td>\n",
       "      <td>-0.686153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Varun</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.421583</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>-1.277235</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>1.001654</td>\n",
       "      <td>-1.004376</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-1.185448</td>\n",
       "      <td>-0.372899</td>\n",
       "      <td>-0.782553</td>\n",
       "      <td>0.520458</td>\n",
       "      <td>1.175552</td>\n",
       "      <td>0.885069</td>\n",
       "      <td>-0.965039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Joy Liu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971912</td>\n",
       "      <td>0.358739</td>\n",
       "      <td>-0.189220</td>\n",
       "      <td>-0.545925</td>\n",
       "      <td>1.448994</td>\n",
       "      <td>1.406127</td>\n",
       "      <td>-0.096262</td>\n",
       "      <td>-0.341579</td>\n",
       "      <td>-0.363797</td>\n",
       "      <td>-0.175410</td>\n",
       "      <td>-2.058855</td>\n",
       "      <td>0.238934</td>\n",
       "      <td>-0.132854</td>\n",
       "      <td>-0.385195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vishal</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.189334</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>-1.277235</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>0.554313</td>\n",
       "      <td>-0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-0.973905</td>\n",
       "      <td>-0.582947</td>\n",
       "      <td>-0.476167</td>\n",
       "      <td>-1.100759</td>\n",
       "      <td>-1.318613</td>\n",
       "      <td>-0.123145</td>\n",
       "      <td>-0.886090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shuen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565476</td>\n",
       "      <td>-1.653701</td>\n",
       "      <td>1.442802</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>-1.235049</td>\n",
       "      <td>1.004376</td>\n",
       "      <td>0.306288</td>\n",
       "      <td>-1.371364</td>\n",
       "      <td>-1.119195</td>\n",
       "      <td>-0.849441</td>\n",
       "      <td>0.331435</td>\n",
       "      <td>0.634156</td>\n",
       "      <td>-0.849356</td>\n",
       "      <td>1.853150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Govind</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.711894</td>\n",
       "      <td>-1.653701</td>\n",
       "      <td>-1.277235</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>0.554313</td>\n",
       "      <td>1.406127</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-0.967156</td>\n",
       "      <td>-1.001605</td>\n",
       "      <td>-0.758511</td>\n",
       "      <td>-1.332627</td>\n",
       "      <td>0.326242</td>\n",
       "      <td>0.329912</td>\n",
       "      <td>-0.302614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Suat</td>\n",
       "      <td>1</td>\n",
       "      <td>1.552535</td>\n",
       "      <td>-1.251213</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>0.106973</td>\n",
       "      <td>-1.406127</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-1.177265</td>\n",
       "      <td>-0.764299</td>\n",
       "      <td>-0.740632</td>\n",
       "      <td>-0.352888</td>\n",
       "      <td>0.113532</td>\n",
       "      <td>-1.009720</td>\n",
       "      <td>-0.466992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>David</td>\n",
       "      <td>0</td>\n",
       "      <td>1.610598</td>\n",
       "      <td>0.157495</td>\n",
       "      <td>1.442802</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>1.225324</td>\n",
       "      <td>1.004376</td>\n",
       "      <td>1.513937</td>\n",
       "      <td>1.095814</td>\n",
       "      <td>0.635857</td>\n",
       "      <td>1.613369</td>\n",
       "      <td>0.884563</td>\n",
       "      <td>1.712052</td>\n",
       "      <td>2.275633</td>\n",
       "      <td>-0.591728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yariel</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.131271</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>-0.680649</td>\n",
       "      <td>-1.682389</td>\n",
       "      <td>0.602626</td>\n",
       "      <td>3.929235</td>\n",
       "      <td>1.079005</td>\n",
       "      <td>-0.400843</td>\n",
       "      <td>-0.383950</td>\n",
       "      <td>0.876861</td>\n",
       "      <td>1.221888</td>\n",
       "      <td>1.464361</td>\n",
       "      <td>-0.490341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Joy Lim</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159040</td>\n",
       "      <td>-0.848725</td>\n",
       "      <td>0.626791</td>\n",
       "      <td>-0.074391</td>\n",
       "      <td>0.106973</td>\n",
       "      <td>0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.051081</td>\n",
       "      <td>-0.151726</td>\n",
       "      <td>-0.016909</td>\n",
       "      <td>1.538785</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>-0.796894</td>\n",
       "      <td>2.284105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Edward</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333227</td>\n",
       "      <td>0.761227</td>\n",
       "      <td>0.898795</td>\n",
       "      <td>1.340212</td>\n",
       "      <td>1.001654</td>\n",
       "      <td>1.406127</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.078824</td>\n",
       "      <td>1.296996</td>\n",
       "      <td>1.072503</td>\n",
       "      <td>0.742777</td>\n",
       "      <td>0.469305</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.063321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Carol</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.711894</td>\n",
       "      <td>0.761227</td>\n",
       "      <td>-1.005231</td>\n",
       "      <td>-0.074391</td>\n",
       "      <td>-1.235049</td>\n",
       "      <td>-0.401751</td>\n",
       "      <td>0.105013</td>\n",
       "      <td>-0.797922</td>\n",
       "      <td>-0.544770</td>\n",
       "      <td>-0.894623</td>\n",
       "      <td>0.503219</td>\n",
       "      <td>0.467772</td>\n",
       "      <td>0.869583</td>\n",
       "      <td>-0.608691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vineet</td>\n",
       "      <td>0</td>\n",
       "      <td>1.262224</td>\n",
       "      <td>1.566204</td>\n",
       "      <td>-0.189220</td>\n",
       "      <td>-0.276477</td>\n",
       "      <td>-1.235049</td>\n",
       "      <td>0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>-0.590952</td>\n",
       "      <td>-0.555030</td>\n",
       "      <td>-1.614741</td>\n",
       "      <td>-1.273851</td>\n",
       "      <td>-2.403558</td>\n",
       "      <td>-0.767611</td>\n",
       "      <td>-0.906615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pratik</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.305458</td>\n",
       "      <td>0.358739</td>\n",
       "      <td>1.442802</td>\n",
       "      <td>0.262419</td>\n",
       "      <td>1.001654</td>\n",
       "      <td>-1.004376</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.086613</td>\n",
       "      <td>0.990617</td>\n",
       "      <td>-0.208933</td>\n",
       "      <td>-1.169399</td>\n",
       "      <td>-1.308847</td>\n",
       "      <td>-1.565357</td>\n",
       "      <td>0.106795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sharvil</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.292517</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>-0.189220</td>\n",
       "      <td>1.744384</td>\n",
       "      <td>-0.787708</td>\n",
       "      <td>0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.141500</td>\n",
       "      <td>2.581352</td>\n",
       "      <td>2.375308</td>\n",
       "      <td>0.117915</td>\n",
       "      <td>-0.228895</td>\n",
       "      <td>-0.363848</td>\n",
       "      <td>0.561251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Alex</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.815078</td>\n",
       "      <td>1.163715</td>\n",
       "      <td>1.442802</td>\n",
       "      <td>3.361073</td>\n",
       "      <td>-0.787708</td>\n",
       "      <td>-0.200875</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>1.053448</td>\n",
       "      <td>1.590492</td>\n",
       "      <td>1.492991</td>\n",
       "      <td>1.023077</td>\n",
       "      <td>0.266215</td>\n",
       "      <td>0.522353</td>\n",
       "      <td>0.206529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Esteban</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.886081</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>-1.277235</td>\n",
       "      <td>0.936039</td>\n",
       "      <td>-0.340368</td>\n",
       "      <td>-1.406127</td>\n",
       "      <td>0.306288</td>\n",
       "      <td>0.958461</td>\n",
       "      <td>0.979018</td>\n",
       "      <td>0.939205</td>\n",
       "      <td>0.645620</td>\n",
       "      <td>-1.029436</td>\n",
       "      <td>-1.630940</td>\n",
       "      <td>-0.031875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Aadi</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.828019</td>\n",
       "      <td>-1.251213</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>0.760898</td>\n",
       "      <td>1.448994</td>\n",
       "      <td>-0.602626</td>\n",
       "      <td>-0.498812</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.109497</td>\n",
       "      <td>0.320283</td>\n",
       "      <td>-0.095735</td>\n",
       "      <td>-0.876019</td>\n",
       "      <td>-1.503407</td>\n",
       "      <td>-0.668672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Labels  nHeart_Rate    nSleep  nFatigue_Scale  nExercise  \\\n",
       "0      Anna       0     0.159040  0.761227        0.898795  -0.680649   \n",
       "1    Elaine       1    -2.047327  1.566204       -0.733227  -0.680649   \n",
       "2   Mariela       1     0.971912 -1.653701       -0.733227  -0.680649   \n",
       "3    Harris       0     0.971912 -0.043749        0.354787  -0.478563   \n",
       "4   Oddessa       1     1.029975 -0.446237        0.354787  -0.276477   \n",
       "5    Shreya       0    -0.247396  1.566204       -1.821242   0.127695   \n",
       "6     Varun       1    -0.421583 -0.043749       -1.277235  -0.680649   \n",
       "7   Joy Liu       0     0.971912  0.358739       -0.189220  -0.545925   \n",
       "8    Vishal       0    -0.189334 -0.043749       -1.277235  -0.680649   \n",
       "9     Shuen       0     0.565476 -1.653701        1.442802  -0.680649   \n",
       "10   Govind       1    -0.711894 -1.653701       -1.277235  -0.680649   \n",
       "11     Suat       1     1.552535 -1.251213        0.354787  -0.680649   \n",
       "12   David        0     1.610598  0.157495        1.442802  -0.680649   \n",
       "13   Yariel       0    -0.131271 -0.043749        0.354787  -0.680649   \n",
       "14  Joy Lim       1     0.159040 -0.848725        0.626791  -0.074391   \n",
       "15   Edward       1     0.333227  0.761227        0.898795   1.340212   \n",
       "16    Carol       0    -0.711894  0.761227       -1.005231  -0.074391   \n",
       "17   Vineet       0     1.262224  1.566204       -0.189220  -0.276477   \n",
       "18   Pratik       1    -0.305458  0.358739        1.442802   0.262419   \n",
       "19  Sharvil       0    -1.292517 -0.043749       -0.189220   1.744384   \n",
       "20     Alex       0    -1.815078  1.163715        1.442802   3.361073   \n",
       "21  Esteban       1    -0.886081 -0.043749       -1.277235   0.936039   \n",
       "22     Aadi       1    -0.828019 -1.251213        0.354787   0.760898   \n",
       "\n",
       "    nEating_Scale  nStress_Scale  nCaffeine  nS_Intensity_max  \\\n",
       "0        0.554313      -0.602626  -0.498812          1.108375   \n",
       "1       -1.682389       1.004376   0.306288         -1.095019   \n",
       "2       -0.787708      -1.406127  -0.498812         -1.482975   \n",
       "3       -0.340368      -0.602626  -0.498812          1.059858   \n",
       "4        0.106973       1.004376   1.111387         -0.657030   \n",
       "5        1.001654      -1.406127  -0.498812         -0.111797   \n",
       "6        1.001654      -1.004376  -0.498812         -1.185448   \n",
       "7        1.448994       1.406127  -0.096262         -0.341579   \n",
       "8        0.554313      -0.602626  -0.498812         -0.973905   \n",
       "9       -1.235049       1.004376   0.306288         -1.371364   \n",
       "10       0.554313       1.406127  -0.498812         -0.967156   \n",
       "11       0.106973      -1.406127  -0.498812         -1.177265   \n",
       "12       1.225324       1.004376   1.513937          1.095814   \n",
       "13      -1.682389       0.602626   3.929235          1.079005   \n",
       "14       0.106973       0.602626  -0.498812          1.051081   \n",
       "15       1.001654       1.406127  -0.498812          1.078824   \n",
       "16      -1.235049      -0.401751   0.105013         -0.797922   \n",
       "17      -1.235049       0.602626  -0.498812         -0.590952   \n",
       "18       1.001654      -1.004376  -0.498812          1.086613   \n",
       "19      -0.787708       0.602626  -0.498812          1.141500   \n",
       "20      -0.787708      -0.200875  -0.498812          1.053448   \n",
       "21      -0.340368      -1.406127   0.306288          0.958461   \n",
       "22       1.448994      -0.602626  -0.498812          0.039432   \n",
       "\n",
       "    nS_Intensity_avg  nS_Intensity_var  nS_Formant_0_avg  nS_Formant_1_avg  \\\n",
       "0           1.160502          1.362221          0.175746          0.523118   \n",
       "1          -0.976316         -0.695002         -0.801625         -0.836396   \n",
       "2          -1.081316         -0.933524          0.382196          0.997401   \n",
       "3           0.180850          0.205140          0.956877          0.788910   \n",
       "4          -1.409484         -0.906230         -1.706069         -1.488421   \n",
       "5          -0.200953          0.055606          1.192280          0.413803   \n",
       "6          -0.372899         -0.782553          0.520458          1.175552   \n",
       "7          -0.363797         -0.175410         -2.058855          0.238934   \n",
       "8          -0.582947         -0.476167         -1.100759         -1.318613   \n",
       "9          -1.119195         -0.849441          0.331435          0.634156   \n",
       "10         -1.001605         -0.758511         -1.332627          0.326242   \n",
       "11         -0.764299         -0.740632         -0.352888          0.113532   \n",
       "12          0.635857          1.613369          0.884563          1.712052   \n",
       "13         -0.400843         -0.383950          0.876861          1.221888   \n",
       "14         -0.151726         -0.016909          1.538785          0.141304   \n",
       "15          1.296996          1.072503          0.742777          0.469305   \n",
       "16         -0.544770         -0.894623          0.503219          0.467772   \n",
       "17         -0.555030         -1.614741         -1.273851         -2.403558   \n",
       "18          0.990617         -0.208933         -1.169399         -1.308847   \n",
       "19          2.581352          2.375308          0.117915         -0.228895   \n",
       "20          1.590492          1.492991          1.023077          0.266215   \n",
       "21          0.979018          0.939205          0.645620         -1.029436   \n",
       "22          0.109497          0.320283         -0.095735         -0.876019   \n",
       "\n",
       "    nS_Formant_2_avg  nS_Pitch_var  \n",
       "0           0.307106      1.307753  \n",
       "1           0.443064      2.449215  \n",
       "2          -0.167583     -0.826364  \n",
       "3           1.424176     -0.198406  \n",
       "4          -0.614605     -0.817343  \n",
       "5           0.616465     -0.686153  \n",
       "6           0.885069     -0.965039  \n",
       "7          -0.132854     -0.385195  \n",
       "8          -0.123145     -0.886090  \n",
       "9          -0.849356      1.853150  \n",
       "10          0.329912     -0.302614  \n",
       "11         -1.009720     -0.466992  \n",
       "12          2.275633     -0.591728  \n",
       "13          1.464361     -0.490341  \n",
       "14         -0.796894      2.284105  \n",
       "15          0.387597      0.063321  \n",
       "16          0.869583     -0.608691  \n",
       "17         -0.767611     -0.906615  \n",
       "18         -1.565357      0.106795  \n",
       "19         -0.363848      0.561251  \n",
       "20          0.522353      0.206529  \n",
       "21         -1.630940     -0.031875  \n",
       "22         -1.503407     -0.668672  "
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #time to bash with cross validation, 5 column combo\n",
    "# import itertools\n",
    "# col_combos = list(itertools.combinations(df.columns, 5))\n",
    "# highest_accuracy_number = 0\n",
    "# highest_accuracy_combo = []\n",
    "# for a, b, c, d, e in col_combos:\n",
    "#     x_columns = a, b, c, d, e\n",
    "#     x_columns = list(x_columns)\n",
    "#     if 'Labels' not in x_columns:\n",
    "#         if get_best_metric(x_columns, ['Labels'])>highest_accuracy_number:\n",
    "#             highest_accuracy_number = get_best_metric(x_columns, ['Labels'])\n",
    "#             highest_accuracy_combo = x_columns\n",
    "# print(highest_accuracy_combo)\n",
    "# print(highest_accuracy_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-788-9e820cd5a9d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mx_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'Labels'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_columns\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'Name'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mget_best_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mhighest_accuracy_number\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                     \u001b[0mhighest_accuracy_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_best_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                     \u001b[0mhighest_accuracy_combo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-771-c8601a232a1f>\u001b[0m in \u001b[0;36mget_best_metric\u001b[1;34m(x_cols, y_col)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;31m#     y_train_pred_rf= decision_tree.predict(x_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m#     rf_score = accuracy_score(y_train, y_train_pred_rf)*100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mrf_cross_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_forest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;31m#     print(\"Random Forest Training Accuracy is \", rf_score)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[1;32m--> 319\u001b[1;33m                                             random_state=random_state)\n\u001b[0m\u001b[0;32m    320\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0msub\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \"\"\"\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n\u001b[0;32m    128\u001b[0m                                     for p in self.estimator_params))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mparams_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# quick sanity check of the parameters of the clone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \"\"\"\n\u001b[0;32m    180\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_params'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;31m# to represent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0minit_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[1;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36msignature\u001b[1;34m(obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   3073\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m     \u001b[1;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3076\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[1;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   2823\u001b[0m         \u001b[1;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2824\u001b[0m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[1;32m-> 2825\u001b[1;33m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0m\u001b[0;32m   2826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[0;32m   2280\u001b[0m         \u001b[1;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2281\u001b[0m         \u001b[1;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2282\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_signature_from_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_signature_is_builtin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[1;34m(cls, func)\u001b[0m\n\u001b[0;32m   2157\u001b[0m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0;32m   2158\u001b[0m                                     \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_POSITIONAL_OR_KEYWORD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2159\u001b[1;33m                                     default=defaults[offset]))\n\u001b[0m\u001b[0;32m   2160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2161\u001b[0m     \u001b[1;31m# *args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#bashing for 5 columns and less\n",
    "import itertools\n",
    "highest_accuracy_number = 0\n",
    "highest_accuracy_combo = []\n",
    "\n",
    "for number in [1, 2, 3, 4, 5]:\n",
    "    col_combos = list(itertools.combinations(df.columns, number))\n",
    "    if number == 5:\n",
    "        for a, b, c, d, e in col_combos:\n",
    "            x_columns = a, b, c, d\n",
    "            x_columns = list(x_columns)\n",
    "            if 'Labels' not in x_columns and 'Name' not in x_columns:\n",
    "                if get_best_metric(x_columns, ['Labels'])>highest_accuracy_number:\n",
    "                    highest_accuracy_number = get_best_metric(x_columns, ['Labels'])\n",
    "                    highest_accuracy_combo = x_columns\n",
    "    elif number == 4:\n",
    "        for a, b, c, d in col_combos:\n",
    "            x_columns = a, b, c, d\n",
    "            x_columns = list(x_columns)\n",
    "            if 'Labels' not in x_columns and 'Name' not in x_columns:\n",
    "                if get_best_metric(x_columns, ['Labels'])>highest_accuracy_number:\n",
    "                    highest_accuracy_number = get_best_metric(x_columns, ['Labels'])\n",
    "                    highest_accuracy_combo = x_columns\n",
    "    elif number == 3:\n",
    "        for a, b, c in col_combos:\n",
    "            x_columns = a, b, c\n",
    "            x_columns = list(x_columns)\n",
    "            if 'Labels' not in x_columns and 'Name' not in x_columns:\n",
    "                if get_best_metric(x_columns, ['Labels'])>highest_accuracy_number:\n",
    "                    highest_accuracy_number = get_best_metric(x_columns, ['Labels'])\n",
    "                    highest_accuracy_combo = x_columns\n",
    "    elif number == 2:\n",
    "        for a, b in col_combos:\n",
    "            x_columns = a, b\n",
    "            x_columns = list(x_columns)\n",
    "            if 'Labels' not in x_columns and 'Name' not in x_columns:\n",
    "                if get_best_metric(x_columns, ['Labels'])>highest_accuracy_number:\n",
    "                    highest_accuracy_number = get_best_metric(x_columns, ['Labels'])\n",
    "                    highest_accuracy_combo = x_columns\n",
    "    elif number == 1:\n",
    "        for a in col_combos:\n",
    "            x_columns = a\n",
    "            x_columns = list(x_columns)\n",
    "            if 'Labels' not in x_columns and 'Name' not in x_columns:\n",
    "                if get_best_metric(x_columns, ['Labels'])>highest_accuracy_number:\n",
    "                    highest_accuracy_number = get_best_metric(x_columns, ['Labels'])\n",
    "                    highest_accuracy_combo = x_columns\n",
    "print(highest_accuracy_combo)\n",
    "print(highest_accuracy_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46333333333333326\n",
      "0.5599999999999999\n",
      "0.5866666666666667\n",
      "0.6033333333333333\n",
      "0.77\n"
     ]
    }
   ],
   "source": [
    "print_best_metric(['Sleep', 'Stress_Scale'], ['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_cols = ['nHeart_Rate', 'nSleep', 'nS_Intensity_max', 'nS_Formant_2_avg', 'nS_Pitch_var']\n",
    "# y_col = ['Labels']\n",
    "# x_train, x_test, y_train, y_test = train_test_split(df[x_cols], df[y_col], test_size = 0.30, random_state = 0)\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "# knn.fit(x_train, y_train)\n",
    "# y_train_pred_knn= knn.predict(x_train)\n",
    "# knn_score = accuracy_score(y_train, y_train_pred_knn)*100\n",
    "# knn_cross_scores = cross_val_score(knn, x_train, y_train, cv=5)\n",
    "# knn_cross_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nSleep</th>\n",
       "      <th>nCaffeine</th>\n",
       "      <th>nS_Intensity_var</th>\n",
       "      <th>nS_Formant_1_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nSleep</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004211</td>\n",
       "      <td>0.198304</td>\n",
       "      <td>-0.212398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCaffeine</th>\n",
       "      <td>-0.004211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043919</td>\n",
       "      <td>0.254212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nS_Intensity_var</th>\n",
       "      <td>0.198304</td>\n",
       "      <td>-0.043919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.253423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nS_Formant_1_avg</th>\n",
       "      <td>-0.212398</td>\n",
       "      <td>0.254212</td>\n",
       "      <td>0.253423</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    nSleep  nCaffeine  nS_Intensity_var  nS_Formant_1_avg\n",
       "nSleep            1.000000  -0.004211          0.198304         -0.212398\n",
       "nCaffeine        -0.004211   1.000000         -0.043919          0.254212\n",
       "nS_Intensity_var  0.198304  -0.043919          1.000000          0.253423\n",
       "nS_Formant_1_avg -0.212398   0.254212          0.253423          1.000000"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrdf = df[['nSleep', 'nCaffeine', 'nS_Intensity_var', 'nS_Formant_1_avg']]\n",
    "corrdf.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sleep</th>\n",
       "      <th>Fatigue_Scale</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Eating_Scale</th>\n",
       "      <th>Stress_Scale</th>\n",
       "      <th>Caffeine</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>S_Intensity_max</th>\n",
       "      <th>S_Intensity_avg</th>\n",
       "      <th>S_Intensity_var</th>\n",
       "      <th>S_Formant_1_avg</th>\n",
       "      <th>S_Formant_2_avg</th>\n",
       "      <th>S_Formant_0_avg</th>\n",
       "      <th>S_Pitch_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>86.143374</td>\n",
       "      <td>50.205385</td>\n",
       "      <td>153.904346</td>\n",
       "      <td>1700.186657</td>\n",
       "      <td>2817.413656</td>\n",
       "      <td>625.183370</td>\n",
       "      <td>2131.163464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andy</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>70.581638</td>\n",
       "      <td>43.429503</td>\n",
       "      <td>74.933583</td>\n",
       "      <td>1710.123581</td>\n",
       "      <td>2746.356707</td>\n",
       "      <td>591.086196</td>\n",
       "      <td>8000.296166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carol2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.635366</td>\n",
       "      <td>41.294334</td>\n",
       "      <td>41.270625</td>\n",
       "      <td>1770.358418</td>\n",
       "      <td>2885.672278</td>\n",
       "      <td>698.462570</td>\n",
       "      <td>2228.749789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.5</td>\n",
       "      <td>82.896854</td>\n",
       "      <td>51.329865</td>\n",
       "      <td>121.398443</td>\n",
       "      <td>1746.084764</td>\n",
       "      <td>2741.920825</td>\n",
       "      <td>694.596996</td>\n",
       "      <td>4253.062523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emily</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.5</td>\n",
       "      <td>60.627363</td>\n",
       "      <td>41.050361</td>\n",
       "      <td>63.132047</td>\n",
       "      <td>1805.825950</td>\n",
       "      <td>2839.440742</td>\n",
       "      <td>699.951592</td>\n",
       "      <td>2537.070323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Esteban2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>60.589227</td>\n",
       "      <td>41.627282</td>\n",
       "      <td>61.722834</td>\n",
       "      <td>1712.762958</td>\n",
       "      <td>2813.161477</td>\n",
       "      <td>571.539381</td>\n",
       "      <td>12109.075886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jeanette</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>67.5</td>\n",
       "      <td>72.975695</td>\n",
       "      <td>46.764756</td>\n",
       "      <td>90.431776</td>\n",
       "      <td>1691.397773</td>\n",
       "      <td>2638.074506</td>\n",
       "      <td>583.045126</td>\n",
       "      <td>2002.854243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saketh</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>73.553448</td>\n",
       "      <td>43.330092</td>\n",
       "      <td>84.271462</td>\n",
       "      <td>1768.053116</td>\n",
       "      <td>2769.981565</td>\n",
       "      <td>635.323538</td>\n",
       "      <td>3304.960493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shuen2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>72.5</td>\n",
       "      <td>58.023133</td>\n",
       "      <td>42.821011</td>\n",
       "      <td>38.640359</td>\n",
       "      <td>1642.289077</td>\n",
       "      <td>2748.574316</td>\n",
       "      <td>594.837758</td>\n",
       "      <td>5758.362762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Suat2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.5</td>\n",
       "      <td>91.541237</td>\n",
       "      <td>49.412826</td>\n",
       "      <td>96.977152</td>\n",
       "      <td>1708.898676</td>\n",
       "      <td>2814.212418</td>\n",
       "      <td>632.270396</td>\n",
       "      <td>3791.129104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Yeriel2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>70.395392</td>\n",
       "      <td>46.541720</td>\n",
       "      <td>135.851275</td>\n",
       "      <td>1703.623354</td>\n",
       "      <td>2771.520797</td>\n",
       "      <td>642.618874</td>\n",
       "      <td>3153.270442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Sleep  Fatigue_Scale  Exercise  Eating_Scale  Stress_Scale  \\\n",
       "0       Adam    6.0              4        20             8             7   \n",
       "1       Andy    7.5              1         0             5             2   \n",
       "2     Carol2    6.5              6         0             4             5   \n",
       "3      Chris    5.5              7        30             6             7   \n",
       "4      Emily    5.5              6        60             4             4   \n",
       "5   Esteban2    6.0              2         0             8             2   \n",
       "6   Jeanette    5.5              5        75             7             7   \n",
       "7     Saketh    8.5              4        40             7             4   \n",
       "8     Shuen2    7.0              3         0             6             4   \n",
       "9      Suat2    6.0              6        10             7             4   \n",
       "10   Yeriel2    7.0              5         0             7             4   \n",
       "\n",
       "    Caffeine  Labels  Heart_Rate  S_Intensity_max  S_Intensity_avg  \\\n",
       "0        4.0       0        77.0        86.143374        50.205385   \n",
       "1        0.0       0        67.0        70.581638        43.429503   \n",
       "2        0.0       0        76.0        69.635366        41.294334   \n",
       "3        4.0       0        77.5        82.896854        51.329865   \n",
       "4        0.0       1        70.5        60.627363        41.050361   \n",
       "5        0.0       0        72.0        60.589227        41.627282   \n",
       "6        0.0       1        67.5        72.975695        46.764756   \n",
       "7        0.0       1        59.0        73.553448        43.330092   \n",
       "8        0.5       1        72.5        58.023133        42.821011   \n",
       "9        0.0       1        81.5        91.541237        49.412826   \n",
       "10       2.0       0        86.0        70.395392        46.541720   \n",
       "\n",
       "    S_Intensity_var  S_Formant_1_avg  S_Formant_2_avg  S_Formant_0_avg  \\\n",
       "0        153.904346      1700.186657      2817.413656       625.183370   \n",
       "1         74.933583      1710.123581      2746.356707       591.086196   \n",
       "2         41.270625      1770.358418      2885.672278       698.462570   \n",
       "3        121.398443      1746.084764      2741.920825       694.596996   \n",
       "4         63.132047      1805.825950      2839.440742       699.951592   \n",
       "5         61.722834      1712.762958      2813.161477       571.539381   \n",
       "6         90.431776      1691.397773      2638.074506       583.045126   \n",
       "7         84.271462      1768.053116      2769.981565       635.323538   \n",
       "8         38.640359      1642.289077      2748.574316       594.837758   \n",
       "9         96.977152      1708.898676      2814.212418       632.270396   \n",
       "10       135.851275      1703.623354      2771.520797       642.618874   \n",
       "\n",
       "     S_Pitch_var  \n",
       "0    2131.163464  \n",
       "1    8000.296166  \n",
       "2    2228.749789  \n",
       "3    4253.062523  \n",
       "4    2537.070323  \n",
       "5   12109.075886  \n",
       "6    2002.854243  \n",
       "7    3304.960493  \n",
       "8    5758.362762  \n",
       "9    3791.129104  \n",
       "10   3153.270442  "
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = pd.read_csv('new_AllData.csv')\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Fatigue_Scale</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Eating_Scale</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>S_Intensity_max</th>\n",
       "      <th>S_Intensity_avg</th>\n",
       "      <th>S_Formant_2_avg</th>\n",
       "      <th>S_Formant_0_avg</th>\n",
       "      <th>S_Pitch_var</th>\n",
       "      <th>nStress_Scale</th>\n",
       "      <th>nSleep</th>\n",
       "      <th>nCaffeine</th>\n",
       "      <th>nS_Intensity_var</th>\n",
       "      <th>nS_Formant_1_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>86.143374</td>\n",
       "      <td>50.205385</td>\n",
       "      <td>2817.413656</td>\n",
       "      <td>625.183370</td>\n",
       "      <td>2131.163464</td>\n",
       "      <td>1.423025</td>\n",
       "      <td>-0.496292</td>\n",
       "      <td>1.972295</td>\n",
       "      <td>1.864873</td>\n",
       "      <td>-0.541835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>70.581638</td>\n",
       "      <td>43.429503</td>\n",
       "      <td>2746.356707</td>\n",
       "      <td>591.086196</td>\n",
       "      <td>8000.296166</td>\n",
       "      <td>-1.475730</td>\n",
       "      <td>1.141471</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>-0.353013</td>\n",
       "      <td>-0.311877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carol2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.635366</td>\n",
       "      <td>41.294334</td>\n",
       "      <td>2885.672278</td>\n",
       "      <td>698.462570</td>\n",
       "      <td>2228.749789</td>\n",
       "      <td>0.263523</td>\n",
       "      <td>0.049629</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>-1.298434</td>\n",
       "      <td>1.082063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>77.5</td>\n",
       "      <td>82.896854</td>\n",
       "      <td>51.329865</td>\n",
       "      <td>2741.920825</td>\n",
       "      <td>694.596996</td>\n",
       "      <td>4253.062523</td>\n",
       "      <td>1.423025</td>\n",
       "      <td>-1.042213</td>\n",
       "      <td>1.972295</td>\n",
       "      <td>0.951948</td>\n",
       "      <td>0.520328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emily</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>70.5</td>\n",
       "      <td>60.627363</td>\n",
       "      <td>41.050361</td>\n",
       "      <td>2839.440742</td>\n",
       "      <td>699.951592</td>\n",
       "      <td>2537.070323</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-1.042213</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>-0.684458</td>\n",
       "      <td>1.902844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Esteban2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>60.589227</td>\n",
       "      <td>41.627282</td>\n",
       "      <td>2813.161477</td>\n",
       "      <td>571.539381</td>\n",
       "      <td>12109.075886</td>\n",
       "      <td>-1.475730</td>\n",
       "      <td>-0.496292</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>-0.724036</td>\n",
       "      <td>-0.250797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jeanette</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>67.5</td>\n",
       "      <td>72.975695</td>\n",
       "      <td>46.764756</td>\n",
       "      <td>2638.074506</td>\n",
       "      <td>583.045126</td>\n",
       "      <td>2002.854243</td>\n",
       "      <td>1.423025</td>\n",
       "      <td>-1.042213</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>0.082252</td>\n",
       "      <td>-0.745225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saketh</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>73.553448</td>\n",
       "      <td>43.330092</td>\n",
       "      <td>2769.981565</td>\n",
       "      <td>635.323538</td>\n",
       "      <td>3304.960493</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>2.233313</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>-0.090760</td>\n",
       "      <td>1.028714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shuen2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>72.5</td>\n",
       "      <td>58.023133</td>\n",
       "      <td>42.821011</td>\n",
       "      <td>2748.574316</td>\n",
       "      <td>594.837758</td>\n",
       "      <td>5758.362762</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>0.595550</td>\n",
       "      <td>-0.294372</td>\n",
       "      <td>-1.372304</td>\n",
       "      <td>-1.881686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Suat2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>81.5</td>\n",
       "      <td>91.541237</td>\n",
       "      <td>49.412826</td>\n",
       "      <td>2814.212418</td>\n",
       "      <td>632.270396</td>\n",
       "      <td>3791.129104</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.496292</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>0.266078</td>\n",
       "      <td>-0.340224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Yeriel2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>70.395392</td>\n",
       "      <td>46.541720</td>\n",
       "      <td>2771.520797</td>\n",
       "      <td>642.618874</td>\n",
       "      <td>3153.270442</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>0.595550</td>\n",
       "      <td>0.677057</td>\n",
       "      <td>1.357854</td>\n",
       "      <td>-0.462304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Fatigue_Scale  Exercise  Eating_Scale  Labels  Heart_Rate  \\\n",
       "0       Adam              4        20             8       0        77.0   \n",
       "1       Andy              1         0             5       0        67.0   \n",
       "2     Carol2              6         0             4       0        76.0   \n",
       "3      Chris              7        30             6       0        77.5   \n",
       "4      Emily              6        60             4       1        70.5   \n",
       "5   Esteban2              2         0             8       0        72.0   \n",
       "6   Jeanette              5        75             7       1        67.5   \n",
       "7     Saketh              4        40             7       1        59.0   \n",
       "8     Shuen2              3         0             6       1        72.5   \n",
       "9      Suat2              6        10             7       1        81.5   \n",
       "10   Yeriel2              5         0             7       0        86.0   \n",
       "\n",
       "    S_Intensity_max  S_Intensity_avg  S_Formant_2_avg  S_Formant_0_avg  \\\n",
       "0         86.143374        50.205385      2817.413656       625.183370   \n",
       "1         70.581638        43.429503      2746.356707       591.086196   \n",
       "2         69.635366        41.294334      2885.672278       698.462570   \n",
       "3         82.896854        51.329865      2741.920825       694.596996   \n",
       "4         60.627363        41.050361      2839.440742       699.951592   \n",
       "5         60.589227        41.627282      2813.161477       571.539381   \n",
       "6         72.975695        46.764756      2638.074506       583.045126   \n",
       "7         73.553448        43.330092      2769.981565       635.323538   \n",
       "8         58.023133        42.821011      2748.574316       594.837758   \n",
       "9         91.541237        49.412826      2814.212418       632.270396   \n",
       "10        70.395392        46.541720      2771.520797       642.618874   \n",
       "\n",
       "     S_Pitch_var  nStress_Scale    nSleep  nCaffeine  nS_Intensity_var  \\\n",
       "0    2131.163464       1.423025 -0.496292   1.972295          1.864873   \n",
       "1    8000.296166      -1.475730  1.141471  -0.618182         -0.353013   \n",
       "2    2228.749789       0.263523  0.049629  -0.618182         -1.298434   \n",
       "3    4253.062523       1.423025 -1.042213   1.972295          0.951948   \n",
       "4    2537.070323      -0.316228 -1.042213  -0.618182         -0.684458   \n",
       "5   12109.075886      -1.475730 -0.496292  -0.618182         -0.724036   \n",
       "6    2002.854243       1.423025 -1.042213  -0.618182          0.082252   \n",
       "7    3304.960493      -0.316228  2.233313  -0.618182         -0.090760   \n",
       "8    5758.362762      -0.316228  0.595550  -0.294372         -1.372304   \n",
       "9    3791.129104      -0.316228 -0.496292  -0.618182          0.266078   \n",
       "10   3153.270442      -0.316228  0.595550   0.677057          1.357854   \n",
       "\n",
       "    nS_Formant_1_avg  \n",
       "0          -0.541835  \n",
       "1          -0.311877  \n",
       "2           1.082063  \n",
       "3           0.520328  \n",
       "4           1.902844  \n",
       "5          -0.250797  \n",
       "6          -0.745225  \n",
       "7           1.028714  \n",
       "8          -1.881686  \n",
       "9          -0.340224  \n",
       "10         -0.462304  "
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "for item in ['Stress_Scale', 'Sleep', 'Caffeine', 'S_Intensity_var', 'S_Formant_1_avg']:\n",
    "    norm_data = val_data[item].values.reshape(-1, 1)\n",
    "    scaler.fit(norm_data)\n",
    "    val_data['n' + item] = scaler.transform(norm_data)\n",
    "\n",
    "    val_data = val_data.drop([item], axis=1)\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['nSleep', 'nStress_Scale']\n",
    "y_col = ['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Fatigue_Scale</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Eating_Scale</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>S_Intensity_max</th>\n",
       "      <th>S_Intensity_avg</th>\n",
       "      <th>S_Formant_2_avg</th>\n",
       "      <th>S_Formant_0_avg</th>\n",
       "      <th>S_Pitch_var</th>\n",
       "      <th>nStress_Scale</th>\n",
       "      <th>nSleep</th>\n",
       "      <th>nCaffeine</th>\n",
       "      <th>nS_Intensity_var</th>\n",
       "      <th>nS_Formant_1_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>86.143374</td>\n",
       "      <td>50.205385</td>\n",
       "      <td>2817.413656</td>\n",
       "      <td>625.183370</td>\n",
       "      <td>2131.163464</td>\n",
       "      <td>1.423025</td>\n",
       "      <td>-0.496292</td>\n",
       "      <td>1.972295</td>\n",
       "      <td>1.864873</td>\n",
       "      <td>-0.541835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>70.581638</td>\n",
       "      <td>43.429503</td>\n",
       "      <td>2746.356707</td>\n",
       "      <td>591.086196</td>\n",
       "      <td>8000.296166</td>\n",
       "      <td>-1.475730</td>\n",
       "      <td>1.141471</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>-0.353013</td>\n",
       "      <td>-0.311877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carol2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.635366</td>\n",
       "      <td>41.294334</td>\n",
       "      <td>2885.672278</td>\n",
       "      <td>698.462570</td>\n",
       "      <td>2228.749789</td>\n",
       "      <td>0.263523</td>\n",
       "      <td>0.049629</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>-1.298434</td>\n",
       "      <td>1.082063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>77.5</td>\n",
       "      <td>82.896854</td>\n",
       "      <td>51.329865</td>\n",
       "      <td>2741.920825</td>\n",
       "      <td>694.596996</td>\n",
       "      <td>4253.062523</td>\n",
       "      <td>1.423025</td>\n",
       "      <td>-1.042213</td>\n",
       "      <td>1.972295</td>\n",
       "      <td>0.951948</td>\n",
       "      <td>0.520328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emily</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>70.5</td>\n",
       "      <td>60.627363</td>\n",
       "      <td>41.050361</td>\n",
       "      <td>2839.440742</td>\n",
       "      <td>699.951592</td>\n",
       "      <td>2537.070323</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-1.042213</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>-0.684458</td>\n",
       "      <td>1.902844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Esteban2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>60.589227</td>\n",
       "      <td>41.627282</td>\n",
       "      <td>2813.161477</td>\n",
       "      <td>571.539381</td>\n",
       "      <td>12109.075886</td>\n",
       "      <td>-1.475730</td>\n",
       "      <td>-0.496292</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>-0.724036</td>\n",
       "      <td>-0.250797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jeanette</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>67.5</td>\n",
       "      <td>72.975695</td>\n",
       "      <td>46.764756</td>\n",
       "      <td>2638.074506</td>\n",
       "      <td>583.045126</td>\n",
       "      <td>2002.854243</td>\n",
       "      <td>1.423025</td>\n",
       "      <td>-1.042213</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>0.082252</td>\n",
       "      <td>-0.745225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saketh</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>73.553448</td>\n",
       "      <td>43.330092</td>\n",
       "      <td>2769.981565</td>\n",
       "      <td>635.323538</td>\n",
       "      <td>3304.960493</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>2.233313</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>-0.090760</td>\n",
       "      <td>1.028714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shuen2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>72.5</td>\n",
       "      <td>58.023133</td>\n",
       "      <td>42.821011</td>\n",
       "      <td>2748.574316</td>\n",
       "      <td>594.837758</td>\n",
       "      <td>5758.362762</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>0.595550</td>\n",
       "      <td>-0.294372</td>\n",
       "      <td>-1.372304</td>\n",
       "      <td>-1.881686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Suat2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>81.5</td>\n",
       "      <td>91.541237</td>\n",
       "      <td>49.412826</td>\n",
       "      <td>2814.212418</td>\n",
       "      <td>632.270396</td>\n",
       "      <td>3791.129104</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.496292</td>\n",
       "      <td>-0.618182</td>\n",
       "      <td>0.266078</td>\n",
       "      <td>-0.340224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Yeriel2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>70.395392</td>\n",
       "      <td>46.541720</td>\n",
       "      <td>2771.520797</td>\n",
       "      <td>642.618874</td>\n",
       "      <td>3153.270442</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>0.595550</td>\n",
       "      <td>0.677057</td>\n",
       "      <td>1.357854</td>\n",
       "      <td>-0.462304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Fatigue_Scale  Exercise  Eating_Scale  Labels  Heart_Rate  \\\n",
       "0       Adam              4        20             8       0        77.0   \n",
       "1       Andy              1         0             5       0        67.0   \n",
       "2     Carol2              6         0             4       0        76.0   \n",
       "3      Chris              7        30             6       0        77.5   \n",
       "4      Emily              6        60             4       1        70.5   \n",
       "5   Esteban2              2         0             8       0        72.0   \n",
       "6   Jeanette              5        75             7       1        67.5   \n",
       "7     Saketh              4        40             7       1        59.0   \n",
       "8     Shuen2              3         0             6       1        72.5   \n",
       "9      Suat2              6        10             7       1        81.5   \n",
       "10   Yeriel2              5         0             7       0        86.0   \n",
       "\n",
       "    S_Intensity_max  S_Intensity_avg  S_Formant_2_avg  S_Formant_0_avg  \\\n",
       "0         86.143374        50.205385      2817.413656       625.183370   \n",
       "1         70.581638        43.429503      2746.356707       591.086196   \n",
       "2         69.635366        41.294334      2885.672278       698.462570   \n",
       "3         82.896854        51.329865      2741.920825       694.596996   \n",
       "4         60.627363        41.050361      2839.440742       699.951592   \n",
       "5         60.589227        41.627282      2813.161477       571.539381   \n",
       "6         72.975695        46.764756      2638.074506       583.045126   \n",
       "7         73.553448        43.330092      2769.981565       635.323538   \n",
       "8         58.023133        42.821011      2748.574316       594.837758   \n",
       "9         91.541237        49.412826      2814.212418       632.270396   \n",
       "10        70.395392        46.541720      2771.520797       642.618874   \n",
       "\n",
       "     S_Pitch_var  nStress_Scale    nSleep  nCaffeine  nS_Intensity_var  \\\n",
       "0    2131.163464       1.423025 -0.496292   1.972295          1.864873   \n",
       "1    8000.296166      -1.475730  1.141471  -0.618182         -0.353013   \n",
       "2    2228.749789       0.263523  0.049629  -0.618182         -1.298434   \n",
       "3    4253.062523       1.423025 -1.042213   1.972295          0.951948   \n",
       "4    2537.070323      -0.316228 -1.042213  -0.618182         -0.684458   \n",
       "5   12109.075886      -1.475730 -0.496292  -0.618182         -0.724036   \n",
       "6    2002.854243       1.423025 -1.042213  -0.618182          0.082252   \n",
       "7    3304.960493      -0.316228  2.233313  -0.618182         -0.090760   \n",
       "8    5758.362762      -0.316228  0.595550  -0.294372         -1.372304   \n",
       "9    3791.129104      -0.316228 -0.496292  -0.618182          0.266078   \n",
       "10   3153.270442      -0.316228  0.595550   0.677057          1.357854   \n",
       "\n",
       "    nS_Formant_1_avg  \n",
       "0          -0.541835  \n",
       "1          -0.311877  \n",
       "2           1.082063  \n",
       "3           0.520328  \n",
       "4           1.902844  \n",
       "5          -0.250797  \n",
       "6          -0.745225  \n",
       "7           1.028714  \n",
       "8          -1.881686  \n",
       "9          -0.340224  \n",
       "10         -0.462304  "
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100).fit(val_data[x_cols], val_data[y_col])\n",
    "model.score(val_data[x_cols], val_data[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict_proba(val_data[x_cols])[:, 1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(val_data[y_col], y_pred)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Receiving operator characteristic')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "\n",
    "auc_score = auc(fpr, tpr)\n",
    "ax.plot(fpr, tpr, label=f'AUC={auc_score}')\n",
    "ax.fill_between(fpr, tpr, y2=0, color='#0000ff20')\n",
    "ax.legend()\n",
    "print(auc_score)\n",
    "\n",
    "fig.savefig('validate_auc.png', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
